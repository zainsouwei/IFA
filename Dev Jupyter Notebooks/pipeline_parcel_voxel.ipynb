{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cupy as cp\n",
    "import torch\n",
    "import hcp_utils as hcp # https://rmldj.github.io/hcp-utils/\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import matlab.engine\n",
    "import os\n",
    "import json\n",
    "import psutil\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import psutil\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.linalg import eigh, svd\n",
    "from scipy.stats import norm\n",
    "from sklearn.decomposition import FastICA, PCA\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso, LassoCV, MultiTaskLasso, ElasticNet, LogisticRegressionCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from nilearn import image as nimg\n",
    "from nilearn import plotting\n",
    "import nibabel as nib\n",
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.utils.mean import mean_covariance\n",
    "from pyriemann.utils.tangentspace import tangent_space, untangent_space, log_map_riemann, log_map_logeuclid, unupper\n",
    "from pyriemann.utils.distance import distance_riemann, distance\n",
    "from pyriemann.utils.base import logm, expm\n",
    "from concurrent.futures import ProcessPoolExecutor, TimeoutError\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your settings\n",
    "settings = {\n",
    "    \"phenotype\": \"PicVocab_AgeAdj_PMAT24_A_CR\",\n",
    "    \"percentile\": 0.2,\n",
    "    \"outputfolder\": \"PicVocab_AgeAdj_PMAT24_A_CR_TangentSVM_3_logeuclid\",\n",
    "    \"n_folds\": 5,\n",
    "    \"TanSVM_C\": 1,\n",
    "    \"random_state\": 42,\n",
    "    \"n_filters_per_group\": 3,\n",
    "    \"Tangent_Class\": True,\n",
    "    \"metric\": \"logeuclid\"\n",
    "}\n",
    "\n",
    "# Ensure the output folder exists\n",
    "outputfolder = settings[\"outputfolder\"]\n",
    "if not os.path.exists(outputfolder):\n",
    "    os.makedirs(outputfolder)\n",
    "\n",
    "# Define the path for the settings file\n",
    "settings_filepath = os.path.join(outputfolder, \"settings.json\")\n",
    "\n",
    "# Save the settings to a JSON file\n",
    "with open(settings_filepath, \"w\") as f:\n",
    "    json.dump(settings, f, indent=4)\n",
    "\n",
    "print(f\"Settings have been saved to {settings_filepath}\")\n",
    "# Define the output folder\n",
    "phenotype = settings[\"phenotype\"]\n",
    "percentile = settings[\"percentile\"]\n",
    "n_folds = settings[\"n_folds\"]\n",
    "TanSVM_C = settings[\"TanSVM_C\"]\n",
    "random_state = settings[\"random_state\"]\n",
    "n_filters_per_group = settings[\"n_filters_per_group\"]\n",
    "Tangent_Class = settings[\"Tangent_Class\"]\n",
    "# Pyriemannian Mean https://github.com/pyRiemann/pyRiemann/blob/master/pyriemann/utils/mean.py#L633 Metric for mean estimation, can be: \"ale\", \"alm\", \"euclid\", \"harmonic\", \"identity\", \"kullback_sym\", \"logdet\", \"logeuclid\", \"riemann\", \"wasserstein\", or a callable function.\n",
    "# https://link.springer.com/article/10.1007/s12021-020-09473-9 <---- best descriptions/plots\n",
    "# Geometric means in a novel vector space structure on symmetric positive-definite matrices <https://epubs.siam.org/doi/abs/10.1137/050637996?journalCode=sjmael>`_\n",
    "metric = settings[\"metric\"]\n",
    "\n",
    "def load_array_from_outputfolder(filename):\n",
    "    filepath = os.path.join(outputfolder, filename)\n",
    "    return np.load(filepath)\n",
    "# Function to save an array to the output folder\n",
    "def save_array_to_outputfolder(filename, array):\n",
    "    filepath = os.path.join(outputfolder, filename)\n",
    "    np.save(filepath, array)\n",
    "\n",
    "def save_text_results(text, filename=\"results.txt\"):\n",
    "    \"\"\"Save text results to a file.\"\"\"\n",
    "    filepath = os.path.join(outputfolder, filename)\n",
    "    with open(filepath, \"a\") as f:  # Using 'a' to append results to the file\n",
    "        f.write(text + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory and Processor Usage/Limits Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kernel.org/doc/Documentation/cgroup-v1/memory.txt\n",
    "#Open terminal for job\n",
    "# srun --jobid=68974 --overlap --pty /bin/bash \n",
    "\n",
    "# #SLURM RAM\n",
    "!cgget -r memory.limit_in_bytes /slurm/uid_$SLURM_JOB_UID/job_$SLURM_JOB_ID\n",
    "\n",
    "#SLURM VM\n",
    "!cgget -r memory.memsw.limit_in_bytes /slurm/uid_$SLURM_JOB_UID/job_$SLURM_JOB_ID\n",
    "\n",
    "#SLURM USAGE\n",
    "!cgget -r memory.memsw.usage_in_bytes /slurm/uid_$SLURM_JOB_UID/job_$SLURM_JOB_ID\n",
    "\n",
    "!echo \"SLURM_JOB_ID: $SLURM_JOB_ID\"\n",
    "!echo \"SLURM_JOB_NAME: $SLURM_JOB_NAME\"\n",
    "!echo \"SLURM_JOB_NODELIST: $SLURM_JOB_NODELIST\"\n",
    "!echo \"SLURM_MEM_PER_NODE: $SLURM_MEM_PER_NODE\"\n",
    "!echo \"SLURM_CPUS_ON_NODE: $SLURM_CPUS_ON_NODE\"\n",
    "!echo \"SLURM_MEM_PER_CPU: $SLURM_MEM_PER_CPU\"\n",
    "\n",
    "!free -h\n",
    "\n",
    "import resource\n",
    "\n",
    "# Get the soft and hard limits of virtual memory (address space)\n",
    "soft, hard = resource.getrlimit(resource.RLIMIT_AS)\n",
    "print(f\"Soft limit: {soft / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Hard limit: {hard / (1024 ** 3):.2f} GB\")\n",
    "\n",
    "# Get the soft and hard limits of the data segment (physical memory usage)\n",
    "soft, hard = resource.getrlimit(resource.RLIMIT_DATA)\n",
    "print(f\"Soft limit: {soft / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Hard limit: {hard / (1024 ** 3):.2f} GB\")\n",
    "\n",
    "#TORQUE Virtual Memory\n",
    "# !cgget -r memory.memsw.limit_in_bytes /torque/$PBS_JOBID\n",
    "\n",
    "# #TORQUE RAM\n",
    "# !cgget -r memory.limit_in_bytes /torque/$PBS_JOBID\n",
    "\n",
    "# #TORQUE USAGE\n",
    "# !cgget -r memory.memsw.usage_in_bytes /torque/$PBS_JOBID\n",
    "# print(int(os.environ['PBS_NP']))\n",
    "!nvidia-smi\n",
    "\n",
    "def gpu_mem():\n",
    "    # Memory usage information\n",
    "    print(f\"Total memory available: {(torch.cuda.get_device_properties('cuda').total_memory / 1024**3):.2f} GB\")\n",
    "    print(f\"Allocated memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"Reserved memory: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "\n",
    "def cpu_mem():\n",
    "   # Display memory information\n",
    "    print(f\"Total Memory: { psutil.virtual_memory().total / (1024**3):.2f} GB\")\n",
    "    print(f\"Available Memory: { psutil.virtual_memory().available / (1024**3):.2f} GB\")\n",
    "    print(f\"Used Memory: { psutil.virtual_memory().used / (1024**3):.2f} GB\")\n",
    "    print(f\"Memory Usage: { psutil.virtual_memory().percent}%\")\n",
    "\n",
    "gpu_mem()\n",
    "cpu_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Paths, Parcellate, Standardize, and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(phenotype, percentile, folder1=0):\n",
    "    \"\"\"\n",
    "    Load data for a specified number of subjects and fMRI tasks, only if they have not been parcellated.\n",
    "    \"\"\"\n",
    "\n",
    "    base_directory = \"/project_cephfs/3022017.01/S1200\"\n",
    "    subdirectory = \"MNINonLinear/Results\"\n",
    "    \n",
    "    folders = [\n",
    "        \"rfMRI_REST1_LR\", \"rfMRI_REST1_RL\", \"rfMRI_REST2_LR\", \"rfMRI_REST2_RL\",\n",
    "        \"tfMRI_EMOTION_LR\", \"tfMRI_EMOTION_RL\", \"tfMRI_GAMBLING_LR\", \"tfMRI_GAMBLING_RL\",\n",
    "        \"tfMRI_LANGUAGE_LR\", \"tfMRI_LANGUAGE_RL\", \"tfMRI_MOTOR_LR\", \"tfMRI_MOTOR_RL\",\n",
    "        \"tfMRI_RELATIONAL_LR\", \"tfMRI_RELATIONAL_RL\", \"tfMRI_SOCIAL_LR\", \"tfMRI_SOCIAL_RL\",\n",
    "        \"tfMRI_WM_LR\", \"tfMRI_WM_RL\"\n",
    "    ]\n",
    "\n",
    "\n",
    "    if folder1 + 1 >= len(folders):\n",
    "        raise IndexError(f\"Invalid folder1 index: {folder1}. Check folder list.\")\n",
    "\n",
    "    if folder1 + 2 >= len(folders):\n",
    "        raise IndexError(f\"Invalid folder1 index: {folder1}. Check folder list.\")\n",
    "\n",
    "    if folder1 + 3 >= len(folders):\n",
    "        raise IndexError(f\"Invalid folder1 index: {folder1}. Check folder list.\")\n",
    "\n",
    "    subids = [sub for sub in os.listdir(base_directory) if os.path.isdir(os.path.join(base_directory, sub))]\n",
    "\n",
    "    file_path_restricted = r'../HCP/RESTRICTED_zainsou_8_6_2024_2_11_21.csv'\n",
    "    file_path_unrestricted = r'../HCP/unrestricted_zainsou_8_2_2024_6_13_22.csv'\n",
    "\n",
    "    try:\n",
    "        # Load the data from CSV files\n",
    "        data_r = pd.read_csv(file_path_restricted)\n",
    "        data_ur = pd.read_csv(file_path_unrestricted)\n",
    "        print(\"Files loaded successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path_restricted} or {file_path_unrestricted}\")\n",
    "        raise\n",
    "\n",
    "    # Combine restricted and unrestricted data on Subject ID\n",
    "    data = pd.merge(data_r, data_ur, on='Subject', how='outer')\n",
    "\n",
    "    filtered_data = data[data['Subject'].astype(str).isin(subids)]\n",
    "    # plt.hist(filtered_data[\"SSAGA_FTND_Score\"], bins=10)\n",
    "    # plt.show()\n",
    "    # picvocab_low_threshold = filtered_data[\"PicVocab_AgeAdj\"].quantile(.2)\n",
    "    # picvocab_high_threshold = filtered_data[\"PicVocab_AgeAdj\"].quantile(0.8)\n",
    "    low_threshold = filtered_data[phenotype].quantile(percentile)\n",
    "    high_threshold = filtered_data[phenotype].quantile(1.0 - percentile)\n",
    "\n",
    "    # pmat24_low_threshold = filtered_data[\"PMAT24_A_CR\"].quantile(.2)\n",
    "    # pmat24_high_threshold = filtered_data[\"PMAT24_A_CR\"].quantile(.8)\n",
    "\n",
    "    # psqi_low_threshold = filtered_data[\"PSQI_Score\"].quantile(.7)\n",
    "    # psqi_high_threshold = filtered_data[\"PSQI_Score\"].quantile(.3)\n",
    "\n",
    "    # ssaga_educ_low_threshold = filtered_data[\"SSAGA_Educ\"].quantile(.3)\n",
    "    # ssaga_educ_high_threshold = filtered_data[\"SSAGA_Educ\"].quantile(.7)\n",
    "\n",
    "    # lifesatisf_low_threshold = filtered_data[\"LifeSatisf_Unadj\"].quantile(.2)\n",
    "    # lifesatisf_high_threshold = filtered_data[\"LifeSatisf_Unadj\"].quantile(.8)\n",
    "\n",
    "    # DDisc_low_threshold = filtered_data[\"DDisc_AUC_200\"].quantile(.2)\n",
    "    # DDisc_high_threshold = filtered_data[\"DDisc_AUC_200\"].quantile(.8)\n",
    "\n",
    "\n",
    "    # # Handedness_low_threshold = 0\n",
    "    # Handedness_high_threshold = 0\n",
    "    # tobacco_low_threshold = 4\n",
    "    # tobacco_high_threshold = 0\n",
    "    # # Binary variables - set the thresholds manually\n",
    "    # fam_hist_threshold_high = 0\n",
    "    # fam_hist_threshold_low = 1\n",
    "\n",
    "    # thc_threshold_high = 0\n",
    "    # thc_threshold_low = 1\n",
    "\n",
    "\n",
    "    # Filtering Group 1 (high tail) and Group 2 (low tail)\n",
    "    group_1 = np.array(filtered_data[\n",
    "        (filtered_data[phenotype] >= high_threshold)\n",
    "    ]['Subject']).astype(str)\n",
    "\n",
    "    group_2 = np.array(filtered_data[\n",
    "        (filtered_data[phenotype] <= low_threshold)\n",
    "    ]['Subject']).astype(str)\n",
    "\n",
    "    # Print the number of subjects in each group\n",
    "    print(f\"Group 1 (high tail): {len(group_1)} subjects\")\n",
    "    print(f\"Group 2 (low tail): {len(group_2)} subjects\")\n",
    "\n",
    "    group_1_paths = []\n",
    "    for subject in group_1:\n",
    "        subject_data1 = os.path.join(base_directory, subject, subdirectory, folders[folder1], folders[folder1] + \"_Atlas_MSMAll_hp2000_clean.dtseries.nii\")\n",
    "        subject_data2 = os.path.join(base_directory, subject, subdirectory, folders[folder1 + 1], folders[folder1 + 1] + \"_Atlas_MSMAll_hp2000_clean.dtseries.nii\")\n",
    "        subject_data3 = os.path.join(base_directory, subject, subdirectory, folders[folder1 + 2], folders[folder1 + 2] + \"_Atlas_MSMAll_hp2000_clean.dtseries.nii\")\n",
    "        subject_data4 = os.path.join(base_directory, subject, subdirectory, folders[folder1 + 3], folders[folder1 + 3] + \"_Atlas_MSMAll_hp2000_clean.dtseries.nii\")\n",
    "\n",
    "        if os.path.exists(subject_data1) and os.path.exists(subject_data2) and os.path.exists(subject_data3) and os.path.exists(subject_data4):\n",
    "            group_1_paths.append((subject_data1, subject_data2,subject_data3,subject_data4))\n",
    "    \n",
    "    group_2_paths = []\n",
    "    for subject in group_2:\n",
    "        subject_data1 = os.path.join(base_directory, subject, subdirectory, folders[folder1], folders[folder1] + \"_Atlas_MSMAll_hp2000_clean.dtseries.nii\")\n",
    "        subject_data2 = os.path.join(base_directory, subject, subdirectory, folders[folder1 + 1], folders[folder1 + 1] + \"_Atlas_MSMAll_hp2000_clean.dtseries.nii\")\n",
    "        subject_data3 = os.path.join(base_directory, subject, subdirectory, folders[folder1 + 2], folders[folder1 + 2] + \"_Atlas_MSMAll_hp2000_clean.dtseries.nii\")\n",
    "        subject_data4 = os.path.join(base_directory, subject, subdirectory, folders[folder1 + 3], folders[folder1 + 3] + \"_Atlas_MSMAll_hp2000_clean.dtseries.nii\")\n",
    "\n",
    "        if os.path.exists(subject_data1) and os.path.exists(subject_data2) and os.path.exists(subject_data3) and os.path.exists(subject_data4):\n",
    "            group_2_paths.append((subject_data1, subject_data2,subject_data3,subject_data4))\n",
    "\n",
    "    \n",
    "    print(\"Length of Group 1:\", len(group_1_paths))\n",
    "    print(\"Length of Group 2:\", len(group_2_paths))\n",
    "\n",
    "    # # Determine the minimum length\n",
    "    # min_length = min(len(group_1_paths), len(group_2_paths))\n",
    "\n",
    "    # # Randomly sample from the larger group to match the size of the smaller group\n",
    "    # if len(group_1_paths) > min_length:\n",
    "    #     group_1_paths = random.sample(group_1_paths, min_length)\n",
    "    # elif len(group_2_paths) > min_length:\n",
    "    #     group_2_paths = random.sample(group_2_paths, min_length)\n",
    "\n",
    "    # Print the new sizes of both groups\n",
    "    print(\"New Length of Group 1:\", len(group_1_paths))\n",
    "    print(\"New Length of Group 2:\", len(group_2_paths))\n",
    "    return group_1_paths,group_2_paths\n",
    "\n",
    "groupA_paths,groupB_paths = load(phenotype=phenotype,percentile=percentile,folder1=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "def process_subject(sub):\n",
    "    try:\n",
    "        concatenated_data = []\n",
    "        for task in sub:\n",
    "            X = nib.load(task).get_fdata(dtype=np.float32)\n",
    "            Xn = hcp.normalize(X-X.mean(axis=1, keepdims=True))\n",
    "            concatenated_data.append(Xn)\n",
    "            del X, Xn\n",
    "\n",
    "        # Concatenate data along the first axis\n",
    "        subject = np.concatenate(concatenated_data, axis=0)\n",
    "        del concatenated_data  # Explicitly delete the concatenated data list\n",
    "\n",
    "        Xp = hcp.parcellate(hcp.normalize(subject - subject.mean(axis=1,keepdims=True)), hcp.mmp)\n",
    "        Xp = hcp.normalize(Xp - Xp.mean(axis=1,keepdims=True))\n",
    "        del subject  # Explicitly delete the subject array\n",
    "\n",
    "        return Xp\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing subject: {e}\")\n",
    "        traceback.print_exc()  # Print the full traceback\n",
    "        return None\n",
    "\n",
    "\n",
    "def parcellate(group):\n",
    "    try:\n",
    "        with ProcessPoolExecutor(max_workers=(int(os.cpu_count()*.3))) as executor:\n",
    "            # Use map to process subjects in parallel\n",
    "            group_parcellated = list(executor.map(process_subject, group))\n",
    "        \n",
    "        # Filter out any None results to continue with successful parcellations\n",
    "        group_parcellated = [result for result in group_parcellated if result is not None]\n",
    "        return group_parcellated\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in parcellation process: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return []\n",
    "\n",
    "# Example usage\n",
    "try:\n",
    "    cpu_mem()  # Monitor CPU and memory usage before the operation\n",
    "    groupA_parcellated = parcellate(groupA_paths)\n",
    "    cpu_mem()  # Monitor CPU and memory usage after processing group A\n",
    "    groupB_parcellated = parcellate(groupB_paths)\n",
    "    cpu_mem()  # Monitor CPU and memory usage after processing group B\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during the outer loop: {e}\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "target_shape = (4800, 379)\n",
    "# Initialize lists to collect indices of mismatched arrays\n",
    "mismatched_indices_A = []\n",
    "mismatched_indices_B = []\n",
    "\n",
    "# Create the array for group A, collecting indices of mismatches\n",
    "groupA_parcellated_array = np.array([\n",
    "    array for index, array in enumerate(groupA_parcellated) \n",
    "    if array.shape == target_shape or mismatched_indices_A.append(index)\n",
    "])\n",
    "\n",
    "# Create the array for group B, collecting indices of mismatches\n",
    "groupB_parcellated_array = np.array([\n",
    "    array for index, array in enumerate(groupB_parcellated) \n",
    "    if array.shape == target_shape or mismatched_indices_B.append(index)\n",
    "])\n",
    "# Print the indices of arrays that did not match the target shape\n",
    "print(\"Mismatched indices in group A:\", mismatched_indices_A)\n",
    "print(\"Mismatched indices in group B:\", mismatched_indices_B)\n",
    "groupA_paths_filtered = np.array([path for i, path in enumerate(groupA_paths) if i not in mismatched_indices_A])\n",
    "groupB_paths_filtered = np.array([path for i, path in enumerate(groupB_paths) if i not in mismatched_indices_B])\n",
    "print(len(groupA_parcellated_array))\n",
    "print(len(groupB_parcellated_array))\n",
    "# Save the arrays in the specified output folder\n",
    "# Example usage to save the arrays\n",
    "save_array_to_outputfolder(\"groupA_parcellated_array.npy\", groupA_parcellated_array)\n",
    "save_array_to_outputfolder(\"groupB_parcellated_array.npy\", groupB_parcellated_array)\n",
    "save_array_to_outputfolder(\"groupA_paths_filtered.npy\", groupA_paths_filtered)\n",
    "save_array_to_outputfolder(\"groupB_paths_filtered.npy\", groupB_paths_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Paths & Parcellated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupA_parcellated_array = load_array_from_outputfolder(\"groupA_parcellated_array.npy\")\n",
    "groupB_parcellated_array = load_array_from_outputfolder(\"groupB_parcellated_array.npy\")\n",
    "groupA_paths_filtered = load_array_from_outputfolder(\"groupA_paths_filtered.npy\")\n",
    "groupB_paths_filtered = load_array_from_outputfolder(\"groupB_paths_filtered.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(groupA_parcellated_array.shape)\n",
    "print(groupB_parcellated_array.shape)\n",
    "total_subjects = groupA_parcellated_array.shape[0] + groupB_parcellated_array.shape[0]\n",
    "\n",
    "save_text_results(f\"Group A: {groupA_parcellated_array.shape}\")\n",
    "save_text_results(f\"Group B: {groupB_parcellated_array.shape}\")\n",
    "save_text_results(f\"Total subjects: {total_subjects}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Linear Seperability of Groups Full Parcellated Tangent Covs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(train, test=None, method=\"zscore\"):\n",
    "    \"\"\"\n",
    "    Preprocesses the training (and optionally test) data using the specified method.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    train : np.ndarray\n",
    "        The training data array of shape (n_samples, n_features).\n",
    "        \n",
    "    test : np.ndarray, optional\n",
    "        The test data array of shape (n_samples, n_features), by default None.\n",
    "        \n",
    "    method : str, optional\n",
    "        The preprocessing method to apply. Supported methods are:\n",
    "            - \"zscore\": Standardize features by removing the mean and scaling to unit variance.\n",
    "            - \"mean_center\": Center features by subtracting the mean without scaling.\n",
    "        Default is \"zscore\".\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    np.ndarray or tuple of np.ndarray\n",
    "        The preprocessed training data. If `test` is provided, returns a tuple of \n",
    "        (train_processed, test_processed). If `test` is None, returns only `train_processed`.\n",
    "    \n",
    "    Raises:\n",
    "    ------\n",
    "    ValueError:\n",
    "        If an unsupported `method` is provided.\n",
    "        \n",
    "    Examples:\n",
    "    --------\n",
    "    >>> train_data = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "    >>> test_data = np.array([[7, 8], [9, 10]])\n",
    "    >>> preproc(train_data, test_data, method=\"zscore\")\n",
    "    (array([[-1.22474487, -1.22474487],\n",
    "            [ 0.        ,  0.        ],\n",
    "            [ 1.22474487,  1.22474487]]),\n",
    "     array([[2.44948974, 2.44948974],\n",
    "            [3.67423461, 3.67423461]]))\n",
    "    \"\"\"\n",
    "    # Initialize variables for consistent return type\n",
    "    train_processed, test_processed = None, None\n",
    "\n",
    "    if method == \"zscore\":\n",
    "        scaler = StandardScaler()\n",
    "        train_processed = scaler.fit_transform(train)\n",
    "        if test is not None:\n",
    "            test_processed = scaler.transform(test)\n",
    "    \n",
    "    elif method == \"mean_center\":\n",
    "        mean = train.mean(axis=0)\n",
    "        train_processed = train - mean\n",
    "        if test is not None:\n",
    "            test_processed = test - mean\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method '{method}'. Supported methods are 'zscore' and 'mean_center'.\")\n",
    "\n",
    "    # Return train_processed, and test_processed if test is provided; else return only train_processed\n",
    "    return (train_processed, test_processed) if test is not None else train_processed\n",
    "\n",
    "\n",
    "\n",
    "def extract_sample_weights(train_subject_ids, y_train):\n",
    "    \"\"\"\n",
    "    Compute sample weights based on normalized phenotype scores for the training data,\n",
    "    ensuring equal total contribution from both groups.\n",
    "    \"\"\"\n",
    "    file_path_restricted = '../HCP/RESTRICTED_zainsou_8_6_2024_2_11_21.csv'\n",
    "    file_path_unrestricted = '../HCP/unrestricted_zainsou_8_2_2024_6_13_22.csv'\n",
    "\n",
    "    try:\n",
    "        data_r = pd.read_csv(file_path_restricted)\n",
    "        data_ur = pd.read_csv(file_path_unrestricted)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path_restricted} or {file_path_unrestricted}\")\n",
    "        raise\n",
    "\n",
    "    # Combine restricted and unrestricted data on Subject ID\n",
    "    data = pd.merge(data_r, data_ur, on='Subject', how='outer')\n",
    "\n",
    "    # Convert Subject IDs to string for consistency\n",
    "    data['Subject'] = data['Subject'].astype(str)\n",
    "    train_subject_ids = train_subject_ids.astype(str)\n",
    "\n",
    "    # Filter data for training subjects\n",
    "    train_data = data[data['Subject'].isin(train_subject_ids)]\n",
    "\n",
    "    # Ensure the order matches the training data\n",
    "    train_data = train_data.set_index('Subject').loc[train_subject_ids].reset_index()\n",
    "\n",
    "    # Extract individual phenotype scores\n",
    "    # pic_vocab_scores = train_data['PicVocab_AgeAdj']\n",
    "    # pmat24_scores = train_data['PMAT24_A_CR']\n",
    "\n",
    "    # Normalize each phenotype score individually between 0 and 1\n",
    "    # pic_vocab_min = pic_vocab_scores.min()\n",
    "    # pic_vocab_max = pic_vocab_scores.max()\n",
    "    # pic_vocab_norm = (pic_vocab_scores - pic_vocab_min) / (pic_vocab_max - pic_vocab_min)\n",
    "\n",
    "    # pmat24_min = pmat24_scores.min()\n",
    "    # pmat24_max = pmat24_scores.max()\n",
    "    # pmat24_norm = (pmat24_scores - pmat24_min) / (pmat24_max - pmat24_min)\n",
    "    # phenotype_scores = (pic_vocab_norm + pmat24_norm) / 2\n",
    "    \n",
    "    pheno_score = train_data['CogCrystalComp_Unadj']\n",
    "    pheno_min = pheno_score.min()\n",
    "    pheno_max = pheno_score.max()\n",
    "    pheno_norm = (pheno_score - pheno_min) / (pheno_max - pheno_min)\n",
    "    phenotype_scores = pheno_norm\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize sample weights array\n",
    "    sample_weights = np.zeros(len(y_train))\n",
    "\n",
    "    # Assign weights based on group labels\n",
    "    for idx, label in enumerate(y_train):\n",
    "        if label == 1:\n",
    "            # For Group 1: Higher scores ⇒ Higher weights\n",
    "            sample_weights[idx] = phenotype_scores.iloc[idx]\n",
    "        else:\n",
    "            # For Group 2: Higher scores ⇒ Lower weights\n",
    "            sample_weights[idx] = 1 - phenotype_scores.iloc[idx]\n",
    "\n",
    "    # Optional: Raise weights to a power to accentuate differences (if desired)\n",
    "    # sample_weights = sample_weights ** exponent  # Adjust the exponent as needed\n",
    "\n",
    "    # Ensure total weights for each group are equal\n",
    "    group1_indices = np.where(y_train == 1)[0]\n",
    "    group2_indices = np.where(y_train == 0)[0]\n",
    "\n",
    "    sum_group1_weights = np.sum(sample_weights[group1_indices])\n",
    "    sum_group2_weights = np.sum(sample_weights[group2_indices])\n",
    "\n",
    "    # Compute the scaling factor for each group\n",
    "    total_weight = (sum_group1_weights + sum_group2_weights) / 2\n",
    "    scale_group1 = total_weight / sum_group1_weights if sum_group1_weights != 0 else 1\n",
    "    scale_group2 = total_weight / sum_group2_weights if sum_group2_weights != 0 else 1\n",
    "\n",
    "    # Apply scaling factors to ensure equal total weight per group\n",
    "    sample_weights[group1_indices] *= scale_group1\n",
    "    sample_weights[group2_indices] *= scale_group2\n",
    "\n",
    "    # Plotting to visualize the sample weights\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(phenotype_scores, sample_weights, c=y_train, cmap='coolwarm', alpha=0.7)\n",
    "    plt.xlabel('Normalized Combined Phenotype Score')\n",
    "    plt.ylabel('Sample Weight')\n",
    "    plt.title('Sample Weights After Scaling')\n",
    "    plt.colorbar(label='Group Label')\n",
    "    plt.show()\n",
    "\n",
    "    return sample_weights\n",
    "\n",
    "    \n",
    "def tangent_transform(group1_train_cov, group1_test_cov, group2_train_cov, group2_test_cov, metric):        \n",
    "    # Compute the Fréchet mean using only the training data from both groups\n",
    "    Frechet_Mean = mean_covariance(\n",
    "        np.concatenate((group1_train_cov, group2_train_cov)), \n",
    "        metric=metric\n",
    "    )\n",
    "    # Perform tangent space projection\n",
    "    train_1 = tangent_space(group1_train_cov, Frechet_Mean, metric=metric)\n",
    "    train_2 = tangent_space(group2_train_cov, Frechet_Mean, metric=metric)\n",
    "    test_1 = tangent_space(group1_test_cov, Frechet_Mean, metric=metric)\n",
    "    test_2 = tangent_space(group2_test_cov, Frechet_Mean, metric=metric)\n",
    "\n",
    "    return train_1, train_2, test_1, test_2\n",
    "\n",
    "def test_classifiers(train_1, test_1, train_2, test_2, sample_weights_train=None):\n",
    "    # Dictionary with keys for each classifier\n",
    "    clf_dict = {\n",
    "        \"SVM (C=1)\": SVC(kernel='linear', C=1, class_weight='balanced'),\n",
    "        \"SVM (C=0.1)\": SVC(kernel='linear', C=0.1, class_weight='balanced'),\n",
    "        \"SVM (C=0.01)\": SVC(kernel='linear', C=0.01, class_weight='balanced'),\n",
    "        \"L2 SVM (C=1)\": LinearSVC(penalty='l2',loss='squared_hinge',C=1,class_weight='balanced'),\n",
    "        \"L2 SVM (C=0.1)\": LinearSVC(penalty='l2',loss='squared_hinge',C=.1,class_weight='balanced'),\n",
    "        \"L2 SVM (C=0.01)\":  LinearSVC(penalty='l2',loss='squared_hinge',C=.01,class_weight='balanced'),\n",
    "        \"L2 SVM Hinge (C=1)\": LinearSVC(penalty='l2',loss='hinge',C=1,class_weight='balanced'),\n",
    "        \"L2 SVM Hinge (C=0.1)\": LinearSVC(penalty='l2',loss='hinge',C=.1,class_weight='balanced'),\n",
    "        \"L2 SVM Hinge (C=0.01)\":  LinearSVC(penalty='l2',loss='hinge',C=.01,class_weight='balanced'),\n",
    "        \"L1 SVM (C=1)\": LinearSVC(penalty='l1',loss='squared_hinge',dual=False,C=1,class_weight='balanced'),\n",
    "        # \"L1 SVM (C=0.1)\": LinearSVC(penalty='l1',loss='squared_hinge',dual=False,C=.1,class_weight='balanced'),\n",
    "        # \"L1 SVM (C=0.01)\":  LinearSVC(penalty='l1',loss='squared_hinge',dual=False,C=.01,class_weight='balanced'),\n",
    "        \"LDA\": LDA(),\n",
    "        \"Logistic Regression (default)\": LogisticRegression(),\n",
    "        \"Logistic Regression (l2)\": LogisticRegression(penalty='l2', class_weight='balanced'),\n",
    "        \"Logistic Regression (l1)\": LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced'),\n",
    "    #     \"Logistic Regression (elasticnet)\": LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.2, class_weight='balanced')\n",
    "    }\n",
    "\n",
    "     # Combine training data and labels\n",
    "    X_train = np.concatenate((train_1, train_2))\n",
    "    y_train = np.concatenate((np.ones(len(train_1)), np.zeros(len(train_2))))\n",
    "\n",
    "    # Combine test data and labels\n",
    "    X_test = np.concatenate((test_1, test_2))\n",
    "    y_test = np.concatenate((np.ones(len(test_1)), np.zeros(len(test_2))))\n",
    "\n",
    "    X_train, X_test = preprocess(X_train, X_test)\n",
    "\n",
    "    # Ensure sample_weights_train aligns with X_train and y_train\n",
    "    if sample_weights_train is not None:\n",
    "        assert len(sample_weights_train) == len(y_train), \"Sample weights length mismatch.\"\n",
    "\n",
    "\n",
    "    # Calculate the distance between the two class means\n",
    "    # mean_group1_train = np.mean(group1_test, axis=0)\n",
    "    # mean_group2_train = np.mean(group2_test, axis=0)\n",
    "    # distance_vars = np.linalg.norm(mean_group1_train - mean_group2_train)\n",
    "\n",
    "    # Initialize a dictionary to store the metrics\n",
    "    metrics_dict = {}\n",
    "    \n",
    "    # Iterate through each classifier and calculate accuracy\n",
    "    for key, clf in clf_dict.items():\n",
    "        clf.fit(X_train, y_train)\n",
    "        # clf.fit(X_train, y_train, sample_weight=sample_weights_train)\n",
    "\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        correct_predictions = np.sum(predictions == y_test)\n",
    "        total_predictions = len(y_test)\n",
    "        # Confusion matrix to get per-class accuracy\n",
    "        cm = confusion_matrix(y_test, predictions, labels=[1, 0])\n",
    "        per_class_correct = np.diag(cm)\n",
    "        per_class_total = np.sum(cm, axis=1)\n",
    "        per_class_accuracy = per_class_correct / per_class_total\n",
    "\n",
    "        metrics_dict[key] = {\n",
    "            'accuracy': accuracy,\n",
    "            'correct_predictions': correct_predictions,\n",
    "            'total_predictions': total_predictions,\n",
    "            'per_class_correct': per_class_correct,\n",
    "            'per_class_total': per_class_total,\n",
    "            'per_class_accuracy': per_class_accuracy\n",
    "        }\n",
    "    # if test_data.shape[1] == 2:\n",
    "    #     # Plot when n=1\n",
    "    #     plt.figure(figsize=(8, 6))\n",
    "    #     plt.scatter(group1_test[:, 0], group1_test[:, 1], label='Group 1 Log Variance (Test)', color='blue')\n",
    "    #     plt.scatter(group2_test[:, 0], group2_test[:, 1], label='Group 2 Log Variance (Test)', color='red')\n",
    "\n",
    "    #     # Plot the line connecting the two means\n",
    "    #     plt.plot([mean_group1_train[0], mean_group2_train[0]], [mean_group1_train[1], mean_group2_train[1]], 'k--', label=f'Mean Distance: {distance_vars:.2f}')\n",
    "\n",
    "    #     # Decision boundary\n",
    "    #     x_values = np.array([data[:, 0].min(), data[:, 0].max()])\n",
    "    #     y_values = -(max_clf.intercept_ + max_clf.coef_[0][0] * x_values) / max_clf.coef_[0][1]\n",
    "    #     plt.plot(x_values, y_values, 'g-', label='Decision Boundary')\n",
    "\n",
    "    #     # Display plot\n",
    "    #     plt.xlabel('Log Variance Feature 1')\n",
    "    #     plt.ylabel('Log Variance Feature 2')\n",
    "    #     plt.title(f'Log Variance Comparison and {max_key} Decision Boundary')\n",
    "\n",
    "    #     # Display classification accuracy on the plot\n",
    "    #     plt.text(0.05, 0.95, f'Accuracy: {accuracy:.2f}', transform=plt.gca().transAxes, fontsize=12,\n",
    "    #     verticalalignment='top', bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgrey'))\n",
    "\n",
    "    #     plt.legend()\n",
    "    #     plt.grid(True)\n",
    "    #     plt.show()\n",
    "    return metrics_dict\n",
    "\n",
    "    \n",
    "def test_linear_sep(groupA_parcellated_array, groupB_parcellated_array,groupA_paths, groupB_paths,metric='riemann',n_splits=10):\n",
    "    cov_est = Covariances(estimator='lwf')\n",
    "    groupA_parcellated_covs = cov_est.transform(np.transpose(groupA_parcellated_array, (0, 2, 1)))\n",
    "    groupB_parcellated_covs = cov_est.transform(np.transpose(groupB_parcellated_array, (0, 2, 1)))\n",
    "\n",
    "    data = np.concatenate((groupA_parcellated_covs, groupB_parcellated_covs))\n",
    "    labels = np.concatenate((np.ones(len(groupA_parcellated_covs)), np.zeros(len(groupB_parcellated_covs))))\n",
    "\n",
    "    all_paths = np.concatenate((groupA_paths, groupB_paths))\n",
    "    subject_ids = np.array([re.search(r'/(\\d+)/', path[0]).group(1) for path in all_paths])\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    metrics_dict = {}\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(data, labels)):\n",
    "        print(f\"\\nProcessing Fold {fold + 1}/{n_splits}\")\n",
    "        data_train, data_test = data[train_index], data[test_index]\n",
    "        labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        group1_train_cov = data_train[labels_train == 1]\n",
    "        group2_train_cov = data_train[labels_train == 0]\n",
    "        group1_test_cov = data_test[labels_test == 1]\n",
    "        group2_test_cov = data_test[labels_test == 0]\n",
    "\n",
    "        # train_subject_ids = subject_ids[train_index]\n",
    "        # # Compute sample weights for the training data\n",
    "        # sample_weights_train = extract_sample_weights(train_subject_ids, labels_train)\n",
    "\n",
    "        # Perform tangent space transformation\n",
    "        train_1, train_2, test_1, test_2 = tangent_transform(\n",
    "            group1_train_cov, group1_test_cov,\n",
    "            group2_train_cov, group2_test_cov,\n",
    "            metric=metric \n",
    "        )\n",
    "\n",
    "        fold_metrics = test_classifiers(train_1, test_1, train_2, test_2, sample_weights_train=None)\n",
    "\n",
    "        # Initialize metrics_dict keys on first fold\n",
    "        if fold == 0:\n",
    "            for clf_name in fold_metrics.keys():\n",
    "                metrics_dict[clf_name] = {\n",
    "                    'correct_predictions': 0,\n",
    "                    'total_predictions': 0,\n",
    "                    'accuracies': [],\n",
    "                    'per_class_correct': np.array([0, 0]),\n",
    "                    'per_class_total': np.array([0, 0])\n",
    "                }\n",
    "\n",
    "        # Aggregate metrics\n",
    "        for clf_name, metrics in fold_metrics.items():\n",
    "            # Update total correct predictions and total samples\n",
    "            metrics_dict[clf_name]['correct_predictions'] += metrics['correct_predictions']\n",
    "            metrics_dict[clf_name]['total_predictions'] += metrics['total_predictions']\n",
    "            # Store accuracies for mean and std calculation\n",
    "            metrics_dict[clf_name]['accuracies'].append(metrics['accuracy'])\n",
    "            # Update per-class correct and total counts\n",
    "            metrics_dict[clf_name]['per_class_correct'] += metrics['per_class_correct']\n",
    "            metrics_dict[clf_name]['per_class_total'] += metrics['per_class_total']\n",
    "\n",
    "            # Print per-fold metrics\n",
    "            print(f\"Classifier: {clf_name}\")\n",
    "            print(f\"  Fold Accuracy: {metrics['accuracy'] * 100:.2f}%\")\n",
    "            print(f\"  Correct Predictions: {metrics['correct_predictions']}/{metrics['total_predictions']}\")\n",
    "            print(f\"  Per-Class Accuracy: {metrics['per_class_accuracy'] * 100}\")\n",
    "\n",
    "    # After all folds, compute overall metrics\n",
    "    print(\"\\nOverall Metrics Across All Folds:\")\n",
    "    for clf_name, clf_metrics in metrics_dict.items():\n",
    "        overall_accuracy = clf_metrics['correct_predictions'] / clf_metrics['total_predictions']\n",
    "        mean_accuracy = np.mean(clf_metrics['accuracies'])\n",
    "        std_accuracy = np.std(clf_metrics['accuracies'])\n",
    "        per_class_accuracy = clf_metrics['per_class_correct'] / clf_metrics['per_class_total']\n",
    "\n",
    "        print(f\"\\nClassifier: {clf_name}\")\n",
    "        print(f\"  Total Accuracy: {overall_accuracy * 100:.2f}%\")\n",
    "        print(f\"  Average Fold Accuracy: {mean_accuracy * 100:.2f}%\")\n",
    "        print(f\"  Fold Accuracy Std Dev: {std_accuracy * 100:.2f}%\")\n",
    "        print(f\"  Per-Class Accuracy: {per_class_accuracy * 100}\")\n",
    "\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cov_cross_val = test_linear_sep(groupA_parcellated_array, groupB_parcellated_array,groupA_paths_filtered, groupB_paths_filtered, metric=metric,n_splits=10)\n",
    "save_text_results(f\"Tangent Space Classification Accuracy Results: {full_cov_cross_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FKT Functions and Cross Validate Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tangent_LDA(group1_covs=None, group2_covs=None, Frechet_Mean=None,tangent_projected_1=None, tangent_projected_2=None, tangent_calc=True, metric=\"riemann\",k=1, visualize=False):\n",
    "#     if tangent_calc:\n",
    "#         all_covs = np.concatenate((group1_covs, group2_covs))\n",
    "#         Frechet_Mean = mean_covariance(all_covs, metric=metric)\n",
    "#         tangent_projected_1 = tangent_space(group1_covs, Frechet_Mean, metric=metric)\n",
    "#         tangent_projected_2 = tangent_space(group2_covs, Frechet_Mean, metric=metric)\n",
    "        \n",
    "\n",
    "#     # Initialize the Covariances estimator\n",
    "#     cov_estimator = Covariances(estimator='lwf')\n",
    "#     tangent_projected_mean = np.mean(np.concatenate((tangent_projected_1, tangent_projected_2)),axis=0,keepdims=True)  \n",
    "    \n",
    "#     tangent_1_mean = np.mean(tangent_projected_1,axis=0,keepdims=True) - tangent_projected_mean\n",
    "#     tangent_2_mean = np.mean(tangent_projected_2,axis=0,keepdims=True) - tangent_projected_mean\n",
    "#     tangent_between_scatter = tangent_1_mean.T@tangent_1_mean + tangent_2_mean.T@tangent_2_mean\n",
    "    \n",
    "#     # Estimate the covariance matrices\n",
    "#     cov_tangent_projected_1 = cov_estimator.transform(np.transpose(tangent_projected_1[np.newaxis,:,:],(0,2,1)))[0]\n",
    "#     cov_tangent_projected_2 = cov_estimator.transform(np.transpose(tangent_projected_2[np.newaxis,:,:],(0,2,1)))[0]\n",
    "    \n",
    "\n",
    "#     # Convert to PyTorch tensors and move to GPU\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     print((\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "#     gpu_mem()\n",
    "#     sum = torch.tensor(cov_tangent_projected_1, dtype=torch.float32, device=\"cuda\") + torch.tensor(cov_tangent_projected_2, dtype=torch.float32, device=\"cuda\")\n",
    "#     gpu_mem()\n",
    "#     # cov_tangent_projected_1 = torch.tensor(cov_tangent_projected_1, dtype=torch.float32, device=device)\n",
    "#     # gpu_mem()\n",
    "#     # cov_tangent_projected_2 = torch.tensor(cov_tangent_projected_2, dtype=torch.float32, device=device) \n",
    "#     # gpu_mem()\n",
    "#     gpu_mem()\n",
    "\n",
    "#     tangent_between_scatter = torch.tensor(tangent_between_scatter, dtype=torch.float32, device=device)\n",
    "#     gpu_mem()\n",
    "    \n",
    "#     # For filtersA\n",
    "#     _, eigvecs = torch.lobpcg(tangent_between_scatter, B=sum, k=k, largest=True)\n",
    "#     del sum, tangent_between_scatter\n",
    "#     torch.cuda.empty_cache()\n",
    "#     gpu_mem()\n",
    "#     eigvecs_array = eigvecs.clone().cpu().numpy()\n",
    "#     filters = untangent_space(eigvecs_array.T, Frechet_Mean)\n",
    "#     fkt_riem_eigs, filters, filtersA, filtersB = FKT(filters[0,:,:], Frechet_Mean, mean=metric, average=False, visualize=visualize)\n",
    "\n",
    "#     return fkt_riem_eigs, filters, filtersA, filtersB\n",
    "\n",
    "\n",
    "def tangent_haufe(data, filters, method=\"basic\", alpha=1, beta=0, l1_ratio=0.5, lambda1=.01, lambda2=.01):\n",
    "    S = (data @ filters)\n",
    "    \n",
    "    if method == \"basic\":\n",
    "        proj = (np.linalg.pinv(S)@ data)\n",
    "    elif method == \"covs\":\n",
    "        cov_est_scm = Covariances(estimator='scm')\n",
    "        s_cov = cov_est_scm.transform(S.T[np.newaxis,:,:])[0,:,:]\n",
    "        data_cov = cov_est_scm.transform(data.T[np.newaxis,:,:])[0,:,:]\n",
    "        proj = (data_cov @ filters @ np.linalg.inv(s_cov)).T\n",
    "    elif method == \"linreg\":\n",
    "        reg = LinearRegression()\n",
    "        reg.fit(S, data)\n",
    "        proj = reg.coef_.T\n",
    "    elif method == \"grouplassolinreg\":\n",
    "        reg = MultiTaskLasso(alpha=alpha)  # Using 5-fold cross-validation\n",
    "        reg.fit(S, data)\n",
    "        proj = reg.coef_.T\n",
    "    elif method == \"lassolinreg\":\n",
    "        reg = Lasso(alpha=alpha)  # Using 5-fold cross-validation\n",
    "        reg.fit(S, data)\n",
    "        proj = reg.coef_.T\n",
    "    elif method == \"elasticlinreg\":\n",
    "        reg = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "        reg.fit(S, data)\n",
    "        proj = reg.coef_.T\n",
    "    elif method == \"growl\":\n",
    "        # Proximal Operator for GrOWL targeting columns\n",
    "        def prox_growl(V, lambda1, lambda2, tau):\n",
    "            p, r = V.shape\n",
    "            norms = np.linalg.norm(V, axis=0)  # Norms of columns\n",
    "            indices = np.argsort(-norms)  # Sort indices by descending norms\n",
    "            weights = lambda1 + lambda2 * np.linspace(1, 0, r)  # Weights decrease\n",
    "            V_new = np.zeros_like(V)\n",
    "            for i in range(r):\n",
    "                idx = indices[i]\n",
    "                if norms[idx] > weights[i] * tau:\n",
    "                    V_new[:, idx] = (1 - tau * weights[i] / norms[idx]) * V[:, idx]\n",
    "            return V_new\n",
    "        \n",
    "        # Initialization\n",
    "        B = np.zeros((filters.shape[1], data.shape[1]))\n",
    "        \n",
    "        # Optimization Loop\n",
    "        max_iter = 100\n",
    "        learning_rate = 0.01\n",
    "        for _ in range(max_iter):\n",
    "            gradient = S.T @ (S @ B - data)\n",
    "            B -= learning_rate * gradient\n",
    "            B = prox_growl(B, lambda1, lambda2, tau=learning_rate)\n",
    "            if np.linalg.norm(gradient) < 1e-1:\n",
    "                break\n",
    "        \n",
    "        proj = B.T\n",
    "    \n",
    "    return proj\n",
    "\n",
    "def tangent_CSP(group1_covs=None, group2_covs=None, Frechet_Mean=None,tangent_projected_1=None, tangent_projected_2=None, tangent_calc=True, metric=\"riemann\",k=1, visualize=False):\n",
    "    if tangent_calc:\n",
    "        all_covs = np.concatenate((group1_covs, group2_covs))\n",
    "        Frechet_Mean = mean_covariance(all_covs, metric=metric)\n",
    "        tangent_projected_1 = tangent_space(group1_covs, Frechet_Mean, metric=metric)\n",
    "        tangent_projected_2 = tangent_space(group2_covs, Frechet_Mean, metric=metric)\n",
    "        \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print((\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "    tangent_projected_1_gpu = torch.tensor(tangent_projected_1, dtype=torch.float32, device=device)\n",
    "    cov_tangent_projected_1 = (tangent_projected_1_gpu.T@tangent_projected_1_gpu)/tangent_projected_1_gpu.shape[0]\n",
    "    del tangent_projected_1_gpu\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    tangent_projected_2_gpu = torch.tensor(tangent_projected_2, dtype=torch.float32, device=device)\n",
    "    cov_tangent_projected_2 = (tangent_projected_2_gpu.T@tangent_projected_2_gpu)/tangent_projected_2_gpu.shape[0]\n",
    "    del tangent_projected_2_gpu\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    sum = cov_tangent_projected_1 + cov_tangent_projected_2\n",
    "    \n",
    "    #  Group 1 Filters\n",
    "    _, tangent_eigvecs1 = torch.lobpcg(cov_tangent_projected_1, B=sum, method='ortho', k=k, largest=True)\n",
    "    # Convert tangent eigvecs1 back to NumPy and CPU\n",
    "    tangent_eigvecs1_np = tangent_eigvecs1.cpu().numpy()\n",
    "    del cov_tangent_projected_1, tangent_eigvecs1\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    filters1 = []\n",
    "    for i in range(0,k):\n",
    "        filters_untangent_1_i = untangent_space(tangent_eigvecs1_np.T, Frechet_Mean)[i,:,:]\n",
    "        _, filters_1_i  = eigh(filters_untangent_1_i, Frechet_Mean)\n",
    "        for j in range(0,k):\n",
    "            filters1.append(filters_1_i[:,-j])\n",
    "    filters1 = np.array(filters1).T\n",
    "        \n",
    "    #  Group 2 Filters\n",
    "    _, tangent_eigvecs2 = torch.lobpcg(cov_tangent_projected_2, B=sum,method='ortho', k=k, largest=True)\n",
    "    tangent_eigvecs2_np = tangent_eigvecs2.cpu().numpy()\n",
    "    del sum,cov_tangent_projected_2, tangent_eigvecs2\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    filters2 = []\n",
    "    for i in range(0,k):\n",
    "        filters_untangent_2_i = untangent_space(tangent_eigvecs2_np.T, Frechet_Mean)[i,:,:]\n",
    "        _, filters_2_i  = eigh(filters_untangent_2_i, Frechet_Mean)\n",
    "        for j in range(0,k):\n",
    "            filters2.append(filters_2_i[:,-j])\n",
    "    filters2 = np.array(filters2).T\n",
    "\n",
    "    filters = np.concatenate((filters2[:, ::-1], filters1), axis=1)\n",
    "    print(filters.shape, filters1.shape, filters2.shape)\n",
    "    return None, filters, filters1, filters2\n",
    " \n",
    "def FKT(groupA_cov_matrices, groupB_cov_matrices, mean=\"riemann\", average=True, visualize=True, n=0):\n",
    "    # Eigenvalues in ascending order from scipy eigh https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.eigh.html\n",
    "    if average:\n",
    "        groupA_cov = mean_covariance(groupA_cov_matrices, metric=mean)\n",
    "        groupB_cov = mean_covariance(groupB_cov_matrices, metric=mean)    \n",
    "        # eigs, filters  = eigh(groupA_cov, groupA_cov + groupB_cov + gamma*np.identity(groupB_cov.shape[0]),eigvals_only=False)\n",
    "    else:\n",
    "        groupA_cov = groupA_cov_matrices\n",
    "        groupB_cov = groupB_cov_matrices\n",
    "    if n > 0:\n",
    "        eigsA, filtersA  = eigh(groupA_cov, groupA_cov + groupB_cov,eigvals_only=False,subset_by_index=[groupA_cov.shape[0]-n, groupA_cov.shape[0]-1])\n",
    "        eigsB, filtersB = eigh(groupB_cov, groupA_cov + groupB_cov,eigvals_only=False,subset_by_index=[groupB_cov.shape[0]-n, groupB_cov.shape[0]-1])\n",
    "    else:\n",
    "        eigsA, filtersA  = eigh(groupA_cov, groupA_cov + groupB_cov,eigvals_only=False,subset_by_value=[0.5,np.inf])\n",
    "        eigsB, filtersB = eigh(groupB_cov, groupA_cov + groupB_cov,eigvals_only=False,subset_by_value=[0.5,np.inf])\n",
    "       \n",
    "    eigs = np.concatenate((eigsB[::-1], eigsA))\n",
    "    filters = np.concatenate((filtersB[:, ::-1], filtersA), axis=1)\n",
    "    fkt_riem_eigs = np.abs(np.log(eigs/(1-eigs)))**2\n",
    "    \n",
    "    if visualize:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.scatter(range(0,fkt_riem_eigs.shape[0]),fkt_riem_eigs)\n",
    "        plt.show()\n",
    "    return fkt_riem_eigs, filters, filtersA, filtersB\n",
    "\n",
    "def tangent_classifier(group1_covs=None, group2_covs=None, Frechet_Mean=None, tangent_projected_1=None, tangent_projected_2=None, TSVM=True, TLDA=False, tangent_calc=True,metric=\"riemann\",visualize=False,n=0):\n",
    "    if tangent_calc:\n",
    "        all_covs = np.concatenate((group1_covs, group2_covs))\n",
    "        Frechet_Mean = mean_covariance(all_covs, metric=metric)\n",
    "        tangent_projected_1 = tangent_space(group1_covs, Frechet_Mean, metric=metric)\n",
    "        tangent_projected_2 = tangent_space(group2_covs, Frechet_Mean, metric=metric)\n",
    "    # Create labels for each group\n",
    "    labels_1 = np.ones(len(tangent_projected_1))  # Labels for group 1\n",
    "    labels_2 = np.zeros(len(tangent_projected_2))   # Labels for group 2\n",
    "\n",
    "    data = np.concatenate((tangent_projected_1, tangent_projected_2))\n",
    "    data = preprocess(data)\n",
    "    labels = np.concatenate((labels_1, labels_2))\n",
    "\n",
    "    if TSVM:\n",
    "        # Create SVM classifier (adjust kernel and parameters as needed)\n",
    "        # C_values = [0.001, 0.01, 0.1, 1, 10]\n",
    "        clf = LinearSVC(penalty='l1',loss='squared_hinge',dual=False,C=1,class_weight='balanced')\n",
    "        # clf =  LogisticRegression(class_weight='balanced')\n",
    "        # clf = LinearSVC(penalty='l2',loss='hinge',C=.01,class_weight='balanced')\n",
    "        # clf = LogisticRegression(penalty='elasticnet',C=1,solver='saga',l1_ratio=0.1)\n",
    "        # clf = SVC(kernel='linear', C=1, class_weight='balanced')  \n",
    "        # clf = LogisticRegression()\n",
    "\n",
    "        # Train the classifier\n",
    "        clf.fit(data, labels)\n",
    "        # coef = clf.coef_\n",
    "        # coef = normalize(clf.coef_, axis=1)\n",
    "        coef = tangent_haufe(data, clf.coef_.T,method=\"basic\")\n",
    "        filters_SVM = untangent_space(coef, Frechet_Mean)[0,:,:]\n",
    "        fkt_riem_eigs_tangent_SVM, fkt_filters_tangent_SVM  = eigh(filters_SVM, Frechet_Mean)\n",
    "        \n",
    "        # If test data is provided, project the test data to tangent space\n",
    "        # tangent_projected_1_discrim_reconstruction = np.mean(tangent_projected_1@np.linalg.pinv(clf.coef_)@clf.coef_,axis=0)\n",
    "        # print(tangent_projected_1_discrim_reconstruction.shape)\n",
    "        # tangent_projected_2_discrim_reconstruction = np.mean(tangent_projected_2@np.linalg.pinv(clf.coef_)@clf.coef_,axis=0)\n",
    "        # print(tangent_projected_2_discrim_reconstruction.shape)\n",
    "        # group1_discrim_mean = untangent_space(tangent_projected_1_discrim_reconstruction, Frechet_Mean)\n",
    "        # print(group1_discrim_mean.shape)\n",
    "        # group2_discrim_mean = untangent_space(tangent_projected_2_discrim_reconstruction, Frechet_Mean)\n",
    "        # print(group2_discrim_mean.shape)\n",
    "        # fkt_riem_eigs_tangent_SVM, fkt_filters_tangent_SVM, filtersA, filtersB = FKT(group1_discrim_mean, group2_discrim_mean, mean=metric, average=False, visualize=visualize, n=n)\n",
    "\n",
    "\n",
    "        # Return accuracy along with filters\n",
    "        # fkt_riem_eigs_tangent_SVM, fkt_filters_tangent_SVM, filtersA, filtersB = FKT(filters_SVM[0, :, :], Frechet_Mean, mean=metric, average=False, visualize=visualize, n=n)\n",
    "        # eigs1, filters1  = eigh(filters_SVM, mean_covariance(group2_covs, metric=metric) ,eigvals_only=False,subset_by_value=[0.5,np.inf])\n",
    "        # eigs2, filters2 = eigh(filters_SVM, mean_covariance(group1_covs, metric=metric) ,eigvals_only=False,subset_by_value=[0.5,np.inf])\n",
    "        # eigs = np.concatenate((eigs2[::-1], eigs1))\n",
    "        # fkt_filters_tangent_SVM = np.concatenate((filters2[:, ::-1], filters1), axis=1)\n",
    "        # fkt_riem_eigs_tangent_SVM = np.abs(np.log(eigs))**2\n",
    "        if visualize:\n",
    "            plt.scatter(range(0,fkt_riem_eigs_tangent_SVM.shape[0]),np.abs(np.log(fkt_riem_eigs_tangent_SVM)))\n",
    "            plt.show()\n",
    "\n",
    "        return fkt_riem_eigs_tangent_SVM, fkt_filters_tangent_SVM, _, _\n",
    "\n",
    "    if TLDA:\n",
    "        # Create LDA classifier\n",
    "        lda = LDA()\n",
    "        # Train the classifier\n",
    "        lda.fit(data, labels)\n",
    "        # Get the coefficients from LDA\n",
    "        normalized_coef = normalize(lda.coef_, axis=1)\n",
    "        filters_LDA = untangent_space(normalized_coef, Frechet_Mean)\n",
    "        fkt_filters_tangent_LDA, fkt_riem_eigs_tangent_LDA, filtersA, filtersB = FKT(filters_LDA[0,:,:], Frechet_Mean, mean=metric, average=False, visualize=visualize,n=n)\n",
    "        return fkt_filters_tangent_LDA, fkt_riem_eigs_tangent_LDA, filtersA, filtersB\n",
    "    \n",
    "def tangent_classifier_multi(group1_covs=None, group2_covs=None, Frechet_Mean=None, tangent_projected_1=None, tangent_projected_2=None, TSVM=True, TLDA=False, tangent_calc=True,metric=\"riemann\",visualize=False,k=1):\n",
    "    if tangent_calc:\n",
    "        all_covs = np.concatenate((group1_covs, group2_covs))\n",
    "        Frechet_Mean = mean_covariance(all_covs, metric=metric)\n",
    "        tangent_projected_1 = tangent_space(group1_covs, Frechet_Mean, metric=metric)\n",
    "        tangent_projected_2 = tangent_space(group2_covs, Frechet_Mean, metric=metric)\n",
    "    # Create labels for each group\n",
    "    labels_1 = np.ones(len(tangent_projected_1))  # Labels for group 1\n",
    "    labels_2 = np.zeros(len(tangent_projected_2))   # Labels for group 2\n",
    "\n",
    "    data = np.concatenate((tangent_projected_1, tangent_projected_2))\n",
    "    labels = np.concatenate((labels_1, labels_2))\n",
    "    tan_vecs = None\n",
    "    for i in range(k):\n",
    "        clf = SVC(kernel='linear', C=1, class_weight='balanced')\n",
    "        # Collect classifier coefficients (clf.coef_ for linear SVM)\n",
    "        if i == 0:\n",
    "            clf.fit(data, labels)\n",
    "            tan_vecs = clf.coef_\n",
    "        else:\n",
    "            residual_proj = data - (data@np.linalg.pinv(tan_vecs))@tan_vecs\n",
    "            clf.fit(residual_proj, labels)\n",
    "            tan_vecs = np.concatenate((tan_vecs, clf.coef_), axis=0)  # Concatenate along the row axis\n",
    "        tan_vecs = np.array(tan_vecs)\n",
    "    \n",
    "    untan_vecs =  untangent_space(tan_vecs, Frechet_Mean)\n",
    "    filters1 = []\n",
    "    filters2 = []\n",
    "    for i in range(0,k):\n",
    "        _, filters_iter  = eigh(untan_vecs[i,:,:], Frechet_Mean)\n",
    "        filters1.append(filters_iter[:,-1:])\n",
    "        filters2.append(filters_iter[:,0:1])\n",
    "    # filters1 = np.array(filters1).T\n",
    "    # filters2 = np.array(filters2).T\n",
    "    \n",
    "    # Convert lists to NumPy arrays for proper shape handling and transpose if needed\n",
    "    filters1 = np.hstack(filters1)  # Stack horizontally\n",
    "    filters2 = np.hstack(filters2)  # Stack horizontally\n",
    "\n",
    "    print(\"Filters1 shape (largest eigenvectors):\", filters1.shape)\n",
    "    print(\"Filters2 shape (smallest eigenvectors):\", filters2.shape)\n",
    "\n",
    "    filters = np.concatenate((filters2, filters1[:, ::-1]), axis=1)\n",
    "\n",
    "    return None, filters, filters1, filters2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_generation(group1_train,group1_test, group2_train, group2_test, filters,method='log-var',metric='riemann'):\n",
    "    group1_train_transformed = group1_train @ filters\n",
    "    group2_train_transformed = group2_train @ filters\n",
    "    group1_test_transformed = group1_test @ filters\n",
    "    group2_test_transformed = group2_test @ filters\n",
    "\n",
    "    if method == 'log-var':\n",
    "        train_1 = np.log(np.var(group1_train_transformed, axis=1))\n",
    "        train_2 = np.log(np.var(group2_train_transformed, axis=1))\n",
    "        test_1 = np.log(np.var(group1_test_transformed, axis=1))\n",
    "        test_2 = np.log(np.var(group2_test_transformed, axis=1))\n",
    "    \n",
    "    elif method == 'log-cov':\n",
    "        cov_est = Covariances(estimator='lwf')\n",
    "        train_1_cov = cov_est.transform(np.transpose(group1_train_transformed, (0, 2, 1)))\n",
    "        train_2_cov = cov_est.transform(np.transpose(group2_train_transformed, (0, 2, 1)))\n",
    "        test_1_cov = cov_est.transform(np.transpose(group1_test_transformed, (0, 2, 1)))\n",
    "        test_2_cov = cov_est.transform(np.transpose(group2_test_transformed, (0, 2, 1)))\n",
    "        train_1, train_2, test_1, test_2 = tangent_transform(train_1_cov, test_1_cov, train_2_cov, test_2_cov, metric)\n",
    "    \n",
    "    return train_1, test_1, train_2, test_2\n",
    "\n",
    "\n",
    "def validate_parcellated_filters(groupA_parcellated_array, groupB_parcellated_array, metric='riemann',method='log-var',n_splits=10,filters_per_group=1,Tangent_Class=True):\n",
    "    cov_est = Covariances(estimator='oas')\n",
    "    groupA_parcellated_covs = cov_est.transform(np.transpose(groupA_parcellated_array, (0, 2, 1)))\n",
    "    groupB_parcellated_covs = cov_est.transform(np.transpose(groupB_parcellated_array, (0, 2, 1)))\n",
    "\n",
    "    covs = np.concatenate((groupA_parcellated_covs, groupB_parcellated_covs))\n",
    "    data = np.concatenate((groupA_parcellated_array, groupB_parcellated_array))\n",
    "    labels = np.concatenate((np.ones(len(groupA_parcellated_covs)), np.zeros(len(groupB_parcellated_covs))))\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    metrics_dict = {}\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(data, labels)):\n",
    "        print(f\"\\nProcessing Fold {fold + 1}/{n_splits}\")\n",
    "        data_train, data_test = data[train_index], data[test_index]\n",
    "        covs_train, covs_test = covs[train_index], covs[test_index]\n",
    "        labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        data1_train = data_train[labels_train == 1]\n",
    "        data2_train = data_train[labels_train == 0]\n",
    "        data1_test = data_test[labels_test == 1]\n",
    "        data2_test = data_test[labels_test == 0]\n",
    "\n",
    "        cov1_train = covs_train[labels_train == 1]\n",
    "        cov2_train = covs_train[labels_train == 0]\n",
    "\n",
    "        if Tangent_Class:\n",
    "            _, filters, _, _ = tangent_classifier(cov1_train,  cov2_train, TSVM=True, TLDA=False, tangent_calc=True, metric=metric,visualize=False,n=0)\n",
    "        else:\n",
    "            _, filters, _, _ = FKT(cov1_train, cov2_train, mean=metric, average=True, visualize=False, n=0)\n",
    "\n",
    "        selected_filters = np.concatenate((filters[:, :filters_per_group], filters[:, -filters_per_group:]), axis=1)\n",
    "\n",
    "        train_1, test_1, train_2, test_2 = feature_generation(data1_train, data1_test, data2_train, data2_test, selected_filters,method=method,metric=metric)\n",
    "        fold_metrics = test_classifiers(train_1, test_1, train_2, test_2, sample_weights_train=None)\n",
    "        \n",
    "        if fold == 0:\n",
    "            for clf_name in fold_metrics.keys():\n",
    "                metrics_dict[clf_name] = {\n",
    "                    'correct_predictions': 0,\n",
    "                    'total_predictions': 0,\n",
    "                    'accuracies': [],\n",
    "                    'per_class_correct': np.array([0, 0]),\n",
    "                    'per_class_total': np.array([0, 0])\n",
    "                }\n",
    "\n",
    "        # Aggregate metrics\n",
    "        for clf_name, metrics in fold_metrics.items():\n",
    "            # Update total correct predictions and total samples\n",
    "            metrics_dict[clf_name]['correct_predictions'] += metrics['correct_predictions']\n",
    "            metrics_dict[clf_name]['total_predictions'] += metrics['total_predictions']\n",
    "            # Store accuracies for mean and std calculation\n",
    "            metrics_dict[clf_name]['accuracies'].append(metrics['accuracy'])\n",
    "            # Update per-class correct and total counts\n",
    "            metrics_dict[clf_name]['per_class_correct'] += metrics['per_class_correct']\n",
    "            metrics_dict[clf_name]['per_class_total'] += metrics['per_class_total']\n",
    "\n",
    "            # Print per-fold metrics\n",
    "            print(f\"Classifier: {clf_name}\")\n",
    "            print(f\"  Fold Accuracy: {metrics['accuracy'] * 100:.2f}%\")\n",
    "            print(f\"  Correct Predictions: {metrics['correct_predictions']}/{metrics['total_predictions']}\")\n",
    "            print(f\"  Per-Class Accuracy: {metrics['per_class_accuracy'] * 100}\")\n",
    "\n",
    "    # After all folds, compute overall metrics\n",
    "    print(\"\\nOverall Metrics Across All Folds:\")\n",
    "    for clf_name, clf_metrics in metrics_dict.items():\n",
    "        overall_accuracy = clf_metrics['correct_predictions'] / clf_metrics['total_predictions']\n",
    "        mean_accuracy = np.mean(clf_metrics['accuracies'])\n",
    "        std_accuracy = np.std(clf_metrics['accuracies'])\n",
    "        per_class_accuracy = clf_metrics['per_class_correct'] / clf_metrics['per_class_total']\n",
    "\n",
    "        print(f\"\\nClassifier: {clf_name}\")\n",
    "        print(f\"  Total Accuracy: {overall_accuracy * 100:.2f}%\")\n",
    "        print(f\"  Average Fold Accuracy: {mean_accuracy * 100:.2f}%\")\n",
    "        print(f\"  Fold Accuracy Std Dev: {std_accuracy * 100:.2f}%\")\n",
    "        print(f\"  Per-Class Accuracy: {per_class_accuracy * 100}\")\n",
    "\n",
    "    return metrics_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_cross_val_log_var = validate_parcellated_filters(groupA_parcellated_array, groupB_parcellated_array, metric=metric,method='log-var',n_splits=10,filters_per_group=3,Tangent_Class=Tangent_Class)\n",
    "save_text_results(f\"Parcellated Log Var Filter Classification Accuracy Results: {filters_cross_val_log_var}\")\n",
    "filters_cross_val_log_cov = validate_parcellated_filters(groupA_parcellated_array, groupB_parcellated_array, metric=metric,method='log-cov',n_splits=10,filters_per_group=3,Tangent_Class=Tangent_Class)\n",
    "save_text_results(f\"Parcellated Log Cov Filter Classification Accuracy Results: {filters_cross_val_log_cov}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.svm import LinearSVR\n",
    "from sklearn.linear_model import LassoCV, LinearRegression, Lasso, Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "def tangent_haufe(data, filters, method=\"basic\", alpha=1, beta=0, l1_ratio=0.5, lambda1=.01, lambda2=.01):\n",
    "    S = (data @ filters)\n",
    "    \n",
    "    if method == \"basic\":\n",
    "        proj = (np.linalg.pinv(S)@ data)\n",
    "    elif method == \"covs\":\n",
    "        cov_est_scm = Covariances(estimator='scm')\n",
    "        s_cov = cov_est_scm.transform(S.T[np.newaxis,:,:])[0,:,:]\n",
    "        data_cov = cov_est_scm.transform(data.T[np.newaxis,:,:])[0,:,:]\n",
    "        proj = (data_cov @ filters @ np.linalg.inv(s_cov)).T\n",
    "    elif method == \"linreg\":\n",
    "        reg = LinearRegression()\n",
    "        reg.fit(S, data)\n",
    "        proj = reg.coef_.T\n",
    "    elif method == \"grouplassolinreg\":\n",
    "        reg = MultiTaskLasso(alpha=alpha)  # Using 5-fold cross-validation\n",
    "        reg.fit(S, data)\n",
    "        proj = reg.coef_.T\n",
    "    elif method == \"lassolinreg\":\n",
    "        reg = Lasso(alpha=alpha)  # Using 5-fold cross-validation\n",
    "        reg.fit(S, data)\n",
    "        proj = reg.coef_.T\n",
    "    elif method == \"elasticlinreg\":\n",
    "        reg = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "        reg.fit(S, data)\n",
    "        proj = reg.coef_.T\n",
    "    elif method == \"growl\":\n",
    "        # Proximal Operator for GrOWL targeting columns\n",
    "        def prox_growl(V, lambda1, lambda2, tau):\n",
    "            p, r = V.shape\n",
    "            norms = np.linalg.norm(V, axis=0)  # Norms of columns\n",
    "            indices = np.argsort(-norms)  # Sort indices by descending norms\n",
    "            weights = lambda1 + lambda2 * np.linspace(1, 0, r)  # Weights decrease\n",
    "            V_new = np.zeros_like(V)\n",
    "            for i in range(r):\n",
    "                idx = indices[i]\n",
    "                if norms[idx] > weights[i] * tau:\n",
    "                    V_new[:, idx] = (1 - tau * weights[i] / norms[idx]) * V[:, idx]\n",
    "            return V_new\n",
    "        \n",
    "        # Initialization\n",
    "        B = np.zeros((filters.shape[1], data.shape[1]))\n",
    "        \n",
    "        # Optimization Loop\n",
    "        max_iter = 100\n",
    "        learning_rate = 0.01\n",
    "        for _ in range(max_iter):\n",
    "            gradient = S.T @ (S @ B - data)\n",
    "            B -= learning_rate * gradient\n",
    "            B = prox_growl(B, lambda1, lambda2, tau=learning_rate)\n",
    "            if np.linalg.norm(gradient) < 1e-1:\n",
    "                break\n",
    "        \n",
    "        proj = B.T\n",
    "    \n",
    "    return proj\n",
    "\n",
    "# Combine group A and B data and paths\n",
    "def combine_groups(groupA_parcellated_array, groupB_parcellated_array, groupA_paths_filtered, groupB_paths_filtered):\n",
    "    # Combine data arrays\n",
    "    combined_data = np.concatenate((groupA_parcellated_array, groupB_parcellated_array), axis=0)\n",
    "\n",
    "    # Combine paths arrays\n",
    "    combined_paths = np.concatenate((groupA_paths_filtered, groupB_paths_filtered), axis=0)\n",
    "\n",
    "    return combined_data, combined_paths\n",
    "\n",
    "# Extract subject IDs from the combined paths\n",
    "def extract_subject_ids(combined_paths):\n",
    "    subject_ids = np.array([re.search(r'/(\\d+)/', path[0]).group(1) for path in combined_paths])\n",
    "    return np.array(subject_ids)\n",
    "\n",
    "def extract_phenotype(subids,phenotype):\n",
    "    file_path_restricted = '../HCP/RESTRICTED_zainsou_8_6_2024_2_11_21.csv'\n",
    "    file_path_unrestricted = '../HCP/unrestricted_zainsou_8_2_2024_6_13_22.csv'\n",
    "\n",
    "    try:\n",
    "        data_r = pd.read_csv(file_path_restricted)\n",
    "        data_ur = pd.read_csv(file_path_unrestricted)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path_restricted} or {file_path_unrestricted}\")\n",
    "        raise\n",
    "\n",
    "    # Combine restricted and unrestricted data on Subject ID\n",
    "    data = pd.merge(data_r, data_ur, on='Subject', how='outer')\n",
    "\n",
    "    # Convert Subject IDs to string for consistency\n",
    "    data['Subject'] = data['Subject'].astype(str)\n",
    "    subids = subids.astype(str)\n",
    "\n",
    "    # Filter data for training subjects\n",
    "    train_data = data[data['Subject'].isin(subids)]\n",
    "    # Ensure the order matches the training data\n",
    "    train_data = train_data.set_index('Subject').loc[subids].reset_index()\n",
    "    pheno_score = train_data[phenotype]\n",
    "    return pheno_score\n",
    "\n",
    "# Regress out age from predictors\n",
    "def regress_out_age(predictor, age):\n",
    "    reg = Ridge(alpha=1)\n",
    "    # reg = LinearRegression()\n",
    "\n",
    "    reg.fit(age.reshape(-1, 1), predictor)  # Age is the independent variable\n",
    "\n",
    "    # reg = LinearSVR(C=1,fit_intercept=False)\n",
    "    # reg.fit(predictor, age)  # Age is the independent variable\n",
    "\n",
    "    return reg\n",
    "\n",
    "def preproc(train, test,method=\"zscore\"):\n",
    "    if method == \"zscore\":\n",
    "        scaler = StandardScaler()\n",
    "        train_zscore = scaler.fit_transform(train)\n",
    "        test_zscore = scaler.transform(test)\n",
    "    else:\n",
    "        mean = train.mean(axis=0)\n",
    "        train_zscore = train - mean\n",
    "        test_zscore = test - mean\n",
    "    return train_zscore, test_zscore \n",
    "\n",
    "# Helper function to plot regression results\n",
    "def plot_predictions(true_values, predicted_values, title, train_or_test):\n",
    "    plt.scatter(true_values, predicted_values, label=f'{train_or_test} Predictions', color='blue', alpha=0.6)\n",
    "    \n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Helper function to plot residuals vs true values\n",
    "def plot_residuals(true_values, predicted_values, title, train_or_test):\n",
    "    residuals = true_values - predicted_values\n",
    "    plt.scatter(true_values, residuals, label=f'{train_or_test} Residuals', color='red', alpha=0.6)\n",
    "    plt.axhline(y=0, color='black', linestyle='--')  # Add a horizontal line at y=0 for reference\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Tangent space regression with centering\n",
    "def tan_regression(data, values, age, metric=\"riemann\", pre=\"znorm\", n_splits=5):\n",
    "    # Binning the continuous target variable for stratified splits\n",
    "    n_bins = 10  # Adjust this based on your target distribution\n",
    "    binner = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='uniform')\n",
    "    values_binned = binner.fit_transform(values.reshape(-1, 1))\n",
    "\n",
    "    cov_est = Covariances(estimator='lwf')\n",
    "    # cov_est = Covariances(estimator='corr')\n",
    "    covs = cov_est.transform(np.transpose(data, (0, 2, 1)))\n",
    "    \n",
    "    # Initialize Stratified K-Fold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=10)\n",
    "    \n",
    "    fold_scores = []\n",
    "    fold_corrs = []\n",
    "    filter_fold_scores = []\n",
    "    filter_fold_corrs = []\n",
    "\n",
    "    count = 0\n",
    "    # Perform Stratified K-Fold Cross-Validation\n",
    "    for train_index, test_index in kf.split(data, values_binned):\n",
    "        print(\"Fold\", count)\n",
    "        count += 1\n",
    "        train, test = data[train_index], data[test_index]\n",
    "\n",
    "        values_train, values_test = values[train_index], values[test_index]\n",
    "        values_train, values_test = preproc(values_train[:,np.newaxis],values_test[:,np.newaxis], method=\"center\")\n",
    "        values_train = values_train[:,0]\n",
    "        values_test = values_test[:,0]\n",
    "\n",
    "        # Plot the histogram of training data and calculated weights\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        # Plot histogram of training target values\n",
    "        plt.hist(values_train, bins=n_bins, alpha=0.7, color='blue', edgecolor='black', label='Train Data')\n",
    "        plt.title(f'Train Data Histogram and Weights - Fold {count}')\n",
    "        plt.xlabel('Target Value')\n",
    "        plt.ylabel('Frequency / Weight')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        age_train, age_test = age[train_index], age[test_index]\n",
    "        age_train, age_test = preproc(age_train[:,np.newaxis], age_test[:,np.newaxis], method=\"center\")\n",
    "        age_train = age_train[:,0]\n",
    "        age_test = age_test[:,0]\n",
    "\n",
    "\n",
    "        train_covs, test_covs = covs[train_index], covs[test_index]\n",
    "        train_mean = mean_covariance(train_covs, metric=metric)\n",
    "        tan_train = tangent_space(train_covs,train_mean,metric=metric)\n",
    "        tan_test = tangent_space(test_covs,train_mean,metric=metric)\n",
    "\n",
    "        if pre == \"center\":\n",
    "            # Mean center the tangent space data\n",
    "            tan_mean = np.mean(tan_train, axis=0)\n",
    "            tan_train_centered = tan_train - tan_mean\n",
    "            tan_test_centered = tan_test - tan_mean\n",
    "        elif pre == \"znorm\":\n",
    "            tan_train_centered,  tan_test_centered = preproc(tan_train,tan_test)\n",
    "        else:\n",
    "            tan_train_centered = tan_train\n",
    "            tan_test_centered = tan_test\n",
    "\n",
    "\n",
    "        # Regress out age using only the training data\n",
    "        age_reg = regress_out_age(tan_train_centered, age_train)\n",
    "        # tan_train_centered = tan_train_centered - (tan_train_centered@np.linalg.pinv(age_reg.coef_[np.newaxis,:]))@age_reg.coef_[np.newaxis,:]\n",
    "        # tan_test_centered = tan_test_centered - (tan_test_centered@np.linalg.pinv(age_reg.coef_[np.newaxis,:]))@age_reg.coef_[np.newaxis,:]\n",
    "        tan_train_centered = tan_train_centered - age_reg.predict(age_train.reshape(-1, 1))\n",
    "        tan_test_centered = tan_test_centered - age_reg.predict(age_test.reshape(-1, 1))\n",
    "\n",
    "        # Choose the regression model\n",
    "        # reg_model = LinearSVR(C=1,fit_intercept=False)\n",
    "        # reg_model = LinearSVR(C=1)\n",
    "        # reg_model = Lasso(alpha=0.001,fit_intercept=False)\n",
    "        reg_model = Ridge(alpha=1)\n",
    "        # reg_model = LinearRegression(fit_intercept=False)\n",
    "        # reg_model = LassoCV(cv=5)  # Use 5-fold cross-validation within each fold to tune Lasso\n",
    "        reg_model.fit(tan_train_centered, values_train)\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        test_score = reg_model.score(tan_test_centered, values_test)\n",
    "        predictions = reg_model.predict(tan_test_centered)\n",
    "        fold_corr, _ = pearsonr(values_test, predictions)\n",
    "        fold_scores.append(test_score)\n",
    "        fold_corrs.append(fold_corr)\n",
    "\n",
    "        print(f\"Fold Test R² Score: {test_score}\")\n",
    "        print(f\"Fold Test R Score: {fold_corr}\")\n",
    "        \n",
    "        # Plot predictions vs true values for test fold\n",
    "        plot_predictions(values_test, predictions,f'Test Predictions vs True Values - Fold R²: {test_score:.2f}', 'Test')\n",
    "        # Now plot for train fold\n",
    "        predictions_train = reg_model.predict(tan_train_centered)\n",
    "        plot_predictions(values_train, predictions_train, f'Train Predictions vs True Values - Fold R²: {test_score:.2f}', 'Train')\n",
    "         # Plot residuals vs true values for test fold\n",
    "        plot_residuals(values_test, predictions, f'Test Residuals vs True Values - Fold R²: {test_score:.2f}', 'Test')\n",
    "\n",
    "        # Plot residuals vs true values for train fold\n",
    "        plot_residuals(values_train, predictions_train, f'Train Residuals vs True Values - Fold R²: {test_score:.2f}', 'Train')\n",
    "\n",
    "        # (tan_train@np.linalg.pinv(reg_model.coef_))@reg_model.coef_\n",
    "        # hauf_coef = FKT_proj(tan_train,reg_model.coef_[:,np.newaxis],method=\"basic\")\n",
    "        # hauf_coef = FKT_proj(tan_train,reg_model.coef_[:,np.newaxis],method=\"covs\")\n",
    "        hauf_coef = FKT_proj(tan_train_centered,reg_model.coef_[:,np.newaxis],method=\"linreg\")\n",
    "\n",
    "        weights_matrix = untangent_space(hauf_coef.T[:,0],train_mean,metric=metric)\n",
    "        # weights_matrix = untangent_space(reg_model.coef_,train_mean,metric=metric)\n",
    "        eigs, filters_all = eigh(weights_matrix,train_mean)\n",
    "        # plt.scatter(range(0,eigs.shape[0]),np.abs(eigs))\n",
    "        # plt.show()\n",
    "        inds = np.argsort(np.abs(eigs))[-4:]\n",
    "        filters = filters_all[:,inds]\n",
    "\n",
    "        train_transformed = train @ filters\n",
    "        test_transformed = test @ filters\n",
    "\n",
    "        train_transformed_cov = cov_est.transform(np.transpose(train_transformed, (0, 2, 1)))\n",
    "        test_transformed_cov = cov_est.transform(np.transpose(test_transformed, (0, 2, 1)))\n",
    "\n",
    "        reduced_mean = mean_covariance(train_transformed_cov, metric=metric)\n",
    "        tangent_transform_train = tangent_space(train_transformed_cov, reduced_mean, metric=metric)\n",
    "        tangent_transform_test = tangent_space(test_transformed_cov, reduced_mean, metric=metric)\n",
    "        \n",
    "        if pre == \"center\":\n",
    "            tangent_transform_mean = np.mean(tangent_transform_train, axis=0)\n",
    "            tangent_transform_train_centered = tangent_transform_train - tangent_transform_mean\n",
    "            tangent_transform_test_centered = tangent_transform_test - tangent_transform_mean\n",
    "        elif pre == \"znorm\":\n",
    "            tangent_transform_train_centered, tangent_transform_test_centered = preproc(tangent_transform_train,tangent_transform_test)\n",
    "        else:\n",
    "            tangent_transform_train_centered = tangent_transform_train\n",
    "            tangent_transform_test_centered = tangent_transform_test\n",
    "\n",
    "        # Regress out age using only the training data\n",
    "        age_reg_transformed = regress_out_age(tangent_transform_train_centered, age_train)\n",
    "        # tangent_transform_train_centered = tangent_transform_train_centered - (tangent_transform_train_centered@np.linalg.pinv(age_reg_transformed.coef_[np.newaxis,:]))@age_reg_transformed.coef_[np.newaxis,:]\n",
    "        # tangent_transform_test_centered = tangent_transform_test_centered - (tangent_transform_test_centered@np.linalg.pinv(age_reg_transformed.coef_[np.newaxis,:]))@age_reg_transformed.coef_[np.newaxis,:]\n",
    "        tangent_transform_train_centered = tangent_transform_train_centered - age_reg_transformed.predict(age_train.reshape(-1, 1))\n",
    "        tangent_transform_test_centered = tangent_transform_test_centered - age_reg_transformed.predict(age_test.reshape(-1, 1))\n",
    "\n",
    "        # reg_model_reduced = LinearSVR(C=1,fit_intercept=False)\n",
    "        reg_model_reduced = Ridge(alpha=10)\n",
    "        reg_model_reduced.fit(tangent_transform_train_centered, values_train)\n",
    "        \n",
    "        test_score_reduced = reg_model_reduced.score(tangent_transform_test_centered, values_test)\n",
    "        predictions_reduced = reg_model_reduced.predict(tangent_transform_test_centered)\n",
    "        test_corr_reduced, _ = pearsonr(values_test, predictions_reduced)\n",
    "        filter_fold_scores.append(test_score_reduced)\n",
    "        filter_fold_corrs.append(test_corr_reduced)\n",
    "\n",
    "        print(f\"Fold Reduced Test R² Score: {test_score_reduced}\")\n",
    "        print(f\"Fold Reduced Test R Score: {test_corr_reduced}\")\n",
    "        # Plot for filter fold\n",
    "        # Plot for filter fold\n",
    "        plot_predictions(values_test, predictions_reduced, f'Filter Fold Predictions vs True Values - Filter Fold R²: {test_score_reduced:.2f}', 'Filter Test')\n",
    "         # Now plot for train fold\n",
    "        predictions_reduced_train = reg_model_reduced.predict(tangent_transform_train_centered)\n",
    "        plot_predictions(values_train, predictions_reduced_train, f'Train Filter Predictions vs True Values - Fold R²: {test_score:.2f}', 'Filter Train')\n",
    "        # Plot residuals vs true values for test fold\n",
    "        plot_residuals(values_test, predictions_reduced, f'Test Filter Residuals vs True Values - Fold R²: {test_score:.2f}', 'Test')\n",
    "\n",
    "        # Plot residuals vs true values for train fold\n",
    "        plot_residuals(values_train, predictions_reduced_train, f'Train Filter Residuals vs True Values - Fold R²: {test_score:.2f}', 'Train')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Output the average R² score across all folds\n",
    "    mean_score = np.mean(fold_scores)\n",
    "    mean_corr = np.mean(fold_corrs)\n",
    "\n",
    "    mean_filter_score = np.mean(filter_fold_scores)\n",
    "    mean_filter_corr = np.mean(filter_fold_corrs)\n",
    "\n",
    "    print(f\"Mean R² Score across {n_splits} folds: {mean_score}\")\n",
    "    print(f\"Mean R Score across {n_splits} folds: {mean_corr}\")\n",
    "\n",
    "    print(f\"Mean R² Filter Score across {n_splits} folds: {mean_filter_score}\")\n",
    "    print(f\"Mean R Filter Score across {n_splits} folds: {mean_filter_corr}\")\n",
    "    return mean_score, mean_corr, mean_filter_score, mean_filter_corr, fold_scores, fold_corrs, filter_fold_scores, filter_fold_corrs\n",
    "\n",
    "combined_data, combined_paths = combine_groups(groupA_parcellated_array, groupB_parcellated_array, groupA_paths_filtered, groupB_paths_filtered)\n",
    "subject_ids = extract_subject_ids(combined_paths)\n",
    "scores = np.array(extract_phenotype(subject_ids,phenotype))\n",
    "age = np.array(extract_phenotype(subject_ids, 'Age_in_Yrs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_score, mean_corr, mean_filter_score, mean_filter_corr, fold_scores, fold_corrs, filter_fold_scores, filter_fold_corrs = tan_regression(combined_data,scores,age, metric=metric,pre=\"center\",n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import Parallel, delayed\n",
    "# from sklearn.utils import shuffle\n",
    "\n",
    "# def permutation_test(data, scores, age, metric=\"riemann\", pre=\"znorm\", n_splits=10, n_permutations=1000, n_jobs=1):\n",
    "#     # Lists to store results for all permutations\n",
    "#     perm_mean_scores = []\n",
    "#     perm_mean_corrs = []\n",
    "#     perm_mean_filter_scores = []\n",
    "#     perm_mean_filter_corrs = []\n",
    "    \n",
    "#     perm_fold_scores = []  # To store fold scores for all permutations\n",
    "#     perm_fold_corrs = []\n",
    "#     perm_filter_fold_scores = []\n",
    "#     perm_filter_fold_corrs = []\n",
    "    \n",
    "#     # Function to run one permutation\n",
    "#     def run_permutation(i):\n",
    "#         # Shuffle the scores\n",
    "#         shuffled_scores = shuffle(scores, random_state=i)\n",
    "        \n",
    "#         # Fit the model with shuffled data\n",
    "#         perm_mean_score, perm_mean_corr, perm_mean_filter_score, perm_mean_filter_corr, fold_scores, fold_corrs, filter_fold_scores, filter_fold_corrs = tan_regression(data, shuffled_scores, age, metric, pre, n_splits)\n",
    "        \n",
    "#         # Append the mean results to the lists\n",
    "#         perm_mean_scores.append(perm_mean_score)\n",
    "#         perm_mean_corrs.append(perm_mean_corr)\n",
    "#         perm_mean_filter_scores.append(perm_mean_filter_score)\n",
    "#         perm_mean_filter_corrs.append(perm_mean_filter_corr)\n",
    "        \n",
    "#         # Append the fold-specific results to the lists\n",
    "#         perm_fold_scores.append(fold_scores)\n",
    "#         perm_fold_corrs.append(fold_corrs)\n",
    "#         perm_filter_fold_scores.append(filter_fold_scores)\n",
    "#         perm_filter_fold_corrs.append(filter_fold_corrs)\n",
    "    \n",
    "#     # Run the permutations in parallel\n",
    "#     Parallel(n_jobs=n_jobs)(delayed(run_permutation)(i) for i in range(n_permutations))\n",
    "    \n",
    "#     # Return all the stored results\n",
    "#     return perm_mean_scores, perm_mean_corrs, perm_mean_filter_scores, perm_mean_filter_corrs, perm_fold_scores, perm_fold_corrs, perm_filter_fold_scores, perm_filter_fold_corrs\n",
    "\n",
    "# # Example of running the permutation test\n",
    "# n_permutations = 6  # Set the number of permutations you want\n",
    "# results = permutation_test(combined_data, scores, age, metric=metric, pre=\"center\", n_splits=10, n_permutations=n_permutations, n_jobs=-1)\n",
    "\n",
    "# # Extract individual results\n",
    "# perm_mean_scores, perm_mean_corrs, perm_mean_filter_scores, perm_mean_filter_corrs, perm_fold_scores, perm_fold_corrs, perm_filter_fold_scores, perm_filter_fold_corrs = results\n",
    "\n",
    "# # Save the permutation test results as numpy arrays\n",
    "# save_array_to_outputfolder(\"perm_mean_scores.npy\", np.array(perm_mean_scores))\n",
    "# save_array_to_outputfolder(\"perm_mean_corrs.npy\", np.array(perm_mean_corrs))\n",
    "# save_array_to_outputfolder(\"perm_mean_filter_scores.npy\", np.array(perm_mean_filter_scores))\n",
    "# save_array_to_outputfolder(\"perm_mean_filter_corrs.npy\", np.array(perm_mean_filter_corrs))\n",
    "# save_array_to_outputfolder(\"perm_fold_scores.npy\", np.array(perm_fold_scores))\n",
    "# save_array_to_outputfolder(\"perm_fold_corrs.npy\", np.array(perm_fold_corrs))\n",
    "# save_array_to_outputfolder(\"perm_filter_fold_scores.npy\", np.array(perm_filter_fold_scores))\n",
    "# save_array_to_outputfolder(\"perm_filter_fold_corrs.npy\", np.array(perm_filter_fold_corrs))\n",
    "\n",
    "# print(\"All arrays have been saved to the output folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the arrays\n",
    "perm_mean_scores = load_array_from_outputfolder(\"perm_mean_scores.npy\")\n",
    "perm_mean_corrs = load_array_from_outputfolder(\"perm_mean_corrs.npy\")\n",
    "perm_mean_filter_scores = load_array_from_outputfolder(\"perm_mean_filter_scores.npy\")\n",
    "perm_mean_filter_corrs = load_array_from_outputfolder(\"perm_mean_filter_corrs.npy\")\n",
    "perm_fold_scores = load_array_from_outputfolder(\"perm_fold_scores.npy\")\n",
    "perm_fold_corrs = load_array_from_outputfolder(\"perm_fold_corrs.npy\")\n",
    "perm_filter_fold_scores = load_array_from_outputfolder(\"perm_filter_fold_scores.npy\")\n",
    "perm_filter_fold_corrs = load_array_from_outputfolder(\"perm_filter_fold_corrs.npy\")\n",
    "\n",
    "# Plot the distributions\n",
    "def plot_distribution(data, title, xlabel, ylabel):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(data, bins=30, edgecolor='black', alpha=0.7)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot mean scores distribution\n",
    "plot_distribution(perm_mean_scores, \"Distribution of Permutation Mean Scores\", \"Mean Score\", \"Frequency\")\n",
    "# Plot mean correlations distribution\n",
    "plot_distribution(perm_mean_corrs, \"Distribution of Permutation Mean Correlations\", \"Mean Correlation\", \"Frequency\")\n",
    "# Plot mean filter scores distribution\n",
    "plot_distribution(perm_mean_filter_scores, \"Distribution of Permutation Mean Filter Scores\", \"Mean Filter Score\", \"Frequency\")\n",
    "# Plot mean filter correlations distribution\n",
    "plot_distribution(perm_mean_filter_corrs, \"Distribution of Permutation Mean Filter Correlations\", \"Mean Filter Correlation\", \"Frequency\")\n",
    "\n",
    "print(perm_fold_scores.shape)\n",
    "# Plot mean scores distribution\n",
    "plot_distribution(perm_fold_scores, \"Distribution of Permutation Scores\", \"Score\", \"Frequency\")\n",
    "# Plot mean correlations distribution\n",
    "plot_distribution(perm_fold_corrs, \"Distribution of Permutation Correlations\", \"Correlation\", \"Frequency\")\n",
    "# Plot mean filter scores distribution\n",
    "plot_distribution(perm_filter_fold_scores, \"Distribution of Permutation Filter Scores\", \"Filter Score\", \"Frequency\")\n",
    "# Plot mean filter correlations distribution\n",
    "plot_distribution(perm_filter_fold_corrs, \"Distribution of Permutation Filter Correlations\", \"Filter Correlation\", \"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 1 Fold and Filters for Rest of Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((groupA_parcellated_array, groupB_parcellated_array))\n",
    "labels = np.concatenate((np.ones(len(groupA_parcellated_array)), np.zeros(len(groupB_parcellated_array))))\n",
    "paths = np.concatenate((groupA_paths_filtered, groupB_paths_filtered))\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "splits = list(skf.split(data, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 1\n",
    "fold_outputfolder = f\"fold_{fold}\"\n",
    "if not os.path.exists(os.path.join(outputfolder, f\"fold_{fold}\")):\n",
    "    os.makedirs(os.path.join(outputfolder, f\"fold_{fold}\"))\n",
    "if not os.path.exists(os.path.join(outputfolder, f\"fold_{fold}\", \"results\")):\n",
    "    os.makedirs(os.path.join(outputfolder, f\"fold_{fold}\", \"results\"))\n",
    "\n",
    "train_parcellated, test_parcellated = data[splits[fold][0]], data[splits[fold][1]]\n",
    "train_labels, test_labels = labels[splits[fold][0]], labels[splits[fold][1]]\n",
    "train_paths, test_paths = paths[splits[fold][0]], paths[splits[fold][1]]\n",
    "\n",
    "groupA_train_parcellated = train_parcellated[train_labels == 1]\n",
    "groupA_test_parcellated = test_parcellated[test_labels == 1]\n",
    "groupA_train_paths = train_paths[train_labels == 1]\n",
    "groupA_test_paths = test_paths[test_labels == 1]\n",
    "\n",
    "groupB_train_parcellated = train_parcellated[train_labels == 0]\n",
    "groupB_test_parcellated = test_parcellated[test_labels == 0]\n",
    "groupB_train_paths = train_paths[train_labels == 0]\n",
    "groupB_test_paths = test_paths[test_labels == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pyriemann.readthedocs.io/en/latest/auto_examples/signal/plot_covariance_estimation.html\n",
    "cov_est = Covariances(estimator='lwf')\n",
    "groupA_train_parcellated_covs = cov_est.transform(np.transpose(groupA_train_parcellated, (0, 2, 1)))\n",
    "groupB_train_parcellated_covs = cov_est.transform(np.transpose(groupB_train_parcellated, (0, 2, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Tangent_Class:\n",
    "    fkt_riem_eigs, filters, _, _ =  tangent_classifier(groupA_train_parcellated_covs,  groupB_train_parcellated_covs, TSVM=True, TLDA=False, tangent_calc=True, metric=metric,visualize=True,n=0)\n",
    "else:\n",
    "    fkt_riem_eigs, filters, filtersA, filtersB = FKT(groupA_train_parcellated_covs, groupB_train_parcellated_covs, mean=metric, average=True, visualize=True, n=0)\n",
    "n_filters_per_group\n",
    "\n",
    "filtersA = filters[:, -n_filters_per_group:]\n",
    "filtersB = filters[:, :n_filters_per_group]\n",
    "filters = np.concatenate((filtersB, filtersA), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, filters, _, _ = tangent_classifier_multi(groupA_train_parcellated_covs,  groupB_train_parcellated_covs, TSVM=True, TLDA=False, tangent_calc=True, metric=metric,visualize=False,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_filters(group1_train, group1_test, group_2_train,group2_test, filters, metric=\"riemann\", method='log-cov'):\n",
    "    train_1, test_1, train_2, test_2 = feature_generation(group1_train, group1_test, group_2_train, group2_test, filters,method=method,metric=metric)\n",
    "    fold_metrics = test_classifiers(train_1, test_1, train_2, test_2, sample_weights_train=None)\n",
    "    return fold_metrics\n",
    "\n",
    "print(test_filters(groupA_train_parcellated, groupA_test_parcellated, groupB_train_parcellated, groupB_test_parcellated, filters, metric=metric,method='log-cov'))\n",
    "print(test_filters(groupA_train_parcellated, groupA_test_parcellated, groupB_train_parcellated, groupB_test_parcellated, filters, metric=metric,method='log-var'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_visualize_variance(train_1, train_2, two_filter):\n",
    "    train_1_transform = np.var(train_1@two_filter,axis=1)\n",
    "    train_2_transform = np.var(train_2@two_filter,axis=1)\n",
    "\n",
    "    # Plot when n=1\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(train_1_transform[:, 0], train_1_transform[:, 1], label='Group A Variance', color='blue')\n",
    "    plt.scatter(train_2_transform[:, 0], train_2_transform[:, 1], label='Group B Variance', color='red')\n",
    "\n",
    "    # Display plot\n",
    "    plt.xlabel('Variance Feature B')\n",
    "    plt.ylabel('Variance Feature A')\n",
    "    plt.title(f'Variance Comparison')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "for i in range(0,3):\n",
    "    test_visualize_variance(groupA_train_parcellated, groupB_train_parcellated,filters[:,[i,-(i+1)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_visualize_variance(train_1, train_2, two_filter):\n",
    "    import matplotlib.gridspec as gridspec\n",
    "\n",
    "    # Project data onto filters\n",
    "    train_1_proj = np.var(train_1@two_filter,axis=1)\n",
    "    train_2_proj = np.var(train_2@two_filter,axis=1)\n",
    "\n",
    "    # Create figure and gridspec layout\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "\n",
    "    # Define the axes\n",
    "    ax_scatter = fig.add_subplot(gs[1:4, 0:3])\n",
    "    ax_hist_x = fig.add_subplot(gs[0, 0:3], sharex=ax_scatter)\n",
    "    ax_hist_y = fig.add_subplot(gs[1:4, 3], sharey=ax_scatter)\n",
    "\n",
    "    # Scatter plot\n",
    "    ax_scatter.scatter(train_1_proj[:, 0], train_1_proj[:, 1], label='Group A', color='blue', alpha=0.5)\n",
    "    ax_scatter.scatter(train_2_proj[:, 0], train_2_proj[:, 1], label='Group B', color='red', alpha=0.5)\n",
    "    ax_scatter.set_xlabel('Projection onto Filter B')\n",
    "    ax_scatter.set_ylabel('Projection onto Filter A')\n",
    "    ax_scatter.legend()\n",
    "    ax_scatter.grid(True)\n",
    "\n",
    "    # Histograms\n",
    "    bins = 30\n",
    "\n",
    "    # Histograms for X axis (top)\n",
    "    ax_hist_x.hist(train_1_proj[:, 0], bins=bins, color='blue', alpha=0.5, density=True, label='Group A')\n",
    "    ax_hist_x.hist(train_2_proj[:, 0], bins=bins, color='red', alpha=0.5, density=True, label='Group B')\n",
    "    ax_hist_x.set_ylabel('Density')\n",
    "    ax_hist_x.legend()\n",
    "    ax_hist_x.grid(True)\n",
    "\n",
    "    # Histograms for Y axis (right)\n",
    "    ax_hist_y.hist(train_1_proj[:, 1], bins=bins, orientation='horizontal', color='blue', alpha=0.5, density=True)\n",
    "    ax_hist_y.hist(train_2_proj[:, 1], bins=bins, orientation='horizontal', color='red', alpha=0.5, density=True)\n",
    "    ax_hist_y.set_xlabel('Density')\n",
    "    ax_hist_y.grid(True)\n",
    "\n",
    "    # Hide tick labels on histograms to avoid clutter\n",
    "    plt.setp(ax_hist_x.get_xticklabels(), visible=False)\n",
    "    plt.setp(ax_hist_y.get_yticklabels(), visible=False)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for i in range(0,3):\n",
    "    test_visualize_variance(groupA_train_parcellated, groupB_train_parcellated,filters[:,[i,-(i+1)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting.view_surf(hcp.mesh.inflated, hcp.cortex_data(hcp.unparcellate(filters[:,0], hcp.mmp)), threshold=np.percentile(np.abs(filters[:,0]), 95), bg_map=hcp.mesh.sulc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate MIGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def migp(subs, batch_size=2, m=4800):\n",
    "    W_gpu = None\n",
    "    for batch_start in range(0, len(subs), batch_size):\n",
    "        # Select the current batch of subjects\n",
    "        batch_subs = subs[batch_start:batch_start + batch_size]\n",
    "        batch_paths = [path for sublist in batch_subs for path in sublist]\n",
    "\n",
    "        concatenated_data = []\n",
    "\n",
    "        for task in batch_paths:\n",
    "            X = nib.load(task).get_fdata()\n",
    "            Xn = hcp.normalize(X-X.mean(axis=1, keepdims=True))\n",
    "            # print(Xn.mean(axis=0).mean())\n",
    "            # print(Xn.std(axis=0).mean())\n",
    "            concatenated_data.append(Xn)\n",
    "            del X, Xn\n",
    "            \n",
    "        try:\n",
    "            # Concatenate data along the first axis using numpy\n",
    "            batch = np.concatenate(concatenated_data, axis=0)\n",
    "            batch = hcp.normalize(batch - batch.mean(axis=1,keepdims=True))\n",
    "            del concatenated_data\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Convert to torch tensor and move to GPU\n",
    "                batch_gpu = torch.tensor(batch, dtype=torch.float32, device=\"cuda\")\n",
    "                del batch\n",
    "                if torch.isnan(batch_gpu).any():\n",
    "                    print(\"NaNs detected in the batch data. Aborting SVD operation.\")\n",
    "                    del batch_gpu\n",
    "                    torch.cuda.empty_cache()\n",
    "                    return None\n",
    "                if W_gpu is None:\n",
    "                    combined_data_gpu = batch_gpu\n",
    "                else:\n",
    "                    combined_data_gpu = torch.cat([W_gpu, batch_gpu], dim=0)\n",
    "                del batch_gpu\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                # # Calculate size in GB\n",
    "                # size_in_gb = combined_data_gpu.element_size() * combined_data_gpu.nelement() / (1024**3)\n",
    "                # print(f\"Size of the array: {size_in_gb:.2f} GB\")\n",
    "                # cpu_mem()\n",
    "                # gpu_mem()\n",
    "                # Perform SVD on the GPU\n",
    "                # Check for NaNs in the data\n",
    "\n",
    "                # _, S_gpu, Vh_gpu = torch.linalg.svd(combined_data_gpu, full_matrices=False)\n",
    "                _, Q = torch.linalg.eigh(combined_data_gpu@combined_data_gpu.T)\n",
    "                # cpu_mem()\n",
    "                # gpu_mem()\n",
    "                # Compute the updated W on the GPU\n",
    "                # W_gpu = torch.diag(S_gpu[:m]) @ Vh_gpu[:m, :]\n",
    "                # Returned in Ascending order\n",
    "                W_gpu = Q[:, -m:].T@combined_data_gpu\n",
    "                del Q, combined_data_gpu  # Free up GPU memory\n",
    "                torch.cuda.empty_cache()\n",
    "                print(batch_start, \"done\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed during GPU processing: {e}\")\n",
    "            if \"combined_data_gpu\" in locals():\n",
    "                del combined_data_gpu\n",
    "            if \"Q\" in locals():\n",
    "                del Q\n",
    "            if \"W_gpu\" in locals():\n",
    "                del W_gpu\n",
    "            torch.cuda.empty_cache()\n",
    "            return None\n",
    "\n",
    "    # Transfer W back to CPU only at the end\n",
    "    W = W_gpu.cpu().numpy()\n",
    "    del W_gpu  # Free up GPU memory\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducedsubsA = migp((groupA_train_paths))\n",
    "save_array_to_outputfolder(os.path.join(fold_outputfolder,'reducedsubsA.npy'), reducedsubsA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducedsubsB = migp((groupB_train_paths))\n",
    "save_array_to_outputfolder(os.path.join(fold_outputfolder,'reducedsubsB.npy'), reducedsubsB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MIGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"reducedsubsA\" in locals():\n",
    "    del reducedsubsA\n",
    "if \"reducedsubsB\" in locals():\n",
    "    del reducedsubsB\n",
    "reducedsubsA_loaded = load_array_from_outputfolder(os.path.join(fold_outputfolder,'reducedsubsA.npy'))\n",
    "reducedsubsB_loaded = load_array_from_outputfolder(os.path.join(fold_outputfolder,'reducedsubsB.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "reducedsubs_combined_gpu = torch.tensor(np.concatenate((reducedsubsA_loaded,reducedsubsB_loaded),axis=0),dtype=torch.float32,device=device)\n",
    "# Returned in Descending Order\n",
    "Urc,_,_ = torch.linalg.svd(reducedsubs_combined_gpu, full_matrices=False)\n",
    "reducedsubs_combined = (Urc[:,:4800].T@reducedsubs_combined_gpu).cpu().numpy()\n",
    "del Urc, reducedsubs_combined_gpu\n",
    "\n",
    "reducedsubs_gpu = torch.tensor(reducedsubs_combined, dtype=torch.float32, device=device)\n",
    "U,_,_ = torch.linalg.svd(reducedsubs_gpu, full_matrices=False)\n",
    "reducedsubs= (U[:,:1000].T@reducedsubs_gpu).cpu().numpy()\n",
    "del U, reducedsubs_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Haufe Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Should I pinv(F) or just multiply by F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_subject_haufe(sub,pinv_TF):\n",
    "    try:\n",
    "        concatenated_data = []\n",
    "        for task in sub:\n",
    "            X = nib.load(task).get_fdata(dtype=np.float32)\n",
    "            Xn = hcp.normalize(X-X.mean(axis=1, keepdims=True))\n",
    "            concatenated_data.append(Xn)\n",
    "            del X, Xn\n",
    "\n",
    "        # Concatenate data along the first axis\n",
    "        subject = np.concatenate(concatenated_data, axis=0)\n",
    "        del concatenated_data  # Explicitly delete the concatenated data list\n",
    "\n",
    "        Xp = hcp.normalize(subject - subject.mean(axis=1, keepdims=True))\n",
    "        del subject\n",
    "        Xpf = pinv_TF@Xp\n",
    "        del Xp\n",
    "        return Xpf\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing subject: {e}\")\n",
    "        traceback.print_exc()  # Print the full traceback\n",
    "        return None\n",
    "\n",
    "\n",
    "def haufe_transform(F, parcellated,paths):\n",
    "    \n",
    "    # Ensure the tensors are on the correct device\n",
    "    pinv_TF = np.linalg.pinv(parcellated.reshape(-1,parcellated.shape[-1]) @ np.linalg.pinv(F.T))\n",
    "\n",
    "\n",
    "    # pinv_TF_list = pinv_TF.reshape(len(paths),F.shape[1],pinv_TF.shape[0])\n",
    "    pinv_TF_list = (np.array_split(pinv_TF, len(paths), axis=1))\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=(int(os.cpu_count()*.5))) as executor:\n",
    "        # Use map to process subjects in parallel\n",
    "        blocks = np.array(list(executor.map(process_subject_haufe, paths,pinv_TF_list)))\n",
    "        print(blocks.shape)\n",
    "        return (blocks.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtersA_transform = haufe_transform(filtersA[:,-n_filters_per_group:],groupA_train_parcellated,groupA_train_paths)\n",
    "# save_array_to_outputfolder(\"filtersA_transform.npy\", filtersA_transform)\n",
    "\n",
    "filtersA_transform = haufe_transform(filtersA,groupA_train_parcellated,groupA_train_paths)\n",
    "save_array_to_outputfolder(os.path.join(fold_outputfolder,\"filtersA_transform.npy\"), filtersA_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtersB_transform = haufe_transform(filtersB[:,-n_filters_per_group:],groupB_train_parcellated,groupB_train_paths)\n",
    "# save_array_to_outputfolder(\"filtersB_transform.npy\", filtersB_transform)\n",
    "\n",
    "filtersB_transform = haufe_transform(filtersB,groupB_train_parcellated,groupB_train_paths)\n",
    "save_array_to_outputfolder(os.path.join(fold_outputfolder,\"filtersB_transform.npy\"), filtersB_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Haufe Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtersA_transform = load_array_from_outputfolder(os.path.join(fold_outputfolder,'filtersA_transform.npy'))\n",
    "filtersB_transform = load_array_from_outputfolder(os.path.join(fold_outputfolder,'filtersB_transform.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthonormalize Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orthonormalize_filters(W1, W2):\n",
    "    # Stack the two filters into a single matrix\n",
    "    W = np.concatenate((W1, W2)).T  # shape: (features x 2)\n",
    "    print(W.shape)\n",
    "    \n",
    "    # Perform QR decomposition to orthonormalize the filters\n",
    "    Q, _ = np.linalg.qr(W)\n",
    "    \n",
    "    print(Q.shape)\n",
    "\n",
    "    # Verify that the inner product between the two orthonormalized vectors is 0 (orthogonality)\n",
    "    print(f'Inner product between Q[:, 0] and Q[:, 1]: {np.dot(Q[:, 0].T, Q[:, 1])} (should be 0)')\n",
    "    \n",
    "    # Verify that the inner product within each vector is 1 (normalization)\n",
    "    print(f'Norm of Q[:, 0]: {np.dot(Q[:, 0].T, Q[:, 0])} (should be 1)')\n",
    "    print(f'Norm of Q[:, 1]: {np.dot(Q[:, 1].T, Q[:, 1])} (should be 1)')\n",
    "    \n",
    "    return Q\n",
    "# Example usage\n",
    "\n",
    "filters = orthonormalize_filters(filtersA_transform, filtersB_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_surf(hcp.mesh.inflated, hcp.cortex_data(filters[:,0]), threshold=np.percentile(np.abs(filters[:,0]), 90), bg_map=hcp.mesh.sulc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_surf(hcp.mesh.inflated, hcp.cortex_data(filters[:,1]), threshold=np.percentile(np.abs(filters[:,1]), 90), bg_map=hcp.mesh.sulc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_pca_dim(Data=None,eigs=None,N=None):\n",
    "   # Start MATLAB engine\n",
    "    eng = matlab.engine.start_matlab()\n",
    "    \n",
    "    # Add the path to the MATLAB function\n",
    "    eng.addpath(\"/project/3022057.01/IFA/melodic\", nargout=0)\n",
    "    \n",
    "    if Data is not None:\n",
    "      # Call the MATLAB function\n",
    "      prob = eng.pca_dim(matlab.double(Data))\n",
    "      eig_vectors = np.array(prob['E'])\n",
    "    else:\n",
    "      prob = eng.pca_dim_eigs(matlab.double(eigs.tolist()), matlab.double([N]))\n",
    "\n",
    "    # Extract and convert each variable\n",
    "    lap = np.array(prob['lap']).flatten().reshape(-1, 1)\n",
    "    bic = np.array(prob['bic']).flatten().reshape(-1, 1)\n",
    "    rrn = np.array(prob['rrn']).flatten().reshape(-1, 1)\n",
    "    AIC = np.array(prob['AIC']).flatten().reshape(-1, 1)\n",
    "    MDL = np.array(prob['MDL']).flatten().reshape(-1, 1)\n",
    "    eig = np.array(prob['eig']).flatten()\n",
    "    orig_eig = np.array(prob['orig_eig']).flatten()\n",
    "    leig = np.array(prob['leig']).flatten()\n",
    "\n",
    "    # Stop MATLAB engine\n",
    "    eng.eval('clearvars', nargout=0)\n",
    "    eng.quit()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(np.arange(len(eig)),eig,label=\"Adjusted Eigenspectrum\")\n",
    "    plt.scatter(np.arange(len(orig_eig)),orig_eig,label=\"Eigenspectrum\")\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Eigenvalue')\n",
    "    plt.legend()\n",
    "    plt.title('Scree Plot')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Use SimpleImputer to handle any missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    lap = imputer.fit_transform(lap)\n",
    "    bic = imputer.fit_transform(bic)\n",
    "    rrn = imputer.fit_transform(rrn)\n",
    "    AIC = imputer.fit_transform(AIC)\n",
    "    MDL = imputer.fit_transform(MDL)\n",
    "    \n",
    "    # Use StandardScaler to standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    lap_std = scaler.fit_transform(lap)\n",
    "    bic_std = scaler.fit_transform(bic)\n",
    "    rrn_std = scaler.fit_transform(rrn)\n",
    "    AIC_std = scaler.fit_transform(AIC)\n",
    "    MDL_std = scaler.fit_transform(MDL)\n",
    "    \n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(np.arange(len(lap_std)), lap_std, label='Laplacian')\n",
    "    plt.scatter(np.arange(len(bic_std)), bic_std, label='BIC')\n",
    "    plt.scatter(np.arange(len(rrn_std)), rrn_std, label='RRN')\n",
    "    plt.scatter(np.arange(len(AIC_std)), AIC_std, label='AIC')\n",
    "    plt.scatter(np.arange(len(MDL_std)), MDL_std, label='MDL')\n",
    "    \n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Standardized Value')\n",
    "    plt.legend()\n",
    "    plt.title('Scatter Plot of Standardized Eigenvalues and Model Order Selection Values')\n",
    "    plt.show()\n",
    "   \n",
    "    return np.argmax(rrn_std)+1\n",
    "\n",
    "def get_n_and_some(data):\n",
    "    # Check the shape of the data and determine the axis for mean subtraction\n",
    "\n",
    "    # Move data to GPU if available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    data_gpu = data.to(device, dtype=torch.float32)\n",
    "    groupN = data_gpu.shape[1] - 1\n",
    "\n",
    "    # Subtract the mean along the specified axis\n",
    "    data_centered = data_gpu - torch.mean(data_gpu, dim=1, keepdim=True)\n",
    "    del data_gpu  # Free up GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "    # Perform SVD decomposition\n",
    "    _, d, v = torch.svd(data_centered)\n",
    "    del data_centered  # Free up GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Convert singular values to eigenvalues\n",
    "    e = (d ** 2) / groupN\n",
    "\n",
    "    # Move eigenvalues to CPU and convert to NumPy array\n",
    "    e_np = e.cpu().numpy()\n",
    "    del e, d  # Free up GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Determine the number of components\n",
    "    n_components = torch.tensor(call_pca_dim(eigs=e_np, N=groupN),device=device,dtype=torch.int32)\n",
    "\n",
    "    return n_components, v.T\n",
    "\n",
    "def PPCA(data, filters=None, threshold=1.6, niters=10, n=-1):\n",
    "    n_components = -1\n",
    "    n_prev = -2\n",
    "    i = 0\n",
    "\n",
    "    # Move data to GPU if available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    data_gpu = torch.tensor(data,device=device, dtype=torch.float32)\n",
    "\n",
    "    while n_components != n_prev and i < niters:\n",
    "        n_prev = n_components\n",
    "        if filters is not None:\n",
    "            basis_gpu =  torch.tensor(filters.T,device=device, dtype=torch.float32)\n",
    "        else:\n",
    "            n_components, vt = get_n_and_some(data_gpu)\n",
    "            if n <= 0:\n",
    "                basis_gpu = vt[:n_components, :]\n",
    "            else:\n",
    "                print(n)\n",
    "                basis_gpu = vt[:n, :]\n",
    "            del vt\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        print(n_prev, n_components)\n",
    "\n",
    "        # Estimate noise and residual standard deviation\n",
    "        est_noise = data_gpu - (data_gpu @ torch.linalg.pinv(basis_gpu)) @ basis_gpu\n",
    "        est_residual_std = torch.std(est_noise,dim=0,correction=torch.linalg.matrix_rank(basis_gpu))\n",
    "        del est_noise\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Normalize the data\n",
    "        data_gpu = (data_gpu / est_residual_std)\n",
    "        i += 1\n",
    "\n",
    "    data = data_gpu.cpu().numpy()\n",
    "    basis = basis_gpu.cpu().numpy()\n",
    "    # del data_gpu, basis_gpu, est_residual_std\n",
    "    del data_gpu, basis_gpu\n",
    "    torch.cuda.empty_cache()\n",
    "    return data, basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_data_VN, vt = PPCA(reducedsubs.copy(), threshold=0.0, niters=1)\n",
    "save_array_to_outputfolder(os.path.join(fold_outputfolder,\"subs_data_VN.npy\"), subs_data_VN)\n",
    "save_array_to_outputfolder(os.path.join(fold_outputfolder,\"vt.npy\"), vt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load PPCA Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_data_VN = load_array_from_outputfolder(os.path.join(fold_outputfolder,\"subs_data_VN.npy\"))\n",
    "vt = load_array_from_outputfolder(os.path.join(fold_outputfolder,\"vt.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns are samples i.e. XXT is the covariance matrix formed\n",
    "def whiten(X,n_components, method=\"SVD\", visualize=False):\n",
    "    # -1 to account for demean\n",
    "    n_samples = X.shape[-1]-1\n",
    "    X_mean = X.mean(axis=-1)\n",
    "    X -= X_mean[:, np.newaxis]\n",
    "\n",
    "    if method == \"SVD\":\n",
    "        u, d = svd(X, full_matrices=False, check_finite=False)[:2]\n",
    "        # Give consistent eigenvectors for both svd solvers\n",
    "        # u *= np.sign(u[0])\n",
    "        K = (u / d).T[:n_components]  # see (6.33) p.140\n",
    "        del u, d\n",
    "        whitening_matrix = np.sqrt(n_samples)*K\n",
    "    elif method == \"Cholesky\":\n",
    "    # Does not Orthogonalize, just has unit covariance\n",
    "        # Step 2: Perform Cholesky decomposition\n",
    "        L = np.linalg.cholesky(np.cov(X,ddof=1))\n",
    "        # Step 3:\n",
    "        whitening_matrix = np.linalg.inv(L)\n",
    "    elif method == \"InvCov\":\n",
    "        # Calculate the covariance matrix of the centered data\n",
    "        cov_matrix = np.cov(X)\n",
    "        # Perform eigenvalue decomposition of the covariance matrix\n",
    "        eigvals, eigvecs = np.linalg.eigh(cov_matrix)\n",
    "        # Calculate the whitening matrix\n",
    "        D_inv_sqrt = np.diag(1.0 / np.sqrt(eigvals))\n",
    "        whitening_matrix = eigvecs @ D_inv_sqrt @ eigvecs.T\n",
    "   \n",
    "    whitened_data = whitening_matrix@X\n",
    "\n",
    "    return whitened_data, whitening_matrix\n",
    "\n",
    "# Combine Basis\n",
    "combined_spatial = np.vstack((vt,filters.T))\n",
    "\n",
    "# Whiten\n",
    "whitened_basis, whitening_matrix_pre = whiten(combined_spatial,n_components=combined_spatial.shape[0],method=\"InvCov\",visualize=True)\n",
    "subs_data_com_VN, _ = PPCA(reducedsubs_combined.copy(), filters=whitened_basis.T, threshold=0.0, niters=1)\n",
    "\n",
    "# tempbasis = np.linalg.pinv(subs_data_com_VN@np.linalg.pinv(whitened_basis))@subs_data_com_VN\n",
    "# whitened_basis, _ = whiten(tempbasis,n_components=tempbasis.shape[0],method=\"InvCov\",visualize=True)\n",
    "\n",
    "# for i in range(0,3):\n",
    "#     # Readjust the MiGP data based on the new basis\n",
    "#     subs_data_com_VN, _ = PPCA(subs_data_com_VN.copy(), filters=whitened_basis.T, threshold=0.0, niters=1)\n",
    "\n",
    "#     # Recalculate the basis via Haufe transform based on adjusted MIGP data\n",
    "#     tempbasis = np.linalg.pinv(subs_data_com_VN@np.linalg.pinv(whitened_basis))@subs_data_com_VN\n",
    "\n",
    "#     # Rewhiten the basis\n",
    "#     whitened_basis, whitening_matrix = whiten(tempbasis,n_components=combined_spatial.shape[0],method=\"InvCov\",visualize=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scree(data, n_components=None):\n",
    "    \"\"\"\n",
    "    Perform PCA on the provided dataset and plot a scree plot.\n",
    "\n",
    "    Parameters:\n",
    "    - data: np.array or pd.DataFrame, the dataset to perform PCA on.\n",
    "    - n_components: int or None, the number of principal components to compute. \n",
    "                    If None, all components are computed.\n",
    "\n",
    "    Returns:\n",
    "    - pca: PCA object after fitting to the data.\n",
    "    \"\"\"    \n",
    "    # # Standardize the data\n",
    "    # # Initialize PCA\n",
    "    # pca = PCA()\n",
    "    \n",
    "    # # Fit PCA on the data\n",
    "    # pca.fit(data)\n",
    "    \n",
    "    # # Calculate explained variance ratio\n",
    "    # explained_variance_ratio = pca.explained_variance_ratio_\n",
    "    _, S, _ = np.linalg.svd(data, full_matrices=False)\n",
    "    e = (S ** 2) / (data.shape[-1]-1)\n",
    "    # Create the scree plot\n",
    "    print(e)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(S) + 1), e, marker='o', linestyle='--')\n",
    "    plt.title('Scree Plot')\n",
    "    plt.xlabel('Principal Component')\n",
    "    plt.ylabel('Explained Variance Ratio')\n",
    "    plt.xticks(range(1, len(S) + 1))\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "Atemp = np.linalg.pinv(subs_data_com_VN@np.linalg.pinv(whitened_basis))\n",
    "plot_scree(Atemp@subs_data_com_VN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICA(data,whitened_data):\n",
    "    ica = FastICA(whiten=False)\n",
    "    # Takes in array-like of shape (n_samples, n_features) and returns ndarray of shape (n_samples, n_components)\n",
    "    IFA_components = ica.fit_transform(whitened_data.T).T\n",
    "    A = data@np.linalg.pinv(IFA_components)\n",
    "    W = np.linalg.pinv(A)\n",
    "    print(\"The combined unmixing matrix correctly calculates the components: \", np.allclose(W@data, IFA_components))\n",
    "    print(\"The combined mixing matrix correctly reconstructs the low rank data_demean: \", np.allclose(A@IFA_components, A@(W@data)))\n",
    "\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    # Heat map for the combined unmixing matrix\n",
    "    sns.heatmap(W@data, cmap='viridis', ax=axes[0])\n",
    "    axes[0].set_title('Combined Unmixing Matrix (W @ data)')\n",
    "    axes[0].set_xlabel('Components')\n",
    "    axes[0].set_ylabel('Samples')\n",
    "\n",
    "    # Heat map for the IFA components\n",
    "    sns.heatmap(IFA_components, cmap='viridis', ax=axes[1])\n",
    "    axes[1].set_title('IFA Components')\n",
    "    axes[1].set_xlabel('Components')\n",
    "    axes[1].set_ylabel('Samples')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return IFA_components, A, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_components_combined, A_combined, W_combined = ICA(subs_data_com_VN,whitened_basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vtwhiten,_ = whiten(vt,n_components=vt.shape[0],method=\"SVD\")\n",
    "subs_data_VN, _ = PPCA(reducedsubs_combined.copy(), filters=vtwhiten.T, threshold=0.0, niters=1)\n",
    "raw_components_major, A_major, W_major = ICA(subs_data_VN,vtwhiten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_data_VN_more, vtmore = PPCA(reducedsubs.copy(), threshold=0.0, niters=1,n=vt.shape[0]+filters.shape[1])\n",
    "vtmorewhiten,_ = whiten(vtmore,n_components=vtmore.shape[0],method=\"SVD\")\n",
    "subs_data_VN_more, _ = PPCA(reducedsubs_combined.copy(), filters=vtmorewhiten.T, threshold=0.0, niters=1)\n",
    "\n",
    "raw_components_major_more, A_major_more, W_major_more = ICA(subs_data_VN_more,vtmorewhiten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array_to_outputfolder(os.path.join(fold_outputfolder,\"raw_components_combined.npy\"), raw_components_combined)\n",
    "save_array_to_outputfolder(os.path.join(fold_outputfolder,\"A_combined.npy\"), A_combined)\n",
    "save_array_to_outputfolder(os.path.join(fold_outputfolder,\"W_combined.npy\"), W_combined)\n",
    "save_array_to_outputfolder(os.path.join(fold_outputfolder,\"raw_components_major.npy\"), raw_components_major)\n",
    "save_array_to_outputfolder(os.path.join(fold_outputfolder,\"A_major.npy\"), A_major)\n",
    "save_array_to_outputfolder(os.path.join(fold_outputfolder,\"W_major.npy\"), W_major)\n",
    "save_array_to_outputfolder(os.path.join(fold_outputfolder,\"raw_components_major_more.npy\"), raw_components_major_more)\n",
    "save_array_to_outputfolder(os.path.join(fold_outputfolder,\"A_major_more.npy\"), A_major_more)\n",
    "save_array_to_outputfolder(os.path.join(fold_outputfolder,\"W_major_more.npy\"), W_major_more)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_components_combined = load_array_from_outputfolder(os.path.join(fold_outputfolder,\"raw_components_combined.npy\"))\n",
    "A_combined = load_array_from_outputfolder(os.path.join(fold_outputfolder,\"A_combined.npy\"))\n",
    "W_combined = load_array_from_outputfolder(os.path.join(fold_outputfolder,\"W_combined.npy\"))\n",
    "raw_components_major = load_array_from_outputfolder(os.path.join(fold_outputfolder,\"raw_components_major.npy\"))\n",
    "A_major = load_array_from_outputfolder(os.path.join(fold_outputfolder,\"A_major.npy\"))\n",
    "W_major = load_array_from_outputfolder(os.path.join(fold_outputfolder,\"W_major.npy\"))\n",
    "raw_components_major_more = load_array_from_outputfolder(os.path.join(fold_outputfolder,\"raw_components_major_more.npy\"))\n",
    "A_major_more = load_array_from_outputfolder(os.path.join(fold_outputfolder,\"A_major_more.npy\"))\n",
    "W_major_more = load_array_from_outputfolder(os.path.join(fold_outputfolder,\"W_major_more.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_projection(W,data, visualize=True):\n",
    "\n",
    "    Signals = np.linalg.pinv(W)@(W@data)\n",
    "    Residuals = data - Signals\n",
    "    residual_std = np.std(Residuals,axis=0,ddof=np.linalg.matrix_rank(W))\n",
    "    # Trace of I-pinv(W)(W) is equal to the nullity (n-m gvien n > m) of the reconstructed matrix \n",
    "    # trace = data.shape[0] - np.linalg.matrix_rank(W)\n",
    "    # residual_std2 = (np.einsum('ij,ij->j', Residuals, Residuals)/(trace))**.5\n",
    "\n",
    "\n",
    "    if visualize:\n",
    "        n=1000\n",
    "        plt.figure()\n",
    "        plt.plot(Signals[:n,0:1])\n",
    "        plt.plot(Residuals[:n,0:1])\n",
    "        # plt.plot(data[:n,0:1])\n",
    "        # plt.plot(data[:n,0:1] - (Signals[:n,0:1]+Residuals[:n,0:1]))\n",
    "        plt.legend(['Signal','Noise', 'Data' ,'Reconstruction Error'])\n",
    "        plt.title(\"Calculations based on pinv(W)W Projection Matrix\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.scatter(range(0,residual_std.shape[0]), residual_std)\n",
    "        plt.title(\"Noise std Per Voxel based on pinv(W)W Projection Matrix\")\n",
    "        plt.show()\n",
    "    return residual_std\n",
    "\n",
    "\n",
    "def threshold_and_visualize(data, W, components,visualize=False):\n",
    "    \n",
    "    voxel_noise = noise_projection(W,data)[:, np.newaxis]\n",
    "    z_scores_array = np.zeros_like(components)\n",
    "    z_scores = np.zeros_like(components)\n",
    "\n",
    "    # Process each filter individually\n",
    "    for i in range(components.shape[1]):\n",
    "        z_score = ((components[:, i:i+1]))/voxel_noise\n",
    "        # P(Z < -z \\text{ or } Z > z) = (1 - \\text{CDF}(z)) + (1 - \\text{CDF}(z)) = 2 \\times (1 - \\text{CDF}(z))\n",
    "        p_values = 2 * (1 - norm.cdf(np.abs(z_score)))\n",
    "        # Apply multiple comparisons correction for the current filter https://www.statsmodels.org/dev/generated/statsmodels.stats.multitest.multipletests.html\n",
    "        reject, pvals_corrected, _, _ = multipletests(p_values.flatten(), alpha=0.05, method='fdr_bh')\n",
    "        masked_comp = z_score*(reject[:,np.newaxis])\n",
    "        # print(masked_comp, reject[:,np.newaxis],z_score)\n",
    "        z_scores_array[:, i:i+1] = masked_comp        \n",
    "        z_scores[:,i:i+1] = z_score\n",
    "\n",
    "       # Skip the iteration if there are no significant values\n",
    "        if not np.any(reject) and visualize:\n",
    "            print(f'Component {i} did not contain any significant values')\n",
    "            plt.figure()\n",
    "            plt.hist(z_score, bins=30, color='blue', alpha=0.7)\n",
    "            plt.title(f\"Histogram for Filter {i} NO SIGNIFICANT VALUES\")\n",
    "            plt.xlabel('Value')\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.show()\n",
    "        else:\n",
    "            if visualize:\n",
    "                # Create a figure and axes for subplots (1 row of 2 plots per filter)\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(18, 10))\n",
    "\n",
    "                ax_hist1 = axes[0]\n",
    "                ax_img = axes[1]\n",
    "\n",
    "                # Plot the histogram of the current filter\n",
    "                ax_hist1.hist(z_score, bins=30, color='blue', alpha=0.7)\n",
    "                ax_hist1.set_title(f\"Histogram for Filter {i}\")\n",
    "                ax_hist1.set_xlabel('Value')\n",
    "                ax_hist1.set_ylabel('Frequency')\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    # Heat map for the combined unmixing matrix\n",
    "    sns.heatmap(z_scores, cmap='viridis', ax=axes[0])\n",
    "    axes[0].set_title('z_score')\n",
    "    axes[0].set_xlabel('Components')\n",
    "    axes[0].set_ylabel('Samples')\n",
    "\n",
    "    # Heat map for the IFA components\n",
    "    sns.heatmap(z_scores_array, cmap='viridis', ax=axes[1])\n",
    "    axes[1].set_title('z_score thresh')\n",
    "    axes[1].set_xlabel('Components')\n",
    "    axes[1].set_ylabel('Samples')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return z_scores, z_scores_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores_unthresh, z_scores_thresh = threshold_and_visualize(subs_data_com_VN, W_combined, raw_components_combined.T, visualize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores_unthresh_major, z_scores_thresh_major = threshold_and_visualize(subs_data_VN, W_major, raw_components_major.T, visualize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores_unthresh_major_more, z_scores_thresh_major_more = threshold_and_visualize(subs_data_VN_more, W_major_more, raw_components_major_more.T, visualize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array_to_outputfolder(os.path.join(fold_outputfolder,\"z_scores_unthresh.npy\"), z_scores_unthresh)\n",
    "save_array_to_outputfolder(os.path.join(fold_outputfolder,\"z_scores_thresh.npy\"), z_scores_thresh)\n",
    "save_array_to_outputfolder(os.path.join(fold_outputfolder,\"z_scores_unthresh_major.npy\"), z_scores_unthresh_major)\n",
    "save_array_to_outputfolder(os.path.join(fold_outputfolder,\"z_scores_thresh_major.npy\"), z_scores_thresh_major)\n",
    "save_array_to_outputfolder(os.path.join(fold_outputfolder,\"z_scores_unthresh_major_more.npy\"), z_scores_unthresh_major_more)\n",
    "save_array_to_outputfolder(os.path.join(fold_outputfolder,\"z_scores_thresh_major_more.npy\"), z_scores_thresh_major_more)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Z maps (Thresholded and Unthresholded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores_unthresh = load_array_from_outputfolder(os.path.join(fold_outputfolder,\"z_scores_unthresh.npy\"))\n",
    "z_scores_thresh = load_array_from_outputfolder(os.path.join(fold_outputfolder,\"z_scores_thresh.npy\"))\n",
    "z_scores_unthresh_major = load_array_from_outputfolder(os.path.join(fold_outputfolder,\"z_scores_unthresh_major.npy\"))\n",
    "z_scores_thresh_major = load_array_from_outputfolder(os.path.join(fold_outputfolder,\"z_scores_thresh_major.npy\"))\n",
    "z_scores_unthresh_major_more = load_array_from_outputfolder(os.path.join(fold_outputfolder,\"z_scores_unthresh_major_more.npy\"))\n",
    "z_scores_thresh_major_more = load_array_from_outputfolder(os.path.join(fold_outputfolder,\"z_scores_thresh_major_more.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_surf(hcp.mesh.inflated, hcp.cortex_data(z_scores_unthresh[:,20]), threshold=0, bg_map=hcp.mesh.sulc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run and Save Netmats + Dual Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "# https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2017.00115/full\n",
    "\n",
    "def calculate_netmat_and_spatial_map(Xn, z_maps):\n",
    "    \"\"\"\n",
    "    Calculate the network matrix (netmat) and spatial map for a given subject and z_maps.\n",
    "    \n",
    "    Parameters:\n",
    "    Xn (array): Time x Grayordinates normalized data matrix (Time x V)\n",
    "    z_maps (array): Grayordinates x Components map (V x C)\n",
    "\n",
    "    Returns:\n",
    "    netmat (array): Components x Components network matrix (C x C)\n",
    "    spatial_map (array): Components x Grayordinates matrix (C x V)\n",
    "    \"\"\"\n",
    "    # Time x Components\n",
    "    # Demean the regressors (z_maps)\n",
    "    z_maps_demeaned = z_maps - z_maps.mean(axis=0, keepdims=True)  # Demean the columns of z_maps (V x C)\n",
    "    \n",
    "    # Time x Components\n",
    "    A = (Xn @ np.linalg.pinv(z_maps_demeaned.T))  # A is Time x Components (T x C)\n",
    "    reconstructed = A@z_maps_demeaned.T\n",
    "    reconstruction_error = (1 - np.linalg.norm(reconstructed - reconstructed.mean())/np.linalg.norm(Xn - Xn.mean()))*100\n",
    "   \n",
    "    # Normalized Time x Components matrix\n",
    "    An = hcp.normalize(A)  # An is Time x Components (T x C)\n",
    "    del A\n",
    "\n",
    "    # Components x Components network matrix\n",
    "    netmat = (An.T @ An) / (Xn.shape[0] - 1)  # Netmat is Components x Components (C x C)\n",
    "\n",
    "    # Components x Grayordinates spatial map\n",
    "    spatial_map = np.linalg.pinv(An) @ Xn  # Spatial map is Components x Grayordinates (C x V)\n",
    "\n",
    "    return An, netmat, spatial_map, reconstruction_error\n",
    "\n",
    "def dual_regress_sub(sub_path, z_maps_1, z_maps_2):\n",
    "    try:\n",
    "        concatenated_data = []\n",
    "        for task in sub_path:\n",
    "            # Load and preprocess each task\n",
    "            X = nib.load(task).get_fdata(dtype=np.float32)  # Grayordinates x Time (V x T)\n",
    "            Xn = hcp.normalize(X - X.mean(axis=1, keepdims=True))  # Normalizing (V x T)\n",
    "            concatenated_data.append(Xn)\n",
    "            del X, Xn\n",
    "        # Concatenate data along the first axis (all tasks into one big matrix)\n",
    "        subject = np.concatenate(concatenated_data, axis=0)  # Time x Grayordinates (T x V)\n",
    "        del concatenated_data\n",
    "        \n",
    "        # Normalize the concatenated data\n",
    "        Xn = hcp.normalize(subject - subject.mean(axis=1,keepdims=True))  # Time x Grayordinates normalized data (T x V)\n",
    "        del subject\n",
    "        \n",
    "        # Calculate netmat and spatial map for the first set of z_maps\n",
    "        An_1, netmat_1, spatial_map_1, reconstruction_error_1 = calculate_netmat_and_spatial_map(Xn, z_maps_1)\n",
    "\n",
    "        # Calculate netmat and spatial map for the second set of z_maps\n",
    "        An_2, netmat_2, spatial_map_2, reconstruction_error_2 = calculate_netmat_and_spatial_map(Xn, z_maps_2)\n",
    "\n",
    "        return (An_1, netmat_1, spatial_map_1, reconstruction_error_1), (An_2, netmat_2, spatial_map_2, reconstruction_error_2)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing subject: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def dual_regress(group_paths, z_maps_1, z_maps_2):\n",
    "    # Use partial to avoid duplicating z_maps in memory\n",
    "    with ProcessPoolExecutor(max_workers=int(os.cpu_count() * 0.7)) as executor:\n",
    "        # Create a partial function that \"binds\" the z_maps_1 and z_maps_2 without duplicating them\n",
    "        partial_func = partial(dual_regress_sub, z_maps_1=z_maps_1, z_maps_2=z_maps_2)\n",
    "\n",
    "        # Pass the subject paths to the executor without copying z_maps\n",
    "        results = list(executor.map(partial_func, group_paths))\n",
    "        \n",
    "        # Separate the results for the two bases, collecting An, netmat, and spatial_map\n",
    "        An_1, netmats_1, spatial_maps_1, reconstruction_errors_1 = zip(*[(res[0][0], res[0][1], res[0][2], res[0][3]) for res in results if res[0] is not None])\n",
    "        An_2, netmats_2, spatial_maps_2, reconstruction_errors_2 = zip(*[(res[1][0], res[1][1], res[1][2], res[1][3]) for res in results if res[1] is not None])\n",
    "\n",
    "        return (np.array(An_1), np.array(netmats_1), np.array(spatial_maps_1), np.array(reconstruction_errors_1)), (np.array(An_2), np.array(netmats_2), np.array(spatial_maps_2), np.array(reconstruction_errors_2))\n",
    "\n",
    "# Save function for An, netmats, and spatial maps\n",
    "def save_numpy_arrays(output_prefix, An_1, netmats_1, spatial_maps_1, reconstruction_errors_1, An_2, netmats_2, spatial_maps_2,reconstruction_errors_2):\n",
    "    \"\"\"\n",
    "    Saves the An arrays, netmats, and spatial maps to disk using np.save.\n",
    "    \n",
    "    Parameters:\n",
    "    output_prefix (str): Prefix for the output files.\n",
    "    An_1 (np.array): Time x Components matrix for z_maps_1.\n",
    "    netmats_1 (np.array): Network matrices for z_maps_1.\n",
    "    spatial_maps_1 (np.array): Spatial maps for z_maps_1.\n",
    "    An_2 (np.array): Time x Components matrix for z_maps_2.\n",
    "    netmats_2 (np.array): Network matrices for z_maps_2.\n",
    "    spatial_maps_2 (np.array): Spatial maps for z_maps_2.\n",
    "    \"\"\"\n",
    "    save_array_to_outputfolder(f\"{output_prefix}_An_1.npy\", An_1)\n",
    "    save_array_to_outputfolder(f\"{output_prefix}_netmats_1.npy\", netmats_1)\n",
    "    save_array_to_outputfolder(f\"{output_prefix}_spatial_maps_1.npy\", spatial_maps_1)\n",
    "    save_array_to_outputfolder(f\"{output_prefix}_reconstruction_errors_1.npy\", reconstruction_errors_1)\n",
    "    save_array_to_outputfolder(f\"{output_prefix}_An_2.npy\", An_2)\n",
    "    save_array_to_outputfolder(f\"{output_prefix}_netmats_2.npy\", netmats_2)\n",
    "    save_array_to_outputfolder(f\"{output_prefix}_spatial_maps_2.npy\", spatial_maps_2)\n",
    "    save_array_to_outputfolder(f\"{output_prefix}_reconstruction_errors_2.npy\", reconstruction_errors_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Group A - Training Set\n",
    "(groupA_An_1_train, groupA_netmats_1_train, groupA_spatial_maps_1_train), (groupA_An_2_train, groupA_netmats_2_train, groupA_spatial_maps_2_train) = dual_regress([groupA_train_paths[0]], z_scores_unthresh, z_scores_unthresh_major_more)\n",
    "save_numpy_arrays(\"groupA_train\", groupA_An_1_train, groupA_netmats_1_train, groupA_spatial_maps_1_train, groupA_An_2_train, groupA_netmats_2_train, groupA_spatial_maps_2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(groupA_test_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Group A - Test Set\n",
    "(groupA_An_1_test, groupA_netmats_1_test, groupA_spatial_maps_1_test, groupA_reconstruction_errors_1_test), (groupA_An_2_test, groupA_netmats_2_test, groupA_spatial_maps_2_test, groupA_reconstruction_errors_2_test) = dual_regress([groupA_test_paths[0]], z_scores_unthresh, z_scores_unthresh_major_more)\n",
    "save_numpy_arrays(\"groupA_test\", groupA_An_1_test, groupA_netmats_1_test, groupA_spatial_maps_1_test, groupA_reconstruction_errors_1_test, groupA_An_2_test, groupA_netmats_2_test, groupA_spatial_maps_2_test, groupA_reconstruction_errors_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Group B - Training Set\n",
    "(groupB_An_1_train, groupB_netmats_1_train, groupB_spatial_maps_1_train), (groupB_An_2_train, groupB_netmats_2_train, groupB_spatial_maps_2_train) = dual_regress([groupB_train_paths[0]], z_scores_unthresh, z_scores_unthresh_major_more)\n",
    "save_numpy_arrays(\"groupB_train\", groupB_An_1_train, groupB_netmats_1_train, groupB_spatial_maps_1_train, groupB_An_2_train, groupB_netmats_2_train, groupB_spatial_maps_2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Group B - Test Set\n",
    "(groupB_An_1_test, groupB_netmats_1_test, groupB_spatial_maps_1_test, groupB_reconstruction_errors_1_test), (groupB_An_2_test, groupB_netmats_2_test, groupB_spatial_maps_2_test, groupB_reconstruction_errors_2_test) = dual_regress([groupB_test_paths[0]], z_scores_unthresh, z_scores_unthresh_major_more)\n",
    "save_numpy_arrays(\"groupB_test\", groupB_An_1_test, groupB_netmats_1_test, groupB_spatial_maps_1_test, groupB_reconstruction_errors_1_test, groupB_An_2_test, groupB_netmats_2_test, groupB_spatial_maps_2_test, groupB_reconstruction_errors_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Group A - Training Set\n",
    "(groupA_An_1_train, groupA_netmats_1_train, groupA_spatial_maps_1_train), (groupA_An_2_train, groupA_netmats_2_train, groupA_spatial_maps_2_train) = dual_regress(groupA_train_paths, z_scores_unthresh, z_scores_unthresh_major_more)\n",
    "save_numpy_arrays(os.path.join(fold_outputfolder,\"groupA_train\"), groupA_An_1_train, groupA_netmats_1_train, groupA_spatial_maps_1_train, groupA_An_2_train, groupA_netmats_2_train, groupA_spatial_maps_2_train)\n",
    "# For Group A - Test Set\n",
    "(groupA_An_1_test, groupA_netmats_1_test, groupA_spatial_maps_1_test), (groupA_An_2_test, groupA_netmats_2_test, groupA_spatial_maps_2_test) = dual_regress(groupA_test_paths, z_scores_unthresh, z_scores_unthresh_major_more)\n",
    "save_numpy_arrays(os.path.join(fold_outputfolder,\"groupA_test\"), groupA_An_1_test, groupA_netmats_1_test, groupA_spatial_maps_1_test, groupA_An_2_test, groupA_netmats_2_test, groupA_spatial_maps_2_test)\n",
    "# For Group B - Training Set\n",
    "(groupB_An_1_train, groupB_netmats_1_train, groupB_spatial_maps_1_train), (groupB_An_2_train, groupB_netmats_2_train, groupB_spatial_maps_2_train) = dual_regress(groupB_train_paths, z_scores_unthresh, z_scores_unthresh_major_more)\n",
    "save_numpy_arrays(os.path.join(fold_outputfolder,\"groupB_train\"), groupB_An_1_train, groupB_netmats_1_train, groupB_spatial_maps_1_train, groupB_An_2_train, groupB_netmats_2_train, groupB_spatial_maps_2_train)\n",
    "# For Group B - Test Set\n",
    "(groupB_An_1_test, groupB_netmats_1_test, groupB_spatial_maps_1_test), (groupB_An_2_test, groupB_netmats_2_test, groupB_spatial_maps_2_test) = dual_regress(groupB_test_paths, z_scores_unthresh, z_scores_unthresh_major_more)\n",
    "save_numpy_arrays(os.path.join(fold_outputfolder,\"groupB_test\"), groupB_An_1_test, groupB_netmats_1_test, groupB_spatial_maps_1_test, groupB_An_2_test, groupB_netmats_2_test, groupB_spatial_maps_2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Netmats + Dual Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load function for An, netmats, and spatial maps\n",
    "def load_numpy_arrays(input_prefix):\n",
    "    \"\"\"\n",
    "    Loads the An arrays, netmats, and spatial maps from disk using load_array_from_outputfolder.\n",
    "    \n",
    "    Parameters:\n",
    "    input_prefix (str): Prefix for the input files.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Six numpy arrays (An_1, netmats_1, spatial_maps_1, An_2, netmats_2, spatial_maps_2).\n",
    "    \"\"\"\n",
    "    An_1 = load_array_from_outputfolder(f\"{input_prefix}_An_1.npy\")\n",
    "    netmats_1 = load_array_from_outputfolder(f\"{input_prefix}_netmats_1.npy\")\n",
    "    spatial_maps_1 = load_array_from_outputfolder(f\"{input_prefix}_spatial_maps_1.npy\")\n",
    "    An_2 = load_array_from_outputfolder(f\"{input_prefix}_An_2.npy\")\n",
    "    netmats_2 = load_array_from_outputfolder(f\"{input_prefix}_netmats_2.npy\")\n",
    "    spatial_maps_2 = load_array_from_outputfolder(f\"{input_prefix}_spatial_maps_2.npy\")\n",
    "    \n",
    "    return An_1, netmats_1, spatial_maps_1, An_2, netmats_2, spatial_maps_2\n",
    "\n",
    "# Example usage for loading Group A train and test results\n",
    "groupA_An_1_train, groupA_netmats_1_train, groupA_spatial_maps_1_train, groupA_An_2_train, groupA_netmats_2_train, groupA_spatial_maps_2_train = load_numpy_arrays(os.path.join(fold_outputfolder,\"groupA_train\"))\n",
    "groupA_An_1_test, groupA_netmats_1_test, groupA_spatial_maps_1_test, groupA_An_2_test, groupA_netmats_2_test, groupA_spatial_maps_2_test = load_numpy_arrays(os.path.join(fold_outputfolder,\"groupA_test\"))\n",
    "\n",
    "# Example usage for loading Group B train and test results\n",
    "groupB_An_1_train, groupB_netmats_1_train, groupB_spatial_maps_1_train, groupB_An_2_train, groupB_netmats_2_train, groupB_spatial_maps_2_train = load_numpy_arrays(os.path.join(fold_outputfolder,\"groupB_train\"))\n",
    "groupB_An_1_test, groupB_netmats_1_test, groupB_spatial_maps_1_test, groupB_An_2_test, groupB_netmats_2_test, groupB_spatial_maps_2_test = load_numpy_arrays(os.path.join(fold_outputfolder,\"groupB_test\"))\n",
    "\n",
    "# Sanity check for Group A train data\n",
    "print(\"Group A Train:\")\n",
    "print(groupA_An_1_train.shape, groupA_netmats_1_train.shape, groupA_spatial_maps_1_train.shape)\n",
    "print(groupA_An_2_train.shape, groupA_netmats_2_train.shape, groupA_spatial_maps_2_train.shape)\n",
    "\n",
    "# Sanity check for Group A test data\n",
    "print(\"Group A Test:\")\n",
    "print(groupA_An_1_test.shape, groupA_netmats_1_test.shape, groupA_spatial_maps_1_test.shape)\n",
    "print(groupA_An_2_test.shape, groupA_netmats_2_test.shape, groupA_spatial_maps_2_test.shape)\n",
    "\n",
    "# Sanity check for Group B train data\n",
    "print(\"Group B Train:\")\n",
    "print(groupB_An_1_train.shape, groupB_netmats_1_train.shape, groupB_spatial_maps_1_train.shape)\n",
    "print(groupB_An_2_train.shape, groupB_netmats_2_train.shape, groupB_spatial_maps_2_train.shape)\n",
    "\n",
    "# Sanity check for Group B test data\n",
    "print(\"Group B Test:\")\n",
    "print(groupB_An_1_test.shape, groupB_netmats_1_test.shape, groupB_spatial_maps_1_test.shape)\n",
    "print(groupB_An_2_test.shape, groupB_netmats_2_test.shape, groupB_spatial_maps_2_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netmat Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_phenotype_two(subids,phenotype):\n",
    "    file_path_restricted = '../HCP/RESTRICTED_zainsou_8_6_2024_2_11_21.csv'\n",
    "    file_path_unrestricted = '../HCP/unrestricted_zainsou_8_2_2024_6_13_22.csv'\n",
    "\n",
    "    try:\n",
    "        data_r = pd.read_csv(file_path_restricted)\n",
    "        data_ur = pd.read_csv(file_path_unrestricted)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path_restricted} or {file_path_unrestricted}\")\n",
    "        raise\n",
    "\n",
    "    # Combine restricted and unrestricted data on Subject ID\n",
    "    data = pd.merge(data_r, data_ur, on='Subject', how='outer')\n",
    "\n",
    "    # Convert Subject IDs to string for consistency\n",
    "    data['Subject'] = data['Subject'].astype(str)\n",
    "    subids = subids.astype(str)\n",
    "\n",
    "    # Filter data for training subjects\n",
    "    train_data = data[data['Subject'].isin(subids)]\n",
    "    # Ensure the order matches the training data\n",
    "    train_data = train_data.set_index('Subject').loc[subids].reset_index()\n",
    "    pheno_score = train_data[\"PicVocab_AgeAdj\"] + train_data[\"PMAT24_A_CR\"]\n",
    "    return pheno_score\n",
    "\n",
    "# Combine train data from Group A and Group B\n",
    "group_netmats_1_test = np.concatenate((groupA_netmats_1_test, groupB_netmats_1_test), axis=0)\n",
    "group_netmats_2_test = np.concatenate((groupA_netmats_2_test, groupB_netmats_2_test), axis=0)\n",
    "\n",
    "# Combine train data from Group A and Group B\n",
    "group_netmats_1_test = np.concatenate((groupA_netmats_1_test, groupB_netmats_1_test), axis=0)\n",
    "group_netmats_2_test = np.concatenate((groupA_netmats_2_test, groupB_netmats_2_test), axis=0)\n",
    "\n",
    "groupA_train_paths = train_paths[train_labels == 1]\n",
    "groupA_test_paths = test_paths[test_labels == 1]\n",
    "groupB_train_paths = train_paths[train_labels == 0]\n",
    "groupB_test_paths = test_paths[test_labels == 0]\n",
    "\n",
    "groupA_train_subject_ids = extract_subject_ids(groupA_train_paths)\n",
    "groupB_train_subject_ids = extract_subject_ids(groupB_train_paths)\n",
    "groupA_test_subject_ids = extract_subject_ids(groupA_test_paths)\n",
    "groupB_test_subject_ids = extract_subject_ids(groupB_test_paths)\n",
    "train_subid = np.concatenate((groupA_train_subject_ids,groupB_train_subject_ids),axis=0)\n",
    "test_subid = np.concatenate((groupA_test_subject_ids,groupB_test_subject_ids),axis=0)\n",
    "print(train_subid.shape,test_subid.shape)\n",
    "\n",
    "train_values = np.array(extract_phenotype_two(train_subid,phenotype))\n",
    "train_age = np.array(extract_phenotype(train_subid, 'Age_in_Yrs'))\n",
    "\n",
    "test_values = np.array(extract_phenotype_two(test_subid,phenotype))\n",
    "test_age = np.array(extract_phenotype(test_subid, 'Age_in_Yrs'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tan_regression(train_netmats,test_netmats, train_values, test_values, train_age, test_age, metric=metric):\n",
    "    \n",
    "    # Plot the histogram of training data and calculated weights\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # Plot histogram of training target values\n",
    "    plt.hist(train_values, bins=10, alpha=0.7, color='blue', edgecolor='black', label='Train Data')\n",
    "    plt.title(f'Train Data Histogram and Weights')\n",
    "    plt.xlabel('Target Value')\n",
    "    plt.ylabel('Frequency / Weight')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    train_values, test_values = preproc(train_values[:,np.newaxis],test_values[:,np.newaxis], method=\"center\")\n",
    "    train_age, test_age = preproc(train_age[:,np.newaxis], test_age[:,np.newaxis], method=\"center\")\n",
    "\n",
    "\n",
    "    train_mean = mean_covariance(train_netmats, metric=metric)\n",
    "    tan_train = tangent_space(train_netmats, train_mean,metric=metric)\n",
    "    tan_test = tangent_space(test_netmats, train_mean,metric=metric)\n",
    "\n",
    "    tan_mean = np.mean(tan_train, axis=0)\n",
    "    tan_train_centered = tan_train - tan_mean\n",
    "    tan_test_centered = tan_test - tan_mean\n",
    "\n",
    "    age_reg = regress_out_age(tan_train_centered, train_age)\n",
    "    tan_train_centered = tan_train_centered - age_reg.predict(train_age.reshape(-1, 1))\n",
    "    tan_test_centered = tan_test - age_reg.predict(test_age.reshape(-1, 1))\n",
    "\n",
    "    reg_model = Ridge(alpha=1)\n",
    "    # reg_model = LinearSVR(C=1,fit_intercept=True)\n",
    "\n",
    "    reg_model.fit(tan_train_centered, train_values)\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    test_score = reg_model.score(tan_test_centered, test_values)\n",
    "    predictions = reg_model.predict(tan_test_centered)\n",
    "    fold_corr, _ = pearsonr(test_values, predictions)\n",
    "\n",
    "    print(f\"Fold Test R² Score: {test_score}\")\n",
    "    print(f\"Fold Test R Score: {fold_corr}\")\n",
    "\n",
    "    # Plot predictions vs true values for test fold\n",
    "    plot_predictions(test_values, predictions,f'Test Predictions vs True Values - Fold R²: {test_score:.2f}', 'Test')\n",
    "    # Now plot for train fold\n",
    "    predictions_train = reg_model.predict(tan_train_centered)\n",
    "    plot_predictions(train_values, predictions_train, f'Train Predictions vs True Values - Fold R²: {test_score:.2f}', 'Train')\n",
    "     # Plot residuals vs true values for test fold\n",
    "    plot_residuals(test_values, predictions, f'Test Residuals vs True Values - Fold R²: {test_score:.2f}', 'Test')\n",
    "\n",
    "    # Plot residuals vs true values for train fold\n",
    "    plot_residuals(train_values, predictions_train, f'Train Residuals vs True Values - Fold R²: {test_score:.2f}', 'Train')\n",
    "\n",
    "\n",
    "tan_regression(group_netmats_1_train,group_netmats_1_test, train_values, test_values, train_age, test_age, metric=metric)\n",
    "tan_regression(group_netmats_2_train,group_netmats_2_test, train_values, test_values, train_age, test_age, metric=metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Discriminant Information via Netmats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def migp_netmat(group_data,basis):\n",
    "    group_data_dm = group_data - group_data.mean(axis=0, keepdims=True)\n",
    "    basis_dm = basis - basis.mean(axis=0, keepdims=True)\n",
    "    A = ((group_data_dm@np.linalg.pinv(basis_dm.T)))\n",
    "    # Normalized Time x Components matrix\n",
    "    An = hcp.normalize(A)  # An is Time x Components (T x C)\n",
    "    del A\n",
    "\n",
    "    timepoints = An.shape[0]\n",
    "    group_netmat = (An.T@An)/(timepoints-1)\n",
    "    return group_netmat\n",
    "\n",
    "def group_dist(group_data1,group_data2,basis,metric=\"riemann\"):\n",
    "    netmat1 = migp_netmat(group_data1,basis)\n",
    "    netmat2 = migp_netmat(group_data2,basis)\n",
    "    return distance(netmat1,netmat2,metric=metric)\n",
    "\n",
    "ICA_mean_dist = group_dist(reducedsubsA_loaded,reducedsubsB_loaded,z_scores_unthresh_major,metric=metric)\n",
    "ICA_more_mean_dist = group_dist(reducedsubsA_loaded,reducedsubsB_loaded,z_scores_unthresh_major_more,metric=metric)\n",
    "IFA_mean_dist = group_dist(reducedsubsA_loaded,reducedsubsB_loaded,z_scores_unthresh,metric=metric)\n",
    "\n",
    "save_text_results(f'Distance between Group Average Netmats formed from MIGP on train data projected on {z_scores_unthresh_major.shape[1]} ICA components: {ICA_mean_dist}',os.path.join(f\"fold_{fold}\", \"results\",\"results.txt\"))\n",
    "save_text_results(f'Distance between Group Average Netmats formed from MIGP on train data projected on {z_scores_unthresh_major_more.shape[1]} ICA components: {ICA_more_mean_dist}',os.path.join(f\"fold_{fold}\", \"results\",\"results.txt\"))\n",
    "save_text_results(f'Distance between Group Average Netmats formed from MIGP on train data projected on {z_scores_unthresh.shape[1]} IFA components: {IFA_mean_dist}',os.path.join(f\"fold_{fold}\", \"results\",\"results.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5662067\n",
    "def var_diff(group1_train, group1_test, group1_cov_train,group2_train, group2_test, group2_cov_train, metric):\n",
    "    # clf = SVC(kernel='linear', class_weight='balanced')\n",
    "    clf = LogisticRegression()\n",
    "\n",
    "    \n",
    "    # Compute the mean covariances using the training data only\n",
    "    group1_mean = mean_covariance(group1_cov_train, metric=metric)\n",
    "    group2_mean = mean_covariance(group2_cov_train, metric=metric)\n",
    "\n",
    "    # # Eigen decomposition to get features\n",
    "    _, feature_all = eigh(group1_mean, group2_mean + group2_mean, eigvals_only=False)\n",
    "    # _, feature_all, _, _ = tangent_classifier(group1_cov_train, group2_cov_train, TSVM=True, TLDA=False, tangent_calc=True, metric=metric,visualize=False,n=0)\n",
    "\n",
    "\n",
    "    # Initialize list to store results (accuracy and distance)\n",
    "    results = []\n",
    "\n",
    "    # Loop from n=1 to n=15 for selecting top and bottom eigenvectors\n",
    "    for n in range(1, feature_all.shape[1] // 2 + 1): \n",
    "        # Perform eigen decomposition based on top and bottom n eigenvectors\n",
    "        features = np.hstack([feature_all[:, :n], feature_all[:, -n:]])  # Select top and bottom n eigenvectors\n",
    "        group1_train_logvar, group1_test_logvar, group2_train_logvar, group2_test_logvar = feature_generation(group1_train, group1_test,group2_train,group2_test, features, metric=metric,method=\"log-var\")\n",
    "\n",
    "        # Prepare the dataset for classification\n",
    "        X_train = np.vstack([group1_train_logvar, group2_train_logvar])\n",
    "        y_train = np.hstack([np.ones(group1_train_logvar.shape[0]), np.zeros(group2_train_logvar.shape[0])])\n",
    "        X_test = np.vstack([group1_test_logvar, group2_test_logvar])\n",
    "        y_test = np.hstack([np.ones(group1_test_logvar.shape[0]), np.zeros(group2_test_logvar.shape[0])])\n",
    "\n",
    "        # Train logistic regression classifier on training data\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on the test data and calculate accuracy\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Calculate class means for distance (using the training data)\n",
    "        mean_group1_test = np.mean(group1_test_logvar, axis=0)\n",
    "        mean_group2_test = np.mean(group2_test_logvar, axis=0)\n",
    "\n",
    "        # Calculate the distance between the two class means\n",
    "        mean_dist = np.linalg.norm(mean_group1_test - mean_group2_test)\n",
    "\n",
    "        # Store accuracy and Riemannian distance for this n\n",
    "        results.append((n, mean_dist, accuracy))\n",
    "        # Plot when n=1\n",
    "        if n == 1:\n",
    "            \n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.scatter(group1_test_logvar[:, 0], group1_test_logvar[:, 1], label='Group A Log Variance (Test)', color='blue')\n",
    "            plt.scatter(group2_test_logvar[:, 0], group2_test_logvar[:, 1], label='Group B Log Variance (Test)', color='red')\n",
    "\n",
    "            # Plot the line connecting the two means\n",
    "            plt.plot([mean_group1_test[0], mean_group2_test[0]], [mean_group1_test[1], mean_group2_test[1]], 'k--', label=f'Mean Distance: {mean_dist:.2f}')\n",
    "\n",
    "            # Decision boundary\n",
    "            x_values = np.array([X_train[:, 0].min(), X_train[:, 0].max()])\n",
    "            y_values = -(clf.intercept_ + clf.coef_[0][0] * x_values) / clf.coef_[0][1]\n",
    "            plt.plot(x_values, y_values, 'g-', label='Decision Boundary')\n",
    "\n",
    "            # Display plot\n",
    "            plt.xlabel('Log Variance Feature B')\n",
    "            plt.ylabel('Log Variance Feature A')\n",
    "            plt.title('Log Variance FKT Feature Comparison and Logistic Regression Decision Boundary')\n",
    "\n",
    "            # Display classification accuracy on the plot\n",
    "            plt.text(0.05, 0.95, f'Accuracy: {accuracy:.2f}', transform=plt.gca().transAxes, fontsize=12,\n",
    "                     verticalalignment='top', bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgrey'))\n",
    "\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "            # test_visualize_variance(group1_test, group2_test, features)\n",
    "\n",
    "    # Return the list of accuracies and distances for each n\n",
    "    return results\n",
    "\n",
    "# Updated tangent_class_test function\n",
    "def tangent_class_test(group1_cov_train, group1_cov_test, group2_cov_train, group2_cov_test, metric):\n",
    "    # clf = SVC(kernel='linear', C=.01,class_weight='balanced')\n",
    "    clf = LogisticRegression()\n",
    "    tangent_projected_1_train, tangent_projected_2_train, tangent_projected_1_test, tangent_projected_2_test = tangent_transform(group1_cov_train, group1_cov_test, group2_cov_train, group2_cov_test, metric=metric)\n",
    "\n",
    "    # Combine the tangent projections for training and testing\n",
    "    X_train = np.vstack((tangent_projected_1_train, tangent_projected_2_train))\n",
    "    X_test = np.vstack((tangent_projected_1_test, tangent_projected_2_test))\n",
    "    y_train = np.hstack((np.ones(tangent_projected_1_train.shape[0]), np.zeros(tangent_projected_2_train.shape[0])))\n",
    "    y_test = np.hstack((np.ones(tangent_projected_1_test.shape[0]), np.zeros(tangent_projected_2_test.shape[0])))\n",
    "\n",
    "    # Dimensionality reduction\n",
    "    max_dim = np.min((X_train.shape[0], X_train.shape[1]))\n",
    "    dims = [2, 3, int((max_dim-1)/20), int((max_dim-1)/17), int((max_dim-1)/15),\n",
    "            int((max_dim-1)/13), int((max_dim-1)/12), int((max_dim-1)/10), \n",
    "            int((max_dim-1)/7), int((max_dim-1)/5), int((max_dim-1)/3), \n",
    "            int((max_dim-1)/2), int((max_dim-1)/1.7), int((max_dim-1)/1.5), \n",
    "            int((max_dim-1)/1.3), int((max_dim-1)/1.1), max_dim-1]\n",
    "\n",
    "    results = []\n",
    "    for i in dims:\n",
    "        # Reduce dimensionality using PCA\n",
    "        pca = PCA(n_components=i)\n",
    "        X_train_reduced = pca.fit_transform(X_train)\n",
    "        X_test_reduced = pca.transform(X_test)\n",
    "        mean_dist = np.linalg.norm(np.mean(X_test_reduced[y_test == 1],axis=0) - np.mean(X_test_reduced[y_test == 0],axis=0))\n",
    "        # Train logistic regression classifier\n",
    "        clf.fit(X_train_reduced, y_train)\n",
    "\n",
    "        # Test accuracy\n",
    "        y_pred = clf.predict(X_test_reduced)\n",
    "        test_accuracy = accuracy_score(y_test, y_pred)\n",
    "        results.append((i, mean_dist, test_accuracy))\n",
    "\n",
    "    return results\n",
    "\n",
    "def mean_diff(group1_covs_red,group2_covs_red,metric):\n",
    "    group_1 = mean_covariance(group1_covs_red, metric=metric)\n",
    "    group_2 = mean_covariance(group2_covs_red, metric=metric)\n",
    "    return distance(group_1,group_2,metric=metric)\n",
    "\n",
    "   \n",
    "def PSD_diff_all(group1_train, group1_test, group1_cov_train, group1_cov_test, group2_train, group2_test, group2_cov_train, group2_cov_test, metric):\n",
    "    psd_mean_distance = mean_diff(group1_cov_test, group2_cov_test, metric)\n",
    "    tangent_results = tangent_class_test(group1_cov_train, group1_cov_test, group2_cov_train, group2_cov_test, metric)\n",
    "    fkt_results = var_diff(group1_train, group1_test, group1_cov_train, group2_train, group2_test, group2_cov_train, metric)\n",
    "\n",
    "\n",
    "    result = {\n",
    "        \"psd_mean_distance\": psd_mean_distance,\n",
    "        \"tangent_results\": tangent_results,\n",
    "        \"fkt_results\": fkt_results\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the first comparison (using Group 1 data):\n",
    "IFA_result = PSD_diff_all(groupA_An_1_train, groupA_An_1_test, groupA_netmats_1_train, groupA_netmats_1_test, groupB_An_1_train, groupB_An_1_test, groupB_netmats_1_train, groupB_netmats_1_test, metric=metric)\n",
    "\n",
    "# For the second comparison (using Group 2 data):\n",
    "major_result = PSD_diff_all(groupA_An_2_train, groupA_An_2_test, groupA_netmats_2_train, groupA_netmats_2_test, groupB_An_2_train, groupB_An_2_test, groupB_netmats_2_train, groupB_netmats_2_test, metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_with_lines(x1, y1, x2, y2, label1='Series 1', label2='Series 2', xlabel='X', ylabel='Y', title='Scatter Plot with Connecting Lines'):\n",
    "    \"\"\"\n",
    "    Creates a scatter plot with lines connecting corresponding points from two series.\n",
    "\n",
    "    Parameters:\n",
    "    - x1, y1: The x and y values for the first series.\n",
    "    - x2, y2: The x and y values for the second series.\n",
    "    - label1, label2: Labels for the two series.\n",
    "    - xlabel, ylabel: Labels for the x and y axes.\n",
    "    - title: Title for the plot.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12,6))  # Set the size of the figure\n",
    "    plt.scatter(x1, y1, label=label1, color='blue')\n",
    "    plt.scatter(x2, y2, label=label2, color='orange')\n",
    "    \n",
    "    # Draw lines connecting corresponding points\n",
    "    for x_1, y_1, x_2, y_2 in zip(x1, y1, x2, y2):\n",
    "        plt.plot([x_1, x_2], [y_1, y_2], color='gray', linestyle='--')\n",
    "\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "save_text_results(f'Distance between Group Average Netmats formed from Subject Dual Regression using test data and {z_scores_unthresh.shape[1]} IFA Components: {IFA_result[\"psd_mean_distance\"]}',os.path.join(f\"fold_{fold}\", \"results\",\"results.txt\"))\n",
    "save_text_results(f'IFA Tangent Results: {IFA_result[\"tangent_results\"]}',os.path.join(f\"fold_{fold}\", \"results\",\"results.txt\"))\n",
    "save_text_results(f'IFA FKT Results: {IFA_result[\"fkt_results\"]}',os.path.join(f\"fold_{fold}\", \"results\",\"results.txt\"))\n",
    "\n",
    "\n",
    "save_text_results(f'Distance between Group Average Netmats formed from Subject Dual Regression using test data and {z_scores_unthresh_major_more.shape[1]} ICA Components: {major_result[\"psd_mean_distance\"]}',os.path.join(f\"fold_{fold}\", \"results\",\"results.txt\"))\n",
    "save_text_results(f'ICA Tangent Results: {major_result[\"tangent_results\"]}',os.path.join(f\"fold_{fold}\", \"results\",\"results.txt\"))\n",
    "save_text_results(f'ICA FKT Results: {major_result[\"fkt_results\"]}',os.path.join(f\"fold_{fold}\", \"results\",\"results.txt\"))\n",
    "\n",
    "print(IFA_result[\"psd_mean_distance\"], major_result[\"psd_mean_distance\"])\n",
    "\n",
    "scatter_with_lines([tup[0] for tup in IFA_result[\"tangent_results\"]],\n",
    "                   [tup[2] for tup in IFA_result[\"tangent_results\"]],\n",
    "                   [tup[0] for tup in major_result[\"tangent_results\"]],\n",
    "                   [tup[2] for tup in major_result[\"tangent_results\"]],\n",
    "                   label1='IFA Components', label2='ICA Components',\n",
    "                   xlabel='Dimension', ylabel='Accuracy',\n",
    "                   title='Logistic Regression Accuracy of Tangent Netmats')\n",
    "\n",
    "scatter_with_lines([tup[0] for tup in IFA_result[\"tangent_results\"]],\n",
    "                   [tup[1] for tup in IFA_result[\"tangent_results\"]],\n",
    "                   [tup[0] for tup in major_result[\"tangent_results\"]],\n",
    "                   [tup[1] for tup in major_result[\"tangent_results\"]],\n",
    "                   label1='IFA Components', label2='ICA Components',\n",
    "                   xlabel='Dimension', ylabel='Distance',\n",
    "                   title='Distance Between Group Means of Tangent Netmats')\n",
    "\n",
    "scatter_with_lines([tup[0]*2 for tup in IFA_result[\"fkt_results\"]],\n",
    "                   [tup[2] for tup in IFA_result[\"fkt_results\"]],\n",
    "                   [tup[0]*2 for tup in major_result[\"fkt_results\"]],\n",
    "                   [tup[2] for tup in major_result[\"fkt_results\"]],\n",
    "                   label1='IFA Components', label2='ICA Components',\n",
    "                   xlabel='Dimension (# of Filters)', ylabel='Accuracy',\n",
    "                   title='Logistic Regression Accuracy of LogVar FKT Features')\n",
    "\n",
    "scatter_with_lines([tup[0]*2 for tup in IFA_result[\"fkt_results\"]],\n",
    "                   [tup[1] for tup in IFA_result[\"fkt_results\"]],\n",
    "                   [tup[0]*2 for tup in major_result[\"fkt_results\"]],\n",
    "                   [tup[1] for tup in major_result[\"fkt_results\"]],\n",
    "                   label1='IFA Components', label2='ICA Components',\n",
    "                   xlabel='Dimension (# of Filters)', ylabel='Distance',\n",
    "                   title='Distance Between Group Means of LogVar FKT Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupA_train_1_tangent, groupB_train_1_tangent, groupA_test_1_tangent, groupB_test_1_tangent = tangent_transform(groupA_netmats_1_train, groupA_netmats_1_test, groupB_netmats_1_train, groupB_netmats_1_test, metric=metric)\n",
    "groupA_train_2_tangent, groupB_train_2_tangent, groupA_test_2_tangent, groupB_test_2_tangent = tangent_transform(groupA_netmats_2_train, groupA_netmats_2_test, groupB_netmats_2_train, groupB_netmats_2_test, metric=metric)\n",
    "\n",
    "IFA_Class_Result = test_classifiers(groupA_train_1_tangent, groupA_test_1_tangent, groupB_train_1_tangent, groupB_test_1_tangent)\n",
    "ICA_Class_Result = test_classifiers(groupA_train_2_tangent, groupA_test_2_tangent, groupB_train_2_tangent, groupB_test_2_tangent)\n",
    "save_text_results(f'Tangent Space Classification Accuracies for Netmats formed from {z_scores_unthresh.shape[1]} IFA Components: {IFA_Class_Result}',os.path.join(f\"fold_{fold}\", \"results\",\"results.txt\"))\n",
    "save_text_results(f'Tangent Space Classification Accuracies for Netmats formed from {z_scores_unthresh_major_more.shape[1]} ICA Components: {ICA_Class_Result}',os.path.join(f\"fold_{fold}\", \"results\",\"results.txt\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_with_lines_dict(result1, result2, label1='Series 1', label2='Series 2', \n",
    "                            xlabel='Classifier', ylabel='Accuracy', title='Accuracy Comparison'):\n",
    "    \"\"\"\n",
    "    Creates a scatter plot with lines connecting corresponding points from two dictionaries.\n",
    "\n",
    "    Parameters:\n",
    "    - result1: Dictionary containing classifiers and accuracies for the first series.\n",
    "    - result2: Dictionary containing classifiers and accuracies for the second series.\n",
    "    - label1, label2: Labels for the two series.\n",
    "    - xlabel, ylabel: Labels for the x and y axes.\n",
    "    - title: Title for the plot.\n",
    "    \"\"\"\n",
    "    # Extract classifier names\n",
    "    classifiers1 = list(result1.keys())\n",
    "    classifiers2 = list(result2.keys())\n",
    "\n",
    "    # Ensure both dictionaries have the same classifiers\n",
    "    assert classifiers1 == classifiers2, \"The classifiers (keys) must match between the two result dictionaries.\"\n",
    "\n",
    "    # Extract accuracy values\n",
    "    accuracies1 = [metrics['accuracy'] for metrics in result1.values()]\n",
    "    accuracies2 = [metrics['accuracy'] for metrics in result2.values()]\n",
    "    \n",
    "    # Debug: Print extracted accuracies\n",
    "    print(\"Accuracies for Series 1:\", accuracies1)\n",
    "    print(\"Accuracies for Series 2:\", accuracies2)\n",
    "    \n",
    "    # Set the figure size\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Number of classifiers\n",
    "    num_classifiers = len(classifiers1)\n",
    "    x_positions = range(num_classifiers)\n",
    "    \n",
    "    # Create scatter plots\n",
    "    plt.scatter(x_positions, accuracies1, label=label1, color='blue', s=100)\n",
    "    plt.scatter(x_positions, accuracies2, label=label2, color='orange', s=100)\n",
    "    \n",
    "    # Draw lines connecting corresponding points\n",
    "    for i in range(num_classifiers):\n",
    "        plt.plot([x_positions[i], x_positions[i]], [accuracies1[i], accuracies2[i]], \n",
    "                 color='gray', linestyle='--')\n",
    "    \n",
    "    # Set labels and title\n",
    "    plt.xlabel(xlabel, fontsize=14)\n",
    "    plt.ylabel(ylabel, fontsize=14)\n",
    "    plt.title(title, fontsize=16)\n",
    "    \n",
    "    # Set x-ticks to classifier names\n",
    "    plt.xticks(x_positions, classifiers1, rotation=45, ha='right', fontsize=12)\n",
    "    \n",
    "    # Add legend\n",
    "    plt.legend(fontsize=12)\n",
    "    \n",
    "    # Add grid for better readability\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Adjust layout to ensure everything fits\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "scatter_with_lines_dict(IFA_Class_Result, ICA_Class_Result, label1='IFA', label2='ICA', title='Accuracy Comparison Between Tangent Space Classification of Netmats formed via IFA and ICA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dist = []\n",
    "test_dist = []\n",
    "logistic_dims = []\n",
    "logistic_dist = []\n",
    "logistic_acc = []\n",
    "fkt_dims = []\n",
    "fkt_dist = []\n",
    "fkt_acc = []\n",
    "models_acc = []\n",
    "\n",
    "train_dist_ICA = []\n",
    "test_dist_ICA = []\n",
    "logistic_dims_ICA = []\n",
    "logistic_dist_ICA = []\n",
    "logistic_acc_ICA = []\n",
    "fkt_dims_ICA = []\n",
    "fkt_dist_ICA = []\n",
    "fkt_acc_ICA = []\n",
    "models_acc_ICA = []\n",
    "\n",
    "\n",
    "for i in range(0,5):\n",
    "    fold = i\n",
    "    fold_outputfolder = f\"fold_{fold}\"\n",
    "    if not os.path.exists(os.path.join(outputfolder, f\"fold_{fold}\")):\n",
    "        os.makedirs(os.path.join(outputfolder, f\"fold_{fold}\"))\n",
    "    if not os.path.exists(os.path.join(outputfolder, f\"fold_{fold}\", \"results\")):\n",
    "        os.makedirs(os.path.join(outputfolder, f\"fold_{fold}\", \"results\"))\n",
    "\n",
    "    train_parcellated, test_parcellated = data[splits[fold][0]], data[splits[fold][1]]\n",
    "    train_labels, test_labels = labels[splits[fold][0]], labels[splits[fold][1]]\n",
    "    train_paths, test_paths = paths[splits[fold][0]], paths[splits[fold][1]]\n",
    "\n",
    "    groupA_train_parcellated = train_parcellated[train_labels == 1]\n",
    "    groupA_test_parcellated = test_parcellated[test_labels == 1]\n",
    "    groupA_train_paths = train_paths[train_labels == 1]\n",
    "    groupA_test_paths = test_paths[test_labels == 1]\n",
    "\n",
    "    groupB_train_parcellated = train_parcellated[train_labels == 0]\n",
    "    groupB_test_parcellated = test_parcellated[test_labels == 0]\n",
    "    groupB_train_paths = train_paths[train_labels == 0]\n",
    "    groupB_test_paths = test_paths[test_labels == 0]\n",
    "    if \"reducedsubsA\" in locals():\n",
    "        del reducedsubsA\n",
    "    if \"reducedsubsB\" in locals():\n",
    "        del reducedsubsB\n",
    "    reducedsubsA_loaded = load_array_from_outputfolder(os.path.join(fold_outputfolder,'reducedsubsA.npy'))\n",
    "    reducedsubsB_loaded = load_array_from_outputfolder(os.path.join(fold_outputfolder,'reducedsubsB.npy'))\n",
    "    z_scores_unthresh = load_array_from_outputfolder(os.path.join(fold_outputfolder,\"z_scores_unthresh.npy\"))\n",
    "    z_scores_thresh = load_array_from_outputfolder(os.path.join(fold_outputfolder,\"z_scores_thresh.npy\"))\n",
    "    z_scores_unthresh_major = load_array_from_outputfolder(os.path.join(fold_outputfolder,\"z_scores_unthresh_major.npy\"))\n",
    "    z_scores_thresh_major = load_array_from_outputfolder(os.path.join(fold_outputfolder,\"z_scores_thresh_major.npy\"))\n",
    "    z_scores_unthresh_major_more = load_array_from_outputfolder(os.path.join(fold_outputfolder,\"z_scores_unthresh_major_more.npy\"))\n",
    "    z_scores_thresh_major_more = load_array_from_outputfolder(os.path.join(fold_outputfolder,\"z_scores_thresh_major_more.npy\"))\n",
    "    # Load function for An, netmats, and spatial maps\n",
    "    def load_numpy_arrays(input_prefix):\n",
    "        \"\"\"\n",
    "        Loads the An arrays, netmats, and spatial maps from disk using load_array_from_outputfolder.\n",
    "        \n",
    "        Parameters:\n",
    "        input_prefix (str): Prefix for the input files.\n",
    "\n",
    "        Returns:\n",
    "        tuple: Six numpy arrays (An_1, netmats_1, spatial_maps_1, An_2, netmats_2, spatial_maps_2).\n",
    "        \"\"\"\n",
    "        An_1 = load_array_from_outputfolder(f\"{input_prefix}_An_1.npy\")\n",
    "        netmats_1 = load_array_from_outputfolder(f\"{input_prefix}_netmats_1.npy\")\n",
    "        spatial_maps_1 = load_array_from_outputfolder(f\"{input_prefix}_spatial_maps_1.npy\")\n",
    "        An_2 = load_array_from_outputfolder(f\"{input_prefix}_An_2.npy\")\n",
    "        netmats_2 = load_array_from_outputfolder(f\"{input_prefix}_netmats_2.npy\")\n",
    "        spatial_maps_2 = load_array_from_outputfolder(f\"{input_prefix}_spatial_maps_2.npy\")\n",
    "        \n",
    "        return An_1, netmats_1, spatial_maps_1, An_2, netmats_2, spatial_maps_2\n",
    "\n",
    "    # Example usage for loading Group A train and test results\n",
    "    groupA_An_1_train, groupA_netmats_1_train, groupA_spatial_maps_1_train, groupA_An_2_train, groupA_netmats_2_train, groupA_spatial_maps_2_train = load_numpy_arrays(os.path.join(fold_outputfolder,\"groupA_train\"))\n",
    "    groupA_An_1_test, groupA_netmats_1_test, groupA_spatial_maps_1_test, groupA_An_2_test, groupA_netmats_2_test, groupA_spatial_maps_2_test = load_numpy_arrays(os.path.join(fold_outputfolder,\"groupA_test\"))\n",
    "\n",
    "    # Example usage for loading Group B train and test results\n",
    "    groupB_An_1_train, groupB_netmats_1_train, groupB_spatial_maps_1_train, groupB_An_2_train, groupB_netmats_2_train, groupB_spatial_maps_2_train = load_numpy_arrays(os.path.join(fold_outputfolder,\"groupB_train\"))\n",
    "    groupB_An_1_test, groupB_netmats_1_test, groupB_spatial_maps_1_test, groupB_An_2_test, groupB_netmats_2_test, groupB_spatial_maps_2_test = load_numpy_arrays(os.path.join(fold_outputfolder,\"groupB_test\"))\n",
    "\n",
    "    # Sanity check for Group A train data\n",
    "    print(\"Group A Train:\")\n",
    "    print(groupA_An_1_train.shape, groupA_netmats_1_train.shape, groupA_spatial_maps_1_train.shape)\n",
    "    print(groupA_An_2_train.shape, groupA_netmats_2_train.shape, groupA_spatial_maps_2_train.shape)\n",
    "\n",
    "    # Sanity check for Group A test data\n",
    "    print(\"Group A Test:\")\n",
    "    print(groupA_An_1_test.shape, groupA_netmats_1_test.shape, groupA_spatial_maps_1_test.shape)\n",
    "    print(groupA_An_2_test.shape, groupA_netmats_2_test.shape, groupA_spatial_maps_2_test.shape)\n",
    "\n",
    "    # Sanity check for Group B train data\n",
    "    print(\"Group B Train:\")\n",
    "    print(groupB_An_1_train.shape, groupB_netmats_1_train.shape, groupB_spatial_maps_1_train.shape)\n",
    "    print(groupB_An_2_train.shape, groupB_netmats_2_train.shape, groupB_spatial_maps_2_train.shape)\n",
    "\n",
    "    # Sanity check for Group B test data\n",
    "    print(\"Group B Test:\")\n",
    "    print(groupB_An_1_test.shape, groupB_netmats_1_test.shape, groupB_spatial_maps_1_test.shape)\n",
    "    print(groupB_An_2_test.shape, groupB_netmats_2_test.shape, groupB_spatial_maps_2_test.shape)\n",
    "    def migp_netmat(group_data,basis):\n",
    "        group_data_dm = group_data - group_data.mean(axis=0, keepdims=True)\n",
    "        basis_dm = basis - basis.mean(axis=0, keepdims=True)\n",
    "        A = ((group_data_dm@np.linalg.pinv(basis_dm.T)))\n",
    "        # Normalized Time x Components matrix\n",
    "        An = hcp.normalize(A)  # An is Time x Components (T x C)\n",
    "        del A\n",
    "\n",
    "        timepoints = An.shape[0]\n",
    "        group_netmat = (An.T@An)/(timepoints-1)\n",
    "        return group_netmat\n",
    "\n",
    "    def group_dist(group_data1,group_data2,basis,metric=\"riemann\"):\n",
    "        netmat1 = migp_netmat(group_data1,basis)\n",
    "        netmat2 = migp_netmat(group_data2,basis)\n",
    "        return distance(netmat1,netmat2,metric=metric)\n",
    "\n",
    "    ICA_mean_dist = group_dist(reducedsubsA_loaded,reducedsubsB_loaded,z_scores_unthresh_major,metric=metric)\n",
    "    ICA_more_mean_dist = group_dist(reducedsubsA_loaded,reducedsubsB_loaded,z_scores_unthresh_major_more,metric=metric)\n",
    "    IFA_mean_dist = group_dist(reducedsubsA_loaded,reducedsubsB_loaded,z_scores_unthresh,metric=metric)\n",
    "\n",
    "    train_dist.append(IFA_mean_dist)\n",
    "    train_dist_ICA.append(ICA_more_mean_dist)\n",
    "\n",
    "    save_text_results(f'Distance between Group Average Netmats formed from MIGP on train data projected on {z_scores_unthresh_major.shape[1]} ICA components: {ICA_mean_dist}',os.path.join(f\"fold_{fold}\", \"results\",\"results.txt\"))\n",
    "    save_text_results(f'Distance between Group Average Netmats formed from MIGP on train data projected on {z_scores_unthresh_major_more.shape[1]} ICA components: {ICA_more_mean_dist}',os.path.join(f\"fold_{fold}\", \"results\",\"results.txt\"))\n",
    "    save_text_results(f'Distance between Group Average Netmats formed from MIGP on train data projected on {z_scores_unthresh.shape[1]} IFA components: {IFA_mean_dist}',os.path.join(f\"fold_{fold}\", \"results\",\"results.txt\"))\n",
    "    from sklearn.metrics import accuracy_score, classification_report\n",
    "    from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "    # https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5662067\n",
    "    def var_diff(group1_train, group1_test, group1_cov_train,group2_train, group2_test, group2_cov_train, metric):\n",
    "        # clf = SVC(kernel='linear', class_weight='balanced')\n",
    "        clf = LogisticRegression()\n",
    "\n",
    "        \n",
    "        # Compute the mean covariances using the training data only\n",
    "        group1_mean = mean_covariance(group1_cov_train, metric=metric)\n",
    "        group2_mean = mean_covariance(group2_cov_train, metric=metric)\n",
    "\n",
    "        # # Eigen decomposition to get features\n",
    "        _, feature_all = eigh(group1_mean, group2_mean + group2_mean, eigvals_only=False)\n",
    "        # _, feature_all, _, _ = tangent_classifier(group1_cov_train, group2_cov_train, TSVM=True, TLDA=False, tangent_calc=True, metric=metric,visualize=False,n=0)\n",
    "\n",
    "\n",
    "        # Initialize list to store results (accuracy and distance)\n",
    "        results = []\n",
    "\n",
    "        # Loop from n=1 to n=15 for selecting top and bottom eigenvectors\n",
    "        for n in range(1, feature_all.shape[1] // 2 + 1): \n",
    "            # Perform eigen decomposition based on top and bottom n eigenvectors\n",
    "            features = np.hstack([feature_all[:, :n], feature_all[:, -n:]])  # Select top and bottom n eigenvectors\n",
    "            group1_train_logvar, group1_test_logvar, group2_train_logvar, group2_test_logvar = feature_generation(group1_train, group1_test,group2_train,group2_test, features, metric=metric,method=\"log-var\")\n",
    "\n",
    "            # Prepare the dataset for classification\n",
    "            X_train = np.vstack([group1_train_logvar, group2_train_logvar])\n",
    "            y_train = np.hstack([np.ones(group1_train_logvar.shape[0]), np.zeros(group2_train_logvar.shape[0])])\n",
    "            X_test = np.vstack([group1_test_logvar, group2_test_logvar])\n",
    "            y_test = np.hstack([np.ones(group1_test_logvar.shape[0]), np.zeros(group2_test_logvar.shape[0])])\n",
    "\n",
    "            # Train logistic regression classifier on training data\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            # Predict on the test data and calculate accuracy\n",
    "            y_pred = clf.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            # Calculate class means for distance (using the training data)\n",
    "            mean_group1_test = np.mean(group1_test_logvar, axis=0)\n",
    "            mean_group2_test = np.mean(group2_test_logvar, axis=0)\n",
    "\n",
    "            # Calculate the distance between the two class means\n",
    "            mean_dist = np.linalg.norm(mean_group1_test - mean_group2_test)\n",
    "\n",
    "            # Store accuracy and Riemannian distance for this n\n",
    "            results.append((n, mean_dist, accuracy))\n",
    "            # Plot when n=1\n",
    "            if n == 1:\n",
    "                \n",
    "                plt.figure(figsize=(8, 6))\n",
    "                plt.scatter(group1_test_logvar[:, 0], group1_test_logvar[:, 1], label='Group A Log Variance (Test)', color='blue')\n",
    "                plt.scatter(group2_test_logvar[:, 0], group2_test_logvar[:, 1], label='Group B Log Variance (Test)', color='red')\n",
    "\n",
    "                # Plot the line connecting the two means\n",
    "                plt.plot([mean_group1_test[0], mean_group2_test[0]], [mean_group1_test[1], mean_group2_test[1]], 'k--', label=f'Mean Distance: {mean_dist:.2f}')\n",
    "\n",
    "                # Decision boundary\n",
    "                x_values = np.array([X_train[:, 0].min(), X_train[:, 0].max()])\n",
    "                y_values = -(clf.intercept_ + clf.coef_[0][0] * x_values) / clf.coef_[0][1]\n",
    "                plt.plot(x_values, y_values, 'g-', label='Decision Boundary')\n",
    "\n",
    "                # Display plot\n",
    "                plt.xlabel('Log Variance Feature B')\n",
    "                plt.ylabel('Log Variance Feature A')\n",
    "                plt.title('Log Variance FKT Feature Comparison and Logistic Regression Decision Boundary')\n",
    "\n",
    "                # Display classification accuracy on the top-left of the plot\n",
    "                plt.text(0.05, 0.95, f'Accuracy: {accuracy:.2f}', transform=plt.gca().transAxes, fontsize=12,\n",
    "                        verticalalignment='top', bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgrey'))\n",
    "\n",
    "                # Set legend in the top-right corner\n",
    "                plt.legend(loc='upper right')\n",
    "\n",
    "                # Add grid\n",
    "                plt.grid(True)\n",
    "\n",
    "                # Show the plot\n",
    "                plt.show()\n",
    "\n",
    "                # test_visualize_variance(group1_test, group2_test, features)\n",
    "\n",
    "        # Return the list of accuracies and distances for each n\n",
    "        return results\n",
    "\n",
    "    # Updated tangent_class_test function\n",
    "    def tangent_class_test(group1_cov_train, group1_cov_test, group2_cov_train, group2_cov_test, metric):\n",
    "        # clf = SVC(kernel='linear', C=.01,class_weight='balanced')\n",
    "        clf = LogisticRegression()\n",
    "        tangent_projected_1_train, tangent_projected_2_train, tangent_projected_1_test, tangent_projected_2_test = tangent_transform(group1_cov_train, group1_cov_test, group2_cov_train, group2_cov_test, metric=metric)\n",
    "\n",
    "        # Combine the tangent projections for training and testing\n",
    "        X_train = np.vstack((tangent_projected_1_train, tangent_projected_2_train))\n",
    "        X_test = np.vstack((tangent_projected_1_test, tangent_projected_2_test))\n",
    "        y_train = np.hstack((np.ones(tangent_projected_1_train.shape[0]), np.zeros(tangent_projected_2_train.shape[0])))\n",
    "        y_test = np.hstack((np.ones(tangent_projected_1_test.shape[0]), np.zeros(tangent_projected_2_test.shape[0])))\n",
    "\n",
    "        # Dimensionality reduction\n",
    "        max_dim = np.min((X_train.shape[0], X_train.shape[1]))\n",
    "        dims = [2, 3, int((max_dim-1)/20), int((max_dim-1)/17), int((max_dim-1)/15),\n",
    "                int((max_dim-1)/13), int((max_dim-1)/12), int((max_dim-1)/10), \n",
    "                int((max_dim-1)/7), int((max_dim-1)/5), int((max_dim-1)/3), \n",
    "                int((max_dim-1)/2), int((max_dim-1)/1.7), int((max_dim-1)/1.5), \n",
    "                int((max_dim-1)/1.3), int((max_dim-1)/1.1), max_dim-1]\n",
    "\n",
    "        results = []\n",
    "        for i in dims:\n",
    "            # Reduce dimensionality using PCA\n",
    "            pca = PCA(n_components=i)\n",
    "            X_train_reduced = pca.fit_transform(X_train)\n",
    "            X_test_reduced = pca.transform(X_test)\n",
    "            mean_dist = np.linalg.norm(np.mean(X_test_reduced[y_test == 1],axis=0) - np.mean(X_test_reduced[y_test == 0],axis=0))\n",
    "            # Train logistic regression classifier\n",
    "            clf.fit(X_train_reduced, y_train)\n",
    "\n",
    "            # Test accuracy\n",
    "            y_pred = clf.predict(X_test_reduced)\n",
    "            test_accuracy = accuracy_score(y_test, y_pred)\n",
    "            results.append((i, mean_dist, test_accuracy))\n",
    "\n",
    "        return results\n",
    "\n",
    "    def mean_diff(group1_covs_red,group2_covs_red,metric):\n",
    "        group_1 = mean_covariance(group1_covs_red, metric=metric)\n",
    "        group_2 = mean_covariance(group2_covs_red, metric=metric)\n",
    "        return distance(group_1,group_2,metric=metric)\n",
    "\n",
    "    \n",
    "    def PSD_diff_all(group1_train, group1_test, group1_cov_train, group1_cov_test, group2_train, group2_test, group2_cov_train, group2_cov_test, metric):\n",
    "        psd_mean_distance = mean_diff(group1_cov_test, group2_cov_test, metric)\n",
    "        tangent_results = tangent_class_test(group1_cov_train, group1_cov_test, group2_cov_train, group2_cov_test, metric)\n",
    "        fkt_results = var_diff(group1_train, group1_test, group1_cov_train, group2_train, group2_test, group2_cov_train, metric)\n",
    "\n",
    "\n",
    "        result = {\n",
    "            \"psd_mean_distance\": psd_mean_distance,\n",
    "            \"tangent_results\": tangent_results,\n",
    "            \"fkt_results\": fkt_results\n",
    "        }\n",
    "\n",
    "        return result\n",
    "    # For the first comparison (using Group 1 data):\n",
    "    IFA_result = PSD_diff_all(groupA_An_1_train, groupA_An_1_test, groupA_netmats_1_train, groupA_netmats_1_test, groupB_An_1_train, groupB_An_1_test, groupB_netmats_1_train, groupB_netmats_1_test, metric=metric)\n",
    "\n",
    "    # For the second comparison (using Group 2 data):\n",
    "    major_result = PSD_diff_all(groupA_An_2_train, groupA_An_2_test, groupA_netmats_2_train, groupA_netmats_2_test, groupB_An_2_train, groupB_An_2_test, groupB_netmats_2_train, groupB_netmats_2_test, metric=metric)\n",
    "    def scatter_with_lines(x1, y1, x2, y2, label1='Series 1', label2='Series 2', xlabel='X', ylabel='Y', title='Scatter Plot with Connecting Lines'):\n",
    "        \"\"\"\n",
    "        Creates a scatter plot with lines connecting corresponding points from two series.\n",
    "\n",
    "        Parameters:\n",
    "        - x1, y1: The x and y values for the first series.\n",
    "        - x2, y2: The x and y values for the second series.\n",
    "        - label1, label2: Labels for the two series.\n",
    "        - xlabel, ylabel: Labels for the x and y axes.\n",
    "        - title: Title for the plot.\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(12,6))  # Set the size of the figure\n",
    "        plt.scatter(x1, y1, label=label1, color='blue')\n",
    "        plt.scatter(x2, y2, label=label2, color='orange')\n",
    "        \n",
    "        # Draw lines connecting corresponding points\n",
    "        for x_1, y_1, x_2, y_2 in zip(x1, y1, x2, y2):\n",
    "            plt.plot([x_1, x_2], [y_1, y_2], color='gray', linestyle='--')\n",
    "\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.title(title)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    save_text_results(f'Distance between Group Average Netmats formed from Subject Dual Regression using test data and {z_scores_unthresh.shape[1]} IFA Components: {IFA_result[\"psd_mean_distance\"]}',os.path.join(f\"fold_{fold}\", \"results\",\"results.txt\"))\n",
    "    save_text_results(f'IFA Tangent Results: {IFA_result[\"tangent_results\"]}',os.path.join(f\"fold_{fold}\", \"results\",\"results.txt\"))\n",
    "    save_text_results(f'IFA FKT Results: {IFA_result[\"fkt_results\"]}',os.path.join(f\"fold_{fold}\", \"results\",\"results.txt\"))\n",
    "\n",
    "\n",
    "    save_text_results(f'Distance between Group Average Netmats formed from Subject Dual Regression using test data and {z_scores_unthresh_major_more.shape[1]} ICA Components: {major_result[\"psd_mean_distance\"]}',os.path.join(f\"fold_{fold}\", \"results\",\"results.txt\"))\n",
    "    save_text_results(f'ICA Tangent Results: {major_result[\"tangent_results\"]}',os.path.join(f\"fold_{fold}\", \"results\",\"results.txt\"))\n",
    "    save_text_results(f'ICA FKT Results: {major_result[\"fkt_results\"]}',os.path.join(f\"fold_{fold}\", \"results\",\"results.txt\"))\n",
    "\n",
    "    print(IFA_result[\"psd_mean_distance\"], major_result[\"psd_mean_distance\"])\n",
    "    test_dist.append(IFA_result[\"psd_mean_distance\"])\n",
    "    test_dist_ICA.append(major_result[\"psd_mean_distance\"])\n",
    "\n",
    "    logistic_dims.append([tup[0] for tup in IFA_result[\"tangent_results\"]])\n",
    "    logistic_acc.append([tup[2] for tup in IFA_result[\"tangent_results\"]])\n",
    "    logistic_dist.append([tup[1] for tup in IFA_result[\"tangent_results\"]])\n",
    "    fkt_dims.append([tup[0]*2 for tup in IFA_result[\"fkt_results\"]])\n",
    "    fkt_acc.append([tup[2] for tup in IFA_result[\"fkt_results\"]])\n",
    "    fkt_dist.append([tup[1] for tup in IFA_result[\"fkt_results\"]])\n",
    "\n",
    "    logistic_dims_ICA.append([tup[0] for tup in major_result[\"tangent_results\"]])\n",
    "    logistic_acc_ICA.append([tup[2] for tup in major_result[\"tangent_results\"]])\n",
    "    logistic_dist_ICA.append([tup[1] for tup in major_result[\"tangent_results\"]])\n",
    "    fkt_dims_ICA.append([tup[0]*2 for tup in major_result[\"fkt_results\"]])\n",
    "    fkt_acc_ICA.append([tup[2] for tup in major_result[\"fkt_results\"]])\n",
    "    fkt_dist_ICA.append([tup[1] for tup in major_result[\"fkt_results\"]])\n",
    "\n",
    "    scatter_with_lines([tup[0] for tup in IFA_result[\"tangent_results\"]],\n",
    "                    [tup[2] for tup in IFA_result[\"tangent_results\"]],\n",
    "                    [tup[0] for tup in major_result[\"tangent_results\"]],\n",
    "                    [tup[2] for tup in major_result[\"tangent_results\"]],\n",
    "                    label1='IFA Components', label2='ICA Components',\n",
    "                    xlabel='Dimension', ylabel='Accuracy',\n",
    "                    title='Logistic Regression Accuracy of Tangent Netmats')\n",
    "\n",
    "    scatter_with_lines([tup[0] for tup in IFA_result[\"tangent_results\"]],\n",
    "                    [tup[1] for tup in IFA_result[\"tangent_results\"]],\n",
    "                    [tup[0] for tup in major_result[\"tangent_results\"]],\n",
    "                    [tup[1] for tup in major_result[\"tangent_results\"]],\n",
    "                    label1='IFA Components', label2='ICA Components',\n",
    "                    xlabel='Dimension', ylabel='Distance',\n",
    "                    title='Distance Between Group Means of Tangent Netmats')\n",
    "\n",
    "    scatter_with_lines([tup[0]*2 for tup in IFA_result[\"fkt_results\"]],\n",
    "                    [tup[2] for tup in IFA_result[\"fkt_results\"]],\n",
    "                    [tup[0]*2 for tup in major_result[\"fkt_results\"]],\n",
    "                    [tup[2] for tup in major_result[\"fkt_results\"]],\n",
    "                    label1='IFA Components', label2='ICA Components',\n",
    "                    xlabel='Dimension (# of Filters)', ylabel='Accuracy',\n",
    "                    title='Logistic Regression Accuracy of LogVar FKT Features')\n",
    "\n",
    "    scatter_with_lines([tup[0]*2 for tup in IFA_result[\"fkt_results\"]],\n",
    "                    [tup[1] for tup in IFA_result[\"fkt_results\"]],\n",
    "                    [tup[0]*2 for tup in major_result[\"fkt_results\"]],\n",
    "                    [tup[1] for tup in major_result[\"fkt_results\"]],\n",
    "                    label1='IFA Components', label2='ICA Components',\n",
    "                    xlabel='Dimension (# of Filters)', ylabel='Distance',\n",
    "                    title='Distance Between Group Means of LogVar FKT Features')\n",
    "    groupA_train_1_tangent, groupB_train_1_tangent, groupA_test_1_tangent, groupB_test_1_tangent = tangent_transform(groupA_netmats_1_train, groupA_netmats_1_test, groupB_netmats_1_train, groupB_netmats_1_test, metric=metric)\n",
    "    groupA_train_2_tangent, groupB_train_2_tangent, groupA_test_2_tangent, groupB_test_2_tangent = tangent_transform(groupA_netmats_2_train, groupA_netmats_2_test, groupB_netmats_2_train, groupB_netmats_2_test, metric=metric)\n",
    "\n",
    "    IFA_Class_Result = test_classifiers(groupA_train_1_tangent, groupA_test_1_tangent, groupB_train_1_tangent, groupB_test_1_tangent)\n",
    "    ICA_Class_Result = test_classifiers(groupA_train_2_tangent, groupA_test_2_tangent, groupB_train_2_tangent, groupB_test_2_tangent)\n",
    "    \n",
    "    models_acc.append(IFA_Class_Result)\n",
    "    models_acc_ICA.append(ICA_Class_Result)\n",
    "\n",
    "    save_text_results(f'Tangent Space Classification Accuracies for Netmats formed from {z_scores_unthresh.shape[1]} IFA Components: {IFA_Class_Result}',os.path.join(f\"fold_{fold}\", \"results\",\"results.txt\"))\n",
    "    save_text_results(f'Tangent Space Classification Accuracies for Netmats formed from {z_scores_unthresh_major_more.shape[1]} ICA Components: {ICA_Class_Result}',os.path.join(f\"fold_{fold}\", \"results\",\"results.txt\"))\n",
    "\n",
    "os.mkdir(os.path.join(outputfolder,'results'))\n",
    "# save_array_to_outputfolder(os.path.join('results','train_dist_FKT.npy'), train_dist)\n",
    "# save_array_to_outputfolder(os.path.join('results','test_dist_FKT.npy'), test_dist)\n",
    "# save_array_to_outputfolder(os.path.join('results','logistic_dims_FKT.npy'), logistic_dims)\n",
    "# save_array_to_outputfolder(os.path.join('results','logistic_dist_FKT.npy'), logistic_dist)\n",
    "# save_array_to_outputfolder(os.path.join('results','logistic_acc_FKT.npy'), logistic_acc)\n",
    "# save_array_to_outputfolder(os.path.join('results','fkt_dims_FKT.npy'), fkt_dims)\n",
    "# save_array_to_outputfolder(os.path.join('results','fkt_dist_FKT.npy'), fkt_dist)\n",
    "# save_array_to_outputfolder(os.path.join('results','fkt_acc_FKT.npy'), fkt_acc)\n",
    "# save_array_to_outputfolder(os.path.join('results','models_acc_FKT.npy'), models_acc)\n",
    "\n",
    "save_array_to_outputfolder(os.path.join('results','train_dist_TSSF.npy'), train_dist)\n",
    "save_array_to_outputfolder(os.path.join('results','test_dist_TSSF.npy'), test_dist)\n",
    "save_array_to_outputfolder(os.path.join('results','logistic_dims_TSSF.npy'), logistic_dims)\n",
    "save_array_to_outputfolder(os.path.join('results','logistic_dist_TSSF.npy'), logistic_dist)\n",
    "save_array_to_outputfolder(os.path.join('results','logistic_acc_TSSF.npy'), logistic_acc)\n",
    "save_array_to_outputfolder(os.path.join('results','fkt_dims_TSSF.npy'), fkt_dims)\n",
    "save_array_to_outputfolder(os.path.join('results','fkt_dist_TSSF.npy'), fkt_dist)\n",
    "save_array_to_outputfolder(os.path.join('results','fkt_acc_TSSF.npy'), fkt_acc)\n",
    "save_array_to_outputfolder(os.path.join('results','models_acc_TSSF.npy'), models_acc)\n",
    "\n",
    "save_array_to_outputfolder(os.path.join('results','train_dist_ICA.npy'), train_dist_ICA)\n",
    "save_array_to_outputfolder(os.path.join('results','test_dist_ICA.npy'), test_dist_ICA)\n",
    "save_array_to_outputfolder(os.path.join('results','logistic_dims_ICA.npy'), logistic_dims_ICA)\n",
    "save_array_to_outputfolder(os.path.join('results','logistic_dist_ICA.npy'), logistic_dist_ICA)\n",
    "save_array_to_outputfolder(os.path.join('results','logistic_acc_ICA.npy'), logistic_acc_ICA)\n",
    "save_array_to_outputfolder(os.path.join('results','fkt_dims_ICA.npy'), fkt_dims_ICA)\n",
    "save_array_to_outputfolder(os.path.join('results','fkt_dist_ICA.npy'), fkt_dist_ICA)\n",
    "save_array_to_outputfolder(os.path.join('results','fkt_acc_ICA.npy'), fkt_acc_ICA)\n",
    "save_array_to_outputfolder(os.path.join('results','models_acc_ICA.npy'), models_acc_ICA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(os.path.join(outputfolder,'results'))\n",
    "save_array_to_outputfolder(os.path.join('results','train_dist_FKT.npy'), train_dist)\n",
    "save_array_to_outputfolder(os.path.join('results','test_dist_FKT.npy'), test_dist)\n",
    "save_array_to_outputfolder(os.path.join('results','logistic_dims_FKT.npy'), logistic_dims)\n",
    "save_array_to_outputfolder(os.path.join('results','logistic_dist_FKT.npy'), logistic_dist)\n",
    "save_array_to_outputfolder(os.path.join('results','logistic_acc_FKT.npy'), logistic_acc)\n",
    "save_array_to_outputfolder(os.path.join('results','fkt_dims_FKT.npy'), fkt_dims)\n",
    "save_array_to_outputfolder(os.path.join('results','fkt_dist_FKT.npy'), fkt_dist)\n",
    "save_array_to_outputfolder(os.path.join('results','fkt_acc_FKT.npy'), fkt_acc)\n",
    "save_array_to_outputfolder(os.path.join('results','models_acc_FKT.npy'), models_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(os.path.join(outputfolder,'results'))\n",
    "# save_array_to_outputfolder(os.path.join('results','train_dist_FKT.npy'), train_dist)\n",
    "# save_array_to_outputfolder(os.path.join('results','test_dist_FKT.npy'), test_dist)\n",
    "# save_array_to_outputfolder(os.path.join('results','logistic_dims_FKT.npy'), logistic_dims)\n",
    "# save_array_to_outputfolder(os.path.join('results','logistic_dist_FKT.npy'), logistic_dist)\n",
    "# save_array_to_outputfolder(os.path.join('results','logistic_acc_FKT.npy'), logistic_acc)\n",
    "# save_array_to_outputfolder(os.path.join('results','fkt_dims_FKT.npy'), fkt_dims)\n",
    "# save_array_to_outputfolder(os.path.join('results','fkt_dist_FKT.npy'), fkt_dist)\n",
    "# save_array_to_outputfolder(os.path.join('results','fkt_acc_FKT.npy'), fkt_acc)\n",
    "# save_array_to_outputfolder(os.path.join('results','models_acc_FKT.npy'), models_acc)\n",
    "\n",
    "save_array_to_outputfolder(os.path.join('results','train_dist_TSSF.npy'), train_dist)\n",
    "save_array_to_outputfolder(os.path.join('results','test_dist_TSSF.npy'), test_dist)\n",
    "save_array_to_outputfolder(os.path.join('results','logistic_dims_TSSF.npy'), logistic_dims)\n",
    "save_array_to_outputfolder(os.path.join('results','logistic_dist_TSSF.npy'), logistic_dist)\n",
    "save_array_to_outputfolder(os.path.join('results','logistic_acc_TSSF.npy'), logistic_acc)\n",
    "save_array_to_outputfolder(os.path.join('results','fkt_dims_TSSF.npy'), fkt_dims)\n",
    "save_array_to_outputfolder(os.path.join('results','fkt_dist_TSSF.npy'), fkt_dist)\n",
    "save_array_to_outputfolder(os.path.join('results','fkt_acc_TSSF.npy'), fkt_acc)\n",
    "save_array_to_outputfolder(os.path.join('results','models_acc_TSSF.npy'), models_acc)\n",
    "\n",
    "save_array_to_outputfolder(os.path.join('results','train_dist_ICA.npy'), train_dist_ICA)\n",
    "save_array_to_outputfolder(os.path.join('results','test_dist_ICA.npy'), test_dist_ICA)\n",
    "save_array_to_outputfolder(os.path.join('results','logistic_dims_ICA.npy'), logistic_dims_ICA)\n",
    "save_array_to_outputfolder(os.path.join('results','logistic_dist_ICA.npy'), logistic_dist_ICA)\n",
    "save_array_to_outputfolder(os.path.join('results','logistic_acc_ICA.npy'), logistic_acc_ICA)\n",
    "save_array_to_outputfolder(os.path.join('results','fkt_dims_ICA.npy'), fkt_dims_ICA)\n",
    "save_array_to_outputfolder(os.path.join('results','fkt_dist_ICA.npy'), fkt_dist_ICA)\n",
    "save_array_to_outputfolder(os.path.join('results','fkt_acc_ICA.npy'), fkt_acc_ICA)\n",
    "save_array_to_outputfolder(os.path.join('results','models_acc_ICA.npy'), models_acc_ICA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSSF related files\n",
    "test_dist_TSSF = np.load(os.path.join('Gender_TangentSVMC1_logeuclid','results','test_dist_TSSF.npy'))\n",
    "logistic_dims_TSSF = np.load(os.path.join('Gender_TangentSVMC1_logeuclid','results','logistic_dims_TSSF.npy'))\n",
    "logistic_dist_TSSF = np.load(os.path.join('Gender_TangentSVMC1_logeuclid','results','logistic_dist_TSSF.npy'))\n",
    "logistic_acc_TSSF = np.load(os.path.join('Gender_TangentSVMC1_logeuclid','results','logistic_acc_TSSF.npy'))\n",
    "fkt_dims_TSSF = np.load(os.path.join('Gender_TangentSVMC1_logeuclid','results','fkt_dims_TSSF.npy'))\n",
    "fkt_dist_TSSF = np.load(os.path.join('Gender_TangentSVMC1_logeuclid','results','fkt_dist_TSSF.npy'))\n",
    "fkt_acc_TSSF = np.load(os.path.join('Gender_TangentSVMC1_logeuclid','results','fkt_acc_TSSF.npy'))\n",
    "\n",
    "# Loading models_acc_TSSF with allow_pickle=True\n",
    "models_acc_TSSF = np.load(os.path.join('Gender_TangentSVMC1_logeuclid','results','models_acc_TSSF.npy'), allow_pickle=True)\n",
    "\n",
    "# ICA related files\n",
    "train_dist_ICA = np.load(os.path.join('Gender_TangentSVMC1_logeuclid','results','train_dist_ICA.npy'))\n",
    "test_dist_ICA = np.load(os.path.join('Gender_TangentSVMC1_logeuclid','results','test_dist_ICA.npy'))\n",
    "logistic_dims_ICA = np.load(os.path.join('Gender_TangentSVMC1_logeuclid','results','logistic_dims_ICA.npy'))\n",
    "logistic_dist_ICA = np.load(os.path.join('Gender_TangentSVMC1_logeuclid','results','logistic_dist_ICA.npy'))\n",
    "logistic_acc_ICA = np.load(os.path.join('Gender_TangentSVMC1_logeuclid','results','logistic_acc_ICA.npy'))\n",
    "fkt_dims_ICA = np.load(os.path.join('Gender_TangentSVMC1_logeuclid','results','fkt_dims_ICA.npy'))\n",
    "fkt_dist_ICA = np.load(os.path.join('Gender_TangentSVMC1_logeuclid','results','fkt_dist_ICA.npy'))\n",
    "fkt_acc_ICA = np.load(os.path.join('Gender_TangentSVMC1_logeuclid','results','fkt_acc_ICA.npy'))\n",
    "\n",
    "models_acc_ICA = np.load(os.path.join('Gender_TangentSVMC1_logeuclid','results','models_acc_ICA.npy'), allow_pickle=True)\n",
    "\n",
    "# FKT related files\n",
    "train_dist_FKT = np.load(os.path.join('Gender_FKT2_logeuclid','results','train_dist_FKT.npy'))\n",
    "test_dist_FKT = np.load(os.path.join('Gender_FKT2_logeuclid','results','test_dist_FKT.npy'))\n",
    "logistic_dims_FKT = np.load(os.path.join('Gender_FKT2_logeuclid','results','logistic_dims_FKT.npy'))\n",
    "logistic_dist_FKT = np.load(os.path.join('Gender_FKT2_logeuclid','results','logistic_dist_FKT.npy'))\n",
    "logistic_acc_FKT = np.load(os.path.join('Gender_FKT2_logeuclid','results','logistic_acc_FKT.npy'))\n",
    "fkt_dims_FKT = np.load(os.path.join('Gender_FKT2_logeuclid','results','fkt_dims_FKT.npy'))\n",
    "fkt_dist_FKT = np.load(os.path.join('Gender_FKT2_logeuclid','results','fkt_dist_FKT.npy'))\n",
    "fkt_acc_FKT = np.load(os.path.join('Gender_FKT2_logeuclid','results','fkt_acc_FKT.npy'))\n",
    "\n",
    "models_acc_FKT = np.load(os.path.join('Gender_FKT2_logeuclid','results','models_acc_FKT.npy'), allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute mean and std across folds\n",
    "def compute_mean_std_across_folds(data):\n",
    "    n_folds = data.shape[0]                    # Number of folds (axis 0 gives the number of rows/folds)\n",
    "    mean_across_folds = np.mean(data, axis=0)  # Mean across folds (axis 0)\n",
    "    std_across_folds = np.std(data, axis=0)    # Std deviation across folds (axis 0)\n",
    "    sem_across_folds = std_across_folds / np.sqrt(n_folds)  # Compute SEM\n",
    "    print(n_folds)\n",
    "    return mean_across_folds, sem_across_folds\n",
    "\n",
    "# Modified function to plot means and std dev for a measure across TSSF, ICA, and FKT\n",
    "def plot_comparison(dims, mean_TSSF, std_TSSF, mean_ICA, std_ICA, mean_FKT, std_FKT, measure_name, ax):\n",
    "    # Use seaborn color palette\n",
    "    palette = sns.color_palette(\"Set1\", 3)\n",
    "    \n",
    "    # Map dims to positions on x-axis\n",
    "    spacing_factor = 2  # Adjust this factor to control spacing between bins\n",
    "    x_positions = np.arange(len(dims)) * spacing_factor\n",
    "    \n",
    "    # Width for offsets (should be less than half of spacing_factor)\n",
    "    width = spacing_factor / 5  # Adjust as needed\n",
    "    \n",
    "    # Offsets for each method\n",
    "    offsets = [-width, 0, width]\n",
    "    \n",
    "    # Adjust x-values for each method\n",
    "    x_TSSF = x_positions + offsets[0]\n",
    "    x_ICA = x_positions + offsets[1]\n",
    "    x_FKT = x_positions + offsets[2]\n",
    "    \n",
    "    # Plotting TSSF, ICA, and FKT with adjusted x-values\n",
    "    ax.errorbar(x_TSSF, mean_TSSF, yerr=std_TSSF, fmt='o', label='TSSF IFA', color=palette[0], capsize=0)\n",
    "    ax.errorbar(x_FKT, mean_FKT, yerr=std_FKT, fmt='o', label='FKT IFA', color=palette[2], capsize=0)\n",
    "    ax.errorbar(x_ICA, mean_ICA, yerr=std_ICA, fmt='o', label='ICA', color=palette[1], capsize=0)\n",
    "    \n",
    "    # Set x-ticks to x_positions without offsets, labels to dims\n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels(dims)\n",
    "    \n",
    "    # Formatting plot\n",
    "    ax.set_xlabel('Dimensions')\n",
    "    ax.set_ylabel(f'{measure_name} (Mean ± SEM)')\n",
    "    ax.set_title(f'Comparison of {measure_name} Across Methods')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "# Function to plot measures for a single fold without binning the x-axis\n",
    "def plot_single_fold(dims, measure_TSSF, measure_ICA, measure_FKT, measure_name, fold_index, ax):\n",
    "    # Use seaborn color palette\n",
    "    palette = sns.color_palette(\"Set1\", 3)\n",
    "    \n",
    "    # Plotting TSSF, ICA, and FKT\n",
    "    ax.plot(dims, measure_TSSF, 'o', label='TSSF IFA', color=palette[0])\n",
    "    ax.plot(dims, measure_FKT, 'o', label='FKT IFA', color=palette[2])\n",
    "    ax.plot(dims, measure_ICA, 'o', label='ICA', color=palette[1])    \n",
    "    # Formatting plot\n",
    "    ax.set_xlabel('Dimensions')\n",
    "    ax.set_ylabel(f'{measure_name}')\n",
    "    ax.set_title(f'{measure_name} (Fold {fold_index})')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "# Function to plot both averaged data and specific fold data in subplots\n",
    "def plot_measure_with_fold_and_average(dims, mean_TSSF, std_TSSF, mean_ICA, std_ICA, mean_FKT, std_FKT,\n",
    "                                       fold_TSSF, fold_ICA, fold_FKT, measure_name, fold_index):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(18, 6))\n",
    "    \n",
    "    # Left subplot: Averaged data with categorical bins\n",
    "    plot_comparison(dims, mean_TSSF, std_TSSF, mean_ICA, std_ICA, mean_FKT, std_FKT, measure_name, axs[0])\n",
    "    \n",
    "    # Right subplot: Specific fold data without adjusted x-positions\n",
    "    plot_single_fold(dims, fold_TSSF, fold_ICA, fold_FKT, measure_name, fold_index, axs[1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Loading the data for each method (TSSF, ICA, and FKT)\n",
    "# Replace the paths with your actual data paths\n",
    "# TSSF related files\n",
    "# Loading the data for each method (TSSF, ICA, and FKT)\n",
    "# TSSF related files\n",
    "logistic_acc_TSSF = np.load(os.path.join('PicVocab_AgeAdj_PMAT24_A_CR_TangentSVM_3_logeuclid','results','logistic_acc_TSSF.npy'))\n",
    "logistic_dist_TSSF = np.load(os.path.join('PicVocab_AgeAdj_PMAT24_A_CR_TangentSVM_3_logeuclid','results','logistic_dist_TSSF.npy'))\n",
    "fkt_acc_TSSF = np.load(os.path.join('PicVocab_AgeAdj_PMAT24_A_CR_TangentSVM_3_logeuclid','results','fkt_acc_TSSF.npy'))\n",
    "fkt_dist_TSSF = np.load(os.path.join('PicVocab_AgeAdj_PMAT24_A_CR_TangentSVM_3_logeuclid','results','fkt_dist_TSSF.npy'))\n",
    "\n",
    "logistic_dims_TSSF = np.load(os.path.join('PicVocab_AgeAdj_PMAT24_A_CR_TangentSVM_3_logeuclid','results','logistic_dims_TSSF.npy'))\n",
    "\n",
    "# ICA related files\n",
    "logistic_acc_ICA = np.load(os.path.join('PicVocab_AgeAdj_PMAT24_A_CR_TangentSVM_2_logeuclid','results','logistic_acc_TSSF.npy'))\n",
    "logistic_dist_ICA = np.load(os.path.join('PicVocab_AgeAdj_PMAT24_A_CR_TangentSVM_2_logeuclid','results','logistic_dist_TSSF.npy'))\n",
    "fkt_acc_ICA = np.load(os.path.join('PicVocab_AgeAdj_PMAT24_A_CR_TangentSVM_2_logeuclid','results','fkt_acc_TSSF.npy'))\n",
    "fkt_dist_ICA = np.load(os.path.join('PicVocab_AgeAdj_PMAT24_A_CR_TangentSVM_2_logeuclid','results','fkt_dist_TSSF.npy'))\n",
    "\n",
    "logistic_dims_ICA = np.load(os.path.join('PicVocab_AgeAdj_PMAT24_A_CR_TangentSVM_2_logeuclid','results','logistic_dims_TSSF.npy'))\n",
    "\n",
    "# FKT related files\n",
    "logistic_acc_FKT = np.load(os.path.join('PicVocab_AgeAdj_PMAT24_A_CR_TangentSVM_logeuclid','results','logistic_acc_TSSF.npy'))\n",
    "logistic_dist_FKT = np.load(os.path.join('PicVocab_AgeAdj_PMAT24_A_CR_TangentSVM_logeuclid','results','logistic_dist_TSSF.npy'))\n",
    "fkt_acc_FKT = np.load(os.path.join('PicVocab_AgeAdj_PMAT24_A_CR_TangentSVM_logeuclid','results','fkt_acc_TSSF.npy'))\n",
    "fkt_dist_FKT = np.load(os.path.join('PicVocab_AgeAdj_PMAT24_A_CR_TangentSVM_logeuclid','results','fkt_dist_TSSF.npy'))\n",
    "\n",
    "fkt_dims_FKT = np.load(os.path.join('PicVocab_AgeAdj_PMAT24_A_CR_TangentSVM_logeuclid','results','fkt_dims_TSSF.npy'))\n",
    "\n",
    "# Since logistic_dims and fkt_dims are the same across all methods, we'll just use one of them\n",
    "dims_logistic = logistic_dims_TSSF[0]\n",
    "dims_fkt = fkt_dims_FKT[0]\n",
    "\n",
    "# Compute means and std for all metrics\n",
    "# Logistic accuracy\n",
    "mean_logistic_acc_TSSF, std_logistic_acc_TSSF = compute_mean_std_across_folds(logistic_acc_TSSF)\n",
    "mean_logistic_acc_ICA, std_logistic_acc_ICA = compute_mean_std_across_folds(logistic_acc_ICA)\n",
    "mean_logistic_acc_FKT, std_logistic_acc_FKT = compute_mean_std_across_folds(logistic_acc_FKT)\n",
    "\n",
    "# Logistic distance\n",
    "mean_logistic_dist_TSSF, std_logistic_dist_TSSF = compute_mean_std_across_folds(logistic_dist_TSSF)\n",
    "mean_logistic_dist_ICA, std_logistic_dist_ICA = compute_mean_std_across_folds(logistic_dist_ICA)\n",
    "mean_logistic_dist_FKT, std_logistic_dist_FKT = compute_mean_std_across_folds(logistic_dist_FKT)\n",
    "\n",
    "# FKT accuracy\n",
    "mean_fkt_acc_TSSF, std_fkt_acc_TSSF = compute_mean_std_across_folds(fkt_acc_TSSF)\n",
    "mean_fkt_acc_ICA, std_fkt_acc_ICA = compute_mean_std_across_folds(fkt_acc_ICA)\n",
    "mean_fkt_acc_FKT, std_fkt_acc_FKT = compute_mean_std_across_folds(fkt_acc_FKT)\n",
    "\n",
    "# FKT distance\n",
    "mean_fkt_dist_TSSF, std_fkt_dist_TSSF = compute_mean_std_across_folds(fkt_dist_TSSF)\n",
    "mean_fkt_dist_ICA, std_fkt_dist_ICA = compute_mean_std_across_folds(fkt_dist_ICA)\n",
    "mean_fkt_dist_FKT, std_fkt_dist_FKT = compute_mean_std_across_folds(fkt_dist_FKT)\n",
    "\n",
    "# Select the fold you want to plot (e.g., fold 0)\n",
    "fold_index = 0  # Change this index to select a different fold\n",
    "\n",
    "# Extract data for the selected fold\n",
    "# Logistic accuracy\n",
    "logistic_acc_TSSF_fold = logistic_acc_TSSF[fold_index, :]\n",
    "logistic_acc_ICA_fold = logistic_acc_ICA[fold_index, :]\n",
    "logistic_acc_FKT_fold = logistic_acc_FKT[fold_index, :]\n",
    "\n",
    "# Logistic distance\n",
    "logistic_dist_TSSF_fold = logistic_dist_TSSF[fold_index, :]\n",
    "logistic_dist_ICA_fold = logistic_dist_ICA[fold_index, :]\n",
    "logistic_dist_FKT_fold = logistic_dist_FKT[fold_index, :]\n",
    "\n",
    "# # FKT accuracy\n",
    "# fkt_acc_TSSF_fold = fkt_acc_TSSF[fold_index, :]\n",
    "# fkt_acc_ICA_fold = fkt_acc_ICA[fold_index, :]\n",
    "# fkt_acc_FKT_fold = fkt_acc_FKT[fold_index, :]\n",
    "\n",
    "# # FKT distance\n",
    "# fkt_dist_TSSF_fold = fkt_dist_TSSF[fold_index, :]\n",
    "# fkt_dist_ICA_fold = fkt_dist_ICA[fold_index, :]\n",
    "# fkt_dist_FKT_fold = fkt_dist_FKT[fold_index, :]\n",
    "\n",
    "# Plotting comparisons for each measure\n",
    "# Logistic accuracy comparison\n",
    "plot_measure_with_fold_and_average(dims_logistic,\n",
    "                                   mean_logistic_acc_TSSF, std_logistic_acc_TSSF,\n",
    "                                   mean_logistic_acc_ICA, std_logistic_acc_ICA,\n",
    "                                   mean_logistic_acc_FKT, std_logistic_acc_FKT,\n",
    "                                   logistic_acc_TSSF_fold, logistic_acc_ICA_fold, logistic_acc_FKT_fold,\n",
    "                                   'Logistic Regression TS_AIRM Accuracy', fold_index)\n",
    "\n",
    "# Logistic distance comparison\n",
    "plot_measure_with_fold_and_average(dims_logistic,\n",
    "                                   mean_logistic_dist_TSSF, std_logistic_dist_TSSF,\n",
    "                                   mean_logistic_dist_ICA, std_logistic_dist_ICA,\n",
    "                                   mean_logistic_dist_FKT, std_logistic_dist_FKT,\n",
    "                                   logistic_dist_TSSF_fold, logistic_dist_ICA_fold, logistic_dist_FKT_fold,\n",
    "                                   'Logistic Regression TS_AIRM Distance', fold_index)\n",
    "\n",
    "# # FKT accuracy comparison\n",
    "# plot_measure_with_fold_and_average(dims_fkt,\n",
    "#                                    mean_fkt_acc_TSSF, std_fkt_acc_TSSF,\n",
    "#                                    mean_fkt_acc_ICA, std_fkt_acc_ICA,\n",
    "#                                    mean_fkt_acc_FKT, std_fkt_acc_FKT,\n",
    "#                                    fkt_acc_TSSF_fold, fkt_acc_ICA_fold, fkt_acc_FKT_fold,\n",
    "#                                    'TSSF_Var_1_Step Accuracy', fold_index)\n",
    "\n",
    "# # FKT distance comparison\n",
    "# plot_measure_with_fold_and_average(dims_fkt,\n",
    "#                                    mean_fkt_dist_TSSF, std_fkt_dist_TSSF,\n",
    "#                                    mean_fkt_dist_ICA, std_fkt_dist_ICA,\n",
    "#                                    mean_fkt_dist_FKT, std_fkt_dist_FKT,\n",
    "#                                    fkt_dist_TSSF_fold, fkt_dist_ICA_fold, fkt_dist_FKT_fold,\n",
    "#                                    'TSSF_Var_1_Step Distance', fold_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute mean and std across folds for model accuracies\n",
    "def compute_mean_std_model_acc(models_acc_list):\n",
    "    \"\"\"\n",
    "    models_acc_list: List of dictionaries, one for each fold.\n",
    "    Returns:\n",
    "        models: List of model names.\n",
    "        mean_acc: List of mean accuracies for each model across folds.\n",
    "        std_acc: List of std deviations for each model across folds.\n",
    "    \"\"\"\n",
    "    # Get all model names from the first fold\n",
    "    models = list(models_acc_list[0].keys())\n",
    "    \n",
    "    # Initialize dictionaries to hold accuracies\n",
    "    acc_dict = {model: [] for model in models}\n",
    "    \n",
    "    # Collect accuracies from each fold\n",
    "    for fold_data in models_acc_list:\n",
    "        for model in models:\n",
    "            acc = fold_data[model]['accuracy']\n",
    "            acc_dict[model].append(acc)\n",
    "    \n",
    "    # Compute mean and std for each model\n",
    "    mean_acc = []\n",
    "    sem_acc = []\n",
    "    n_folds = models_acc_list.shape[0]                    # Number of folds (axis 0 gives the number of rows/folds)\n",
    "    print(n_folds)\n",
    "    for model in models:\n",
    "        accs = acc_dict[model]\n",
    "        mean_acc.append(np.mean(accs))\n",
    "        sem_acc.append(np.std(accs)/np.sqrt(n_folds))\n",
    "    \n",
    "    return models, mean_acc, sem_acc\n",
    "\n",
    "# Modified function to plot means and std dev for model accuracies across TSSF, ICA, and FKT\n",
    "def plot_model_comparison(models, mean_TSSF, std_TSSF, mean_ICA, std_ICA, mean_FKT, std_FKT, measure_name, ax):\n",
    "    # Use seaborn color palette\n",
    "    palette = sns.color_palette(\"Set1\", 3)\n",
    "    \n",
    "    # Increase the spacing between bins\n",
    "    spacing_factor = 10  # Increased spacing factor from 2 to 3\n",
    "    x_positions = np.arange(len(models)) * spacing_factor\n",
    "    \n",
    "    # Width for offsets (should be less than half of spacing_factor)\n",
    "    width = spacing_factor / 5\n",
    "    \n",
    "    # Offsets for each method\n",
    "    offsets = [-width, 0, width]\n",
    "    \n",
    "    # Adjust x-values for each method\n",
    "    x_TSSF = x_positions + offsets[0]\n",
    "    x_ICA = x_positions + offsets[1]\n",
    "    x_FKT = x_positions + offsets[2]\n",
    "    \n",
    "    # Plotting TSSF, ICA, and FKT with adjusted x-values\n",
    "    ax.errorbar(x_TSSF, mean_TSSF, yerr=std_TSSF, fmt='o', label='TSSF IFA 3', color=palette[0], capsize=0)\n",
    "    ax.errorbar(x_ICA, mean_ICA, yerr=std_ICA, fmt='o', label='TSSF IFA 2', color=palette[1], capsize=0)\n",
    "    ax.errorbar(x_FKT, mean_FKT, yerr=std_FKT, fmt='o', label='TSSF IFA 1', color=palette[2], capsize=0)\n",
    "    \n",
    "    # Set x-ticks to x_positions without offsets, labels to models\n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "    \n",
    "    # Formatting plot\n",
    "    ax.set_xlabel('Models')\n",
    "    ax.set_ylabel(f'{measure_name} (Mean ± SEM)')\n",
    "    ax.set_title(f'Comparison of {measure_name} Across Methods')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "# Modified function to plot measures for a single fold with categorical bins\n",
    "def plot_single_fold_models(models, acc_TSSF, acc_ICA, acc_FKT, measure_name, fold_index, ax):\n",
    "    # Use seaborn color palette\n",
    "    palette = sns.color_palette(\"Set1\", 3)\n",
    "    \n",
    "    # Increase the spacing between bins (same as in the averaged plot)\n",
    "    spacing_factor = 10  # Increased spacing factor from 2 to 3\n",
    "    x_positions = np.arange(len(models)) * spacing_factor\n",
    "    \n",
    "    # Width for offsets (should be less than half of spacing_factor)\n",
    "    width = spacing_factor / 10\n",
    "    \n",
    "    # Offsets for each method\n",
    "    offsets = [-width, 0, width]\n",
    "    \n",
    "    # Adjust x-values for each method\n",
    "    x_TSSF = x_positions + offsets[0]\n",
    "    x_ICA = x_positions + offsets[1]\n",
    "    x_FKT = x_positions + offsets[2]\n",
    "    \n",
    "    # Plotting TSSF, ICA, and FKT with adjusted x-values\n",
    "    # Changed markers to squares ('s')\n",
    "    ax.plot(x_TSSF, acc_TSSF, 's', label='TSSF IFA 3', color=palette[0])\n",
    "    ax.plot(x_ICA, acc_ICA, 's', label='TSSF IFA 2', color=palette[1])\n",
    "    ax.plot(x_FKT, acc_FKT, 's', label='TSSF IFA 1', color=palette[2])\n",
    "    \n",
    "    # Set x-ticks to x_positions without offsets, labels to models\n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "    \n",
    "    # Formatting plot\n",
    "    ax.set_xlabel('Models')\n",
    "    ax.set_ylabel(f'{measure_name}')\n",
    "    ax.set_title(f'{measure_name} (Fold {fold_index})')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "# Function to plot both averaged data and specific fold data in subplots\n",
    "def plot_model_measure_with_fold_and_average(models, mean_TSSF, std_TSSF, mean_ICA, std_ICA, mean_FKT, std_FKT,\n",
    "                                             fold_TSSF, fold_ICA, fold_FKT, measure_name, fold_index):\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(20, 6))\n",
    "    \n",
    "    # Left subplot: Averaged data with categorical bins\n",
    "    plot_model_comparison(models, mean_TSSF, std_TSSF, mean_ICA, std_ICA, mean_FKT, std_FKT, measure_name, axs)\n",
    "    \n",
    "    # Right subplot: Specific fold data with categorical bins and square markers\n",
    "    # plot_single_fold_models(models, fold_TSSF, fold_ICA, fold_FKT, measure_name, fold_index, axs[1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Loading the data for each method (TSSF, ICA, and FKT)\n",
    "models_acc_TSSF_3 = np.load(os.path.join('PicVocab_AgeAdj_PMAT24_A_CR_TangentSVM_3_logeuclid', 'results', 'models_acc_TSSF.npy'), allow_pickle=True)\n",
    "models_acc_TSSF_2 = np.load(os.path.join('PicVocab_AgeAdj_PMAT24_A_CR_TangentSVM_2_logeuclid', 'results', 'models_acc_TSSF.npy'), allow_pickle=True)\n",
    "models_acc_TSSF_1 = np.load(os.path.join('PicVocab_AgeAdj_PMAT24_A_CR_TangentSVM_logeuclid', 'results', 'models_acc_TSSF.npy'), allow_pickle=True)\n",
    "\n",
    "# Since models are the same across methods, we'll extract them from one\n",
    "models = list(models_acc_TSSF_1[0].keys())\n",
    "print(models)\n",
    "\n",
    "# Compute means and std for model accuracies\n",
    "# TSSF\n",
    "models_TSSF_3, mean_acc_TSSF_3, std_acc_TSSF_3 = compute_mean_std_model_acc(models_acc_TSSF_3)\n",
    "# ICA\n",
    "models_TSSF_2, mean_acc_TSSF_2, std_acc_TSSF_2 = compute_mean_std_model_acc(models_acc_TSSF_2)\n",
    "# FKT\n",
    "models_TSSF_1, mean_acc_TSSF_1, std_acc_TSSF_1 = compute_mean_std_model_acc(models_acc_TSSF_1)\n",
    "\n",
    "# Ensure the models are in the same order\n",
    "assert models_TSSF_1 == models_TSSF_2 == models_TSSF_3 == models, \"Models are not the same across methods\"\n",
    "\n",
    "# Select the fold you want to plot (e.g., fold 0)\n",
    "fold_index = 0  # Change this index to select a different fold\n",
    "\n",
    "# # Extract data for the selected fold\n",
    "# # TSSF\n",
    "# fold_acc_TSSF_3 = [models_TSSF_3[fold_index][model]['accuracy'] for model in models]\n",
    "# # ICA\n",
    "# fold_acc_TSSF_2 = [models_TSSF_2[fold_index][model]['accuracy'] for model in models]\n",
    "# # FKT\n",
    "# fold_acc_TSSF_1 = [models_TSSF_1[fold_index][model]['accuracy'] for model in models]\n",
    "\n",
    "# Plotting comparisons for model accuracies\n",
    "plot_model_measure_with_fold_and_average(models,\n",
    "                                         mean_acc_TSSF_3, std_acc_TSSF_3,\n",
    "                                         mean_acc_TSSF_2, std_acc_TSSF_2,\n",
    "                                         mean_acc_TSSF_1, std_acc_TSSF_1,\n",
    "                                         None, None, None,\n",
    "                                         'Model Accuracy', fold_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute mean and std across folds for model accuracies\n",
    "def compute_mean_std_model_acc(models_acc_list):\n",
    "    \"\"\"\n",
    "    models_acc_list: List of dictionaries, one for each fold.\n",
    "    Returns:\n",
    "        models: List of model names.\n",
    "        mean_acc: List of mean accuracies for each model across folds.\n",
    "        std_acc: List of std deviations for each model across folds.\n",
    "    \"\"\"\n",
    "    # Get all model names from the first fold\n",
    "    models = list(models_acc_list[0].keys())\n",
    "    \n",
    "    # Initialize dictionaries to hold accuracies\n",
    "    acc_dict = {model: [] for model in models}\n",
    "    \n",
    "    # Collect accuracies from each fold\n",
    "    for fold_data in models_acc_list:\n",
    "        for model in models:\n",
    "            acc = fold_data[model]['accuracy']\n",
    "            acc_dict[model].append(acc)\n",
    "    \n",
    "    # Compute mean and std for each model\n",
    "    mean_acc = []\n",
    "    sem_acc = []\n",
    "    n_folds = models_acc_list.shape[0]                    # Number of folds (axis 0 gives the number of rows/folds)\n",
    "    print(n_folds)\n",
    "    for model in models:\n",
    "        accs = acc_dict[model]\n",
    "        mean_acc.append(np.mean(accs))\n",
    "        sem_acc.append(np.std(accs)/np.sqrt(n_folds))\n",
    "    \n",
    "    return models, mean_acc, sem_acc\n",
    "\n",
    "# Modified function to plot means and std dev for model accuracies across TSSF, ICA, and FKT\n",
    "def plot_model_comparison(models, mean_TSSF, std_TSSF, mean_ICA, std_ICA, mean_FKT, std_FKT, measure_name, ax):\n",
    "    # Use seaborn color palette\n",
    "    palette = sns.color_palette(\"Set1\", 3)\n",
    "    \n",
    "    # Increase the spacing between bins\n",
    "    spacing_factor = 10  # Increased spacing factor from 2 to 3\n",
    "    x_positions = np.arange(len(models)) * spacing_factor\n",
    "    \n",
    "    # Width for offsets (should be less than half of spacing_factor)\n",
    "    width = spacing_factor / 5\n",
    "    \n",
    "    # Offsets for each method\n",
    "    offsets = [-width, 0, width]\n",
    "    \n",
    "    # Adjust x-values for each method\n",
    "    x_TSSF = x_positions + offsets[0]\n",
    "    x_ICA = x_positions + offsets[1]\n",
    "    x_FKT = x_positions + offsets[2]\n",
    "    \n",
    "    # Plotting TSSF, ICA, and FKT with adjusted x-values\n",
    "    ax.errorbar(x_TSSF, mean_TSSF, yerr=std_TSSF, fmt='o', label='TSSF IFA', color=palette[0], capsize=0)\n",
    "    ax.errorbar(x_ICA, mean_ICA, yerr=std_ICA, fmt='o', label='ICA', color=palette[1], capsize=0)\n",
    "    ax.errorbar(x_FKT, mean_FKT, yerr=std_FKT, fmt='o', label='FKT IFA', color=palette[2], capsize=0)\n",
    "    \n",
    "    # Set x-ticks to x_positions without offsets, labels to models\n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "    \n",
    "    # Formatting plot\n",
    "    ax.set_xlabel('Models')\n",
    "    ax.set_ylabel(f'{measure_name} (Mean ± SEM)')\n",
    "    ax.set_title(f'Comparison of {measure_name} Across Methods')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "# Modified function to plot measures for a single fold with categorical bins\n",
    "def plot_single_fold_models(models, acc_TSSF, acc_ICA, acc_FKT, measure_name, fold_index, ax):\n",
    "    # Use seaborn color palette\n",
    "    palette = sns.color_palette(\"Set1\", 3)\n",
    "    \n",
    "    # Increase the spacing between bins (same as in the averaged plot)\n",
    "    spacing_factor = 10  # Increased spacing factor from 2 to 3\n",
    "    x_positions = np.arange(len(models)) * spacing_factor\n",
    "    \n",
    "    # Width for offsets (should be less than half of spacing_factor)\n",
    "    width = spacing_factor / 10\n",
    "    \n",
    "    # Offsets for each method\n",
    "    offsets = [-width, 0, width]\n",
    "    \n",
    "    # Adjust x-values for each method\n",
    "    x_TSSF = x_positions + offsets[0]\n",
    "    x_ICA = x_positions + offsets[1]\n",
    "    x_FKT = x_positions + offsets[2]\n",
    "    \n",
    "    # Plotting TSSF, ICA, and FKT with adjusted x-values\n",
    "    # Changed markers to squares ('s')\n",
    "    ax.plot(x_TSSF, acc_TSSF, 's', label='TSSF IFA', color=palette[0])\n",
    "    ax.plot(x_ICA, acc_ICA, 's', label='ICA', color=palette[1])\n",
    "    ax.plot(x_FKT, acc_FKT, 's', label='FKT IFA', color=palette[2])\n",
    "    \n",
    "    # Set x-ticks to x_positions without offsets, labels to models\n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "    \n",
    "    # Formatting plot\n",
    "    ax.set_xlabel('Models')\n",
    "    ax.set_ylabel(f'{measure_name}')\n",
    "    ax.set_title(f'{measure_name} (Fold {fold_index})')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "# Function to plot both averaged data and specific fold data in subplots\n",
    "def plot_model_measure_with_fold_and_average(models, mean_TSSF, std_TSSF, mean_ICA, std_ICA, mean_FKT, std_FKT,\n",
    "                                             fold_TSSF, fold_ICA, fold_FKT, measure_name, fold_index):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(20, 6))\n",
    "    \n",
    "    # Left subplot: Averaged data with categorical bins\n",
    "    plot_model_comparison(models, mean_TSSF, std_TSSF, mean_ICA, std_ICA, mean_FKT, std_FKT, measure_name, axs[0])\n",
    "    \n",
    "    # Right subplot: Specific fold data with categorical bins and square markers\n",
    "    plot_single_fold_models(models, fold_TSSF, fold_ICA, fold_FKT, measure_name, fold_index, axs[1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Loading the data for each method (TSSF, ICA, and FKT)\n",
    "models_acc_TSSF = np.load(os.path.join('PicVocab_AgeAdj_PMAT24_A_CR_TangentSVM_3_logeuclid', 'results', 'models_acc_TSSF.npy'), allow_pickle=True)\n",
    "models_acc_FKT = np.load(os.path.join('PicVocab_AgeAdj_PMAT24_A_CR_TangentSVM_2_logeuclid', 'results', 'models_acc_TSSF.npy'), allow_pickle=True)\n",
    "models_acc_ICA = np.load(os.path.join('PicVocab_AgeAdj_PMAT24_A_CR_TangentSVM_logeuclid', 'results', 'models_acc_TSSF.npy'), allow_pickle=True)\n",
    "\n",
    "# Since models are the same across methods, we'll extract them from one\n",
    "models = list(models_acc_TSSF[0].keys())\n",
    "\n",
    "# Compute means and std for model accuracies\n",
    "# TSSF\n",
    "models_TSSF, mean_acc_TSSF, std_acc_TSSF = compute_mean_std_model_acc(models_acc_TSSF)\n",
    "# ICA\n",
    "models_ICA, mean_acc_ICA, std_acc_ICA = compute_mean_std_model_acc(models_acc_ICA)\n",
    "# FKT\n",
    "models_FKT, mean_acc_FKT, std_acc_FKT = compute_mean_std_model_acc(models_acc_FKT)\n",
    "\n",
    "# Ensure the models are in the same order\n",
    "assert models_TSSF == models_ICA == models_FKT == models, \"Models are not the same across methods\"\n",
    "\n",
    "# Select the fold you want to plot (e.g., fold 0)\n",
    "fold_index = 0  # Change this index to select a different fold\n",
    "\n",
    "# Extract data for the selected fold\n",
    "# TSSF\n",
    "fold_acc_TSSF = [models_acc_TSSF[fold_index][model]['accuracy'] for model in models]\n",
    "# ICA\n",
    "fold_acc_ICA = [models_acc_ICA[fold_index][model]['accuracy'] for model in models]\n",
    "# FKT\n",
    "fold_acc_FKT = [models_acc_FKT[fold_index][model]['accuracy'] for model in models]\n",
    "\n",
    "# Plotting comparisons for model accuracies\n",
    "plot_model_measure_with_fold_and_average(models,\n",
    "                                         mean_acc_TSSF, std_acc_TSSF,\n",
    "                                         mean_acc_ICA, std_acc_ICA,\n",
    "                                         mean_acc_FKT, std_acc_FKT,\n",
    "                                         fold_acc_TSSF, fold_acc_ICA, fold_acc_FKT,\n",
    "                                         'Model Accuracy', fold_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z Scores on Dual Regressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from mne_connectivity.viz import plot_connectivity_circle\n",
    "\n",
    "def unupper_noweighting(vec):\n",
    "    # Compute the matrix size `n`\n",
    "    n = int((np.sqrt(1 + 8 * len(vec)) - 1) / 2)\n",
    "    full_matrix = np.zeros((n, n), dtype=vec.dtype)\n",
    "    upper_indices = np.triu_indices(n)\n",
    "    full_matrix[upper_indices] = vec\n",
    "    i_lower = np.tril_indices(n, -1)\n",
    "    full_matrix[i_lower] = full_matrix.T[i_lower]\n",
    "    return full_matrix\n",
    "\n",
    "def tangent_t_test(atrain, groupA_netmats, btrain, groupB_netmats, alpha=0.05, metric='riemannian'):\n",
    "    combined_netmats = np.concatenate((atrain, btrain))\n",
    "    mean = mean_covariance(combined_netmats, metric=metric)\n",
    "    groupA_tangent = tangent_space(groupA_netmats, mean, metric=metric)\n",
    "    groupB_tangent = tangent_space(groupB_netmats, mean, metric=metric)\n",
    "    \n",
    "    t_values, p_values = ttest_ind(groupA_tangent, groupB_tangent, axis=0, permutations=False)\n",
    "    reject, corrected_p_values, _, _ = multipletests(p_values, alpha=alpha, method='fdr_bh')\n",
    "    \n",
    "    if np.sum(reject) == 0:\n",
    "        print(\"No significant differences\")\n",
    "        return\n",
    "    \n",
    "    t_values_thresholded = t_values * reject\n",
    "    diff_thresholded = corrected_p_values * reject\n",
    "    diff_thresholded[diff_thresholded == 0.0] = alpha + 1e-5\n",
    "    \n",
    "    diff_thresholded_matrix = unupper_noweighting(diff_thresholded)\n",
    "    t_values_thresholded_matrix = unupper_noweighting(t_values_thresholded)\n",
    "    groupA = untangent_space(np.mean(groupA_tangent, axis=0)[np.newaxis, :], mean, metric=metric)[0, :, :] * unupper_noweighting(reject)\n",
    "    groupB = untangent_space(np.mean(groupB_tangent, axis=0)[np.newaxis, :], mean, metric=metric)[0, :, :] * unupper_noweighting(reject)\n",
    "    \n",
    "    global_min = min(groupA.min(), groupB.min())\n",
    "    global_max = max(groupA.max(), groupB.max())\n",
    "    colors = [(0, 'blue'), (0.5, 'white'), (1, 'red')]\n",
    "    custom_cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", colors)\n",
    "    \n",
    "    labels = [f\"Region {i}\" for i in range(groupA.shape[0])]\n",
    "    green_cmap = plt.get_cmap('Greens_r').copy()\n",
    "    green_cmap.set_over('white')\n",
    "    # Plot each chord plot in its own figure\n",
    "    # Create a single figure for subplots\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    fig.suptitle(\"Connectivity Plots\", fontsize=18, y=0.98)\n",
    "\n",
    "    # Adjust the layout to minimize dead space\n",
    "    plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05, wspace=0.05, hspace=0.05)\n",
    "\n",
    "    # Create four polar subplots manually\n",
    "    ax1 = fig.add_subplot(2, 2, 1, polar=True)\n",
    "    ax2 = fig.add_subplot(2, 2, 2, polar=True)\n",
    "    ax3 = fig.add_subplot(2, 2, 3, polar=True)\n",
    "    ax4 = fig.add_subplot(2, 2, 4, polar=True)\n",
    "\n",
    "    # Plot 1: Corrected P-values\n",
    "    im1 = plot_connectivity_circle(\n",
    "        np.where(diff_thresholded_matrix < alpha, diff_thresholded_matrix, np.nan),\n",
    "        labels, facecolor=(0.2, 0.2, 0.2, 1), colormap=green_cmap,\n",
    "        vmin=diff_thresholded_matrix.min(), vmax=alpha, fig=fig, ax=ax1, show=False, colorbar=False\n",
    "    )\n",
    "    ax1.set_title(\"Corrected P-values\", fontsize=12)\n",
    "    cbar1 = fig.colorbar(plt.cm.ScalarMappable(cmap=green_cmap, norm=plt.Normalize(vmin=diff_thresholded_matrix.min(), vmax=alpha)),\n",
    "                        ax=ax1, shrink=0.7, orientation='vertical')\n",
    "    cbar1.set_label('Corrected P-values', fontsize=10)\n",
    "\n",
    "    # Plot 2: T-values\n",
    "    im2 = plot_connectivity_circle(\n",
    "        np.where(np.abs(t_values_thresholded_matrix) > 0, t_values_thresholded_matrix, np.nan),\n",
    "        labels, facecolor=(0.2, 0.2, 0.2, 1), colormap=custom_cmap,\n",
    "        vmin=t_values_thresholded_matrix.min(), vmax=t_values_thresholded_matrix.max(),\n",
    "        fig=fig, ax=ax2, show=False, colorbar=False\n",
    "    )\n",
    "    ax2.set_title(\"T-values\", fontsize=12)\n",
    "    cbar2 = fig.colorbar(plt.cm.ScalarMappable(cmap=custom_cmap, norm=plt.Normalize(vmin=t_values_thresholded_matrix.min(), vmax=t_values_thresholded_matrix.max())),\n",
    "                        ax=ax2, shrink=0.7, orientation='vertical')\n",
    "    cbar2.set_label('Tangent T-values', fontsize=10)\n",
    "\n",
    "    # Plot 3: Group A Connectivity\n",
    "    im3 = plot_connectivity_circle(\n",
    "        np.where(np.abs(groupA) > 0, groupA, np.nan),\n",
    "        labels, facecolor=(0.2, 0.2, 0.2, 1), colormap=custom_cmap,\n",
    "        vmin=groupA.min(), vmax=groupA.max(), fig=fig, ax=ax3, show=False, colorbar=False\n",
    "    )\n",
    "    ax3.set_title(\"Group A Connectivity\", fontsize=12)\n",
    "    cbar3 = fig.colorbar(plt.cm.ScalarMappable(cmap=custom_cmap, norm=plt.Normalize(vmin=groupA.min(), vmax=groupA.max())),\n",
    "                        ax=ax3, shrink=0.7, orientation='vertical')\n",
    "    cbar3.set_label('Covariance', fontsize=10)\n",
    "\n",
    "    # Plot 4: Group B Connectivity\n",
    "    im4 = plot_connectivity_circle(\n",
    "        np.where(np.abs(groupB) > 0, groupB, np.nan),\n",
    "        labels, facecolor=(0.2, 0.2, 0.2, 1), colormap=custom_cmap,\n",
    "        vmin=groupB.min(), vmax=groupB.max(), fig=fig, ax=ax4, show=False, colorbar=False\n",
    "    )\n",
    "    ax4.set_title(\"Group B Connectivity\", fontsize=12)\n",
    "    cbar4 = fig.colorbar(plt.cm.ScalarMappable(cmap=custom_cmap, norm=plt.Normalize(vmin=groupB.min(), vmax=groupB.max())),\n",
    "                        ax=ax4, shrink=0.7, orientation='vertical')\n",
    "    cbar4.set_label('Covariance', fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Create heatmaps in subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(\"Heatmaps of Connectivity Differences\", fontsize=14)\n",
    "    \n",
    "    sns.heatmap(diff_thresholded_matrix, cmap=green_cmap, vmin=diff_thresholded_matrix.min(), vmax=alpha, cbar_kws={'label': 'Corrected P-values'}, ax=axes[0, 0])\n",
    "    axes[0, 0].set_title(\"Corrected P-values\")\n",
    "    \n",
    "    sns.heatmap(t_values_thresholded_matrix, cmap=custom_cmap, center=0, cbar_kws={'label': 'Tangent T-values'}, ax=axes[0, 1])\n",
    "    axes[0, 1].set_title(\"T-values on Tangent Plane\")\n",
    "    \n",
    "    sns.heatmap(groupA, cmap=custom_cmap, vmin=global_min, vmax=global_max, center=0, cbar_kws={'label': 'Covariance'}, ax=axes[1, 0])\n",
    "    axes[1, 0].set_title(\"Group A Mean Connectivity\")\n",
    "    \n",
    "    sns.heatmap(groupB, cmap=custom_cmap, vmin=global_min, vmax=global_max, center=0, cbar_kws={'label': 'Covariance'}, ax=axes[1, 1])\n",
    "    axes[1, 1].set_title(\"Group B Mean Connectivity\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tangent_t_test(groupA_netmats_1_train,groupA_netmats_1_test,groupB_netmats_1_train,groupB_netmats_1_test,metric=metric)\n",
    "tangent_t_test(groupA_netmats_2_train,groupA_netmats_2_test,groupB_netmats_2_train,groupB_netmats_2_test,metric=metric)\n",
    "\n",
    "# tangent_t_test(groupA_netmats_1_train,groupB_netmats_1_train,metric=metric)\n",
    "# tangent_t_test(groupA_netmats_1_test,groupB_netmats_1_test,metric=metric)\n",
    "# tangent_t_test(groupA_netmats_2_train,groupB_netmats_2_train,metric=metric)\n",
    "# tangent_t_test(groupA_netmats_2_test,groupB_netmats_2_test,metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_surf(hcp.mesh.inflated, hcp.cortex_data(z_scores_thresh[:,18]), threshold=0, bg_map=hcp.mesh.sulc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_surf(hcp.mesh.inflated, hcp.cortex_data(z_scores_thresh[:,34]), threshold=0, bg_map=hcp.mesh.sulc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_surf(hcp.mesh.inflated, hcp.cortex_data(groupA_spatial_maps_1_train[10,29,:]), threshold=np.percentile(np.abs(groupA_spatial_maps_1_train[10,21,:]), 95), bg_map=hcp.mesh.sulc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_surf(hcp.mesh.inflated, hcp.cortex_data(groupA_spatial_maps_1_train[10,29,:]), threshold=np.percentile(np.abs(groupA_spatial_maps_1_train[10,29,:]), 90), bg_map=hcp.mesh.sulc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fkt_riem_eigs_netmat, filters_netmatIFA, _, _ =  tangent_classifier(groupA_netmats_1_train,  groupB_netmats_1_train, TSVM=True, TLDA=False, tangent_calc=True, metric=metric,visualize=True,n=0)\n",
    "# fkt_riem_eigs_netmat, filters_netmatIFA, _, _ =  tangent_classifier(groupA_netmats_1_test,  groupB_netmats_1_test, TSVM=True, TLDA=False, tangent_calc=True, metric=metric,visualize=True,n=0)\n",
    "fkt_riem_eigs_netmat, filters_netmatICA, _, _ =  tangent_classifier(groupA_netmats_2_train,  groupB_netmats_2_train, TSVM=True, TLDA=False, tangent_calc=True, metric=metric,visualize=True,n=0)\n",
    "# fkt_riem_eigs_netmat, filters_netmatICA, _, _ =  tangent_classifier(groupA_netmats_2_test,  groupB_netmats_2_test, TSVM=True, TLDA=False, tangent_calc=True, metric=metric,visualize=True,n=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((groupA_spatial_maps_1_test.transpose((0,2,1))@filters_netmatIFA[:,[0,1,-2,-1]]).transpose((0,1,2))).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFA_filters = filters_netmatIFA[:,[0,1,2,-3,-2,-1]]\n",
    "ICA_filters = filters_netmatICA[:,[0,1,2,-3,-2,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformedA1 = groupA_spatial_maps_1_train.transpose((0,2,1))@np.linalg.pinv(IFA_filters.T)@IFA_filters.T\n",
    "transformedB1 = groupB_spatial_maps_1_train.transpose((0,2,1))@np.linalg.pinv(IFA_filters.T)@IFA_filters.T\n",
    "\n",
    "transformedA2 = groupA_spatial_maps_2_train.transpose((0,2,1))@np.linalg.pinv(ICA_filters.T)@ICA_filters.T\n",
    "transformedB2 = groupB_spatial_maps_2_train.transpose((0,2,1))@np.linalg.pinv(ICA_filters.T)@ICA_filters.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_surf(hcp.mesh.inflated, hcp.cortex_data(transformedB1[0,:,-2]), threshold=np.percentile(np.abs(transformedB1[0,:,-2]),99), bg_map=hcp.mesh.sulc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transformedA1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "for i in range(0,transformedA1.shape[2]):\n",
    "    t_stat, p_val = ttest_ind(transformedA1[:,:,i], transformedB1[:,:,i], axis=0, equal_var=False, nan_policy='raise',permutations=None, random_state=None, alternative='two-sided')\n",
    "    reject, _, _, _ = multipletests(p_val, alpha=0.1,method='fdr_bh')\n",
    "    \n",
    "    _, p_val2 = ttest_ind(transformedA2[:,:,i], transformedB2[:,:,i], axis=0, equal_var=False, nan_policy='raise',permutations=None, random_state=None, alternative='two-sided')\n",
    "    reject2, _, _, _ = multipletests(p_val2, alpha=0.1,method='fdr_bh')\n",
    "    print(np.sum(reject) - np.sum(reject2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,groupA_spatial_maps_1_test.shape[1]):\n",
    "    t_stat, p_val = ttest_ind(groupA_spatial_maps_1_test[:,i,:], groupB_spatial_maps_1_test[:,i,:], axis=0, equal_var=True, nan_policy='raise',permutations=None, random_state=None, alternative='two-sided')\n",
    "    reject, _, _, _ = multipletests(p_val, alpha=0.05,method='fdr_bh')\n",
    "    \n",
    "    _, p_val2 = ttest_ind(groupA_spatial_maps_2_test[:,i,:], groupB_spatial_maps_2_test[:,i,:], axis=0, equal_var=True, nan_policy='raise',permutations=None, random_state=None, alternative='two-sided')\n",
    "    reject2, _, _, _ = multipletests(p_val2, alpha=0.05,method='fdr_bh')\n",
    "    print(np.sum(reject) - np.sum(reject2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy.ndimage import label\n",
    "\n",
    "# Step 1: Calculate t-statistics and uncorrected p-values\n",
    "t_stat, p_val = ttest_ind(\n",
    "    np.sum(groupA_spatial_maps_2_train, axis=1),\n",
    "    np.sum(groupB_spatial_maps_2_train, axis=1),\n",
    "    axis=0,\n",
    "    equal_var=True,\n",
    "    nan_policy='raise'\n",
    ")\n",
    "\n",
    "# Step 2: Perform FDR correction on p-values\n",
    "reject, p_values_corrected, _, _ = multipletests(p_val, alpha=0.05, method='fdr_bh')\n",
    "print(f\"Number of significant voxels (FDR corrected): {np.sum(reject)}\")\n",
    "\n",
    "# Step 3: Threshold based on voxel-wise uncorrected p-values for initial cluster formation\n",
    "voxel_threshold = 0.01  # Set an uncorrected threshold for defining clusters\n",
    "significant_voxels = p_val < voxel_threshold\n",
    "\n",
    "# Step 4: Identify clusters of contiguous significant voxels\n",
    "labeled_array, num_clusters = label(significant_voxels)\n",
    "\n",
    "# Step 5: Calculate cluster sizes\n",
    "cluster_sizes = np.array([(labeled_array == i).sum() for i in range(1, num_clusters + 1)])\n",
    "\n",
    "# Step 6: Apply a cluster size threshold (based on empirical threshold or permutation testing)\n",
    "# Here, we choose an arbitrary cluster size threshold (e.g., 20)\n",
    "# In practice, you should determine this threshold using permutation testing\n",
    "cluster_size_threshold = 9  # Example threshold for demonstration\n",
    "significant_clusters = [i for i, size in enumerate(cluster_sizes, 1) if size >= cluster_size_threshold]\n",
    "\n",
    "# Step 7: Create a final thresholded map of significant clusters\n",
    "final_significant_map = np.isin(labeled_array, significant_clusters)\n",
    "\n",
    "# Output results\n",
    "print(f\"Number of clusters found: {num_clusters}\")\n",
    "print(f\"Number of significant clusters (size > {cluster_size_threshold}): {len(significant_clusters)}\")\n",
    "\n",
    "# `final_significant_map` is a binary map of significant clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_significant_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_surf(hcp.mesh.inflated, hcp.cortex_data(transformedA1[0,:,-2]), threshold=np.percentile(np.abs(transformedA1[0,:,-2]),90), bg_map=hcp.mesh.sulc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_surf(hcp.mesh.inflated, hcp.cortex_data(transformedB1[0,:,0]), threshold=np.percentile(np.abs(transformedB1[0,:,0]),90), bg_map=hcp.mesh.sulc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_surf(hcp.mesh.inflated, hcp.cortex_data(z_scores_thresh[:,0]), threshold=0, bg_map=hcp.mesh.sulc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_surf(hcp.mesh.inflated, hcp.cortex_data(groupA_spatial_maps_2_test[0,0,:]), threshold=np.percentile(np.abs(groupA_spatial_maps_1_test[0,0,:]),95), bg_map=hcp.mesh.sulc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_surf(hcp.mesh.inflated, hcp.cortex_data(groupB_spatial_maps_2_test[0,0,:]), threshold=np.percentile(np.abs(groupB_spatial_maps_1_test[0,0,:]),95), bg_map=hcp.mesh.sulc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting.view_surf(hcp.mesh.inflated, hcp.cortex_data(groupA_spatial_maps_1_train[10,20,:]), threshold=np.percentile(np.abs(groupA_spatial_maps_1_train[10,20,:]), 95), bg_map=hcp.mesh.sulc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting.view_surf(hcp.mesh.inflated, hcp.cortex_data(groupA_spatial_maps_1_train[20,20,:]), threshold=np.percentile(np.abs(groupA_spatial_maps_1_train[20,20,:]), 95), bg_map=hcp.mesh.sulc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting.view_surf(hcp.mesh.inflated, hcp.cortex_data(groupB_spatial_maps_1_train[11,20,:]), threshold=np.percentile(np.abs(groupB_spatial_maps_1_train[11,20,:]), 95), bg_map=hcp.mesh.sulc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting.view_surf(hcp.mesh.inflated, hcp.cortex_data(groupB_spatial_maps_1_train[1,20,:]), threshold=np.percentile(np.abs(groupB_spatial_maps_1_train[1,20,:]), 95), bg_map=hcp.mesh.sulc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting.view_surf(hcp.mesh.inflated, hcp.cortex_data(z_scores_unthresh[:,20]), threshold=np.percentile(np.abs(z_scores_unthresh[:,20]), 95), bg_map=hcp.mesh.sulc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
