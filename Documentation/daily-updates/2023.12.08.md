# 2023.12.08

## General Notes

## Algorithm Design

### Developments

* When adding future extensions/variants, the main changes should be in the
  * Discrimination - Current FKT
    * Kernel Discriminatory Analysis
    * Kernel PCA
  * Explanation - Current ICA
    * PROFUMO
    * Dictionary Learning

### Questions

* [ ] How should we be denoising? This method seems prone to site effects
* [ ] What happens if all the discriminatory information is represented by higher-order information? I think it still might work in the case you view it as a linear approximation
* [ ] What is the best distance similarity measure to form the within-subject FC? What is the best similarity measure to measure subject similarity? Is it right to say the parcellated covariance matrix is implicitly based on Euclidean distance and the SPADE algorithm is related to Bhattacharya distance since it uses two different covariance matrices? Are there other kernels we can use in formulating the parcellated covariance matrices and in the FKT/dissimilarity calculation? In forming the covariance matrices it is important to ask what space the vectors/observations live in. For doing the dissimilarity analysis it is important to figure out what space the covariance matrices live in. Should we relate the vectors/observations based on mean, polynomials, variance, and higher-order statistics? the same question applies to relating the separate covariance matrices

## Code

### Developments

### ToDo

*
